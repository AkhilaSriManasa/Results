####################### CMakeLists.txt (libopenshot) #########################
# @brief CMake build file for libopenshot (used to generate makefiles)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################

cmake_minimum_required(VERSION 3.2...3.14 FATAL_ERROR)

message("\
-----------------------------------------------------------------
          Welcome to the OpenShot Build System!

CMake will now check libopenshot's build dependencies and inform
you of any missing files or other issues.

For more information, please visit <http://www.openshot.org/>.
-----------------------------------------------------------------")

################ ADD CMAKE MODULES ##################
set(CMAKE_MODULE_PATH "${CMAKE_SOURCE_DIR}/cmake/Modules")

################ PROJECT VERSION ####################
set(PROJECT_VERSION_FULL "0.2.4-dev1")
set(PROJECT_SO_VERSION 18)

# Remove the dash and anything following, to get the #.#.# version for project()
STRING(REGEX REPLACE "\-.*$" "" VERSION_NUM "${PROJECT_VERSION_FULL}")

################### SETUP PROJECT ###################
# This will define the following variables
# PROJECT_NAME
# PROJECT_VERSION, libopenshot_VERSION
# PROJECT_VERSION_MAJOR, libopenshot_VERSION_MAJOR
# PROJECT_VERSION_MINOR, libopenshot_VERSION_MINOR
# PROJECT_VERSION_PATCH, libopenshot_VERSION_PATCH
PROJECT(libopenshot LANGUAGES C CXX VERSION ${VERSION_NUM})

message("
Generating build files for OpenShot with CMake ${CMAKE_VERSION}
  Building ${PROJECT_NAME} (version ${PROJECT_VERSION})
  SO/API/ABI Version: ${PROJECT_SO_VERSION}
")

# Define install paths according to system conventions
# XXX: This must be AFTER THE PROJECT() COMMAND w/ languages enabled,
#      in order to properly configure CMAKE_INSTALL_LIBDIR path
include(GNUInstallDirs)

# Collect and display summary of options/dependencies
include(FeatureSummary)

################ OPTIONS ##################
# Optional build settings for libopenshot
option(USE_SYSTEM_JSONCPP "Use system installed JsonCpp, if found" ON)
option(DISABLE_BUNDLED_JSONCPP "Don't fall back to bundled JsonCpp" OFF)
option(DISABLE_TESTS "Don't build unit tests" OFF)
option(ENABLE_IWYU "Enable 'Include What You Use' scanner (CMake 3.3+)" OFF)
option(ENABLE_COVERAGE "Enable coverage reporting" OFF)

########## Configure Version.h header ##############
configure_file(include/OpenShotVersion.h.in include/OpenShotVersion.h @ONLY)
# We'll want that installed later
install(FILES ${CMAKE_CURRENT_BINARY_DIR}/include/OpenShotVersion.h
        DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/libopenshot)

#### Enable C++11 (for std::shared_ptr support)
set(CMAKE_CXX_STANDARD 11)
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF)

IF (WIN32)
	SET_PROPERTY(GLOBAL PROPERTY WIN32 "WIN32")
ENDIF(WIN32)

include_directories(
  ${CMAKE_CURRENT_SOURCE_DIR}/include
  ${CMAKE_CURRENT_BINARY_DIR}/include)

############## Code Coverage #########################
if (DISABLE_TESTS AND ENABLE_COVERAGE)
  message(WARNING "ENABLE_COVERAGE requires tests, overriding DISABLE_TESTS")
  set(DISABLE_TESTS OFF CACHE BOOL "Don't build unit tests" FORCE)
endif()

if (ENABLE_COVERAGE)
  if (NOT CMAKE_BUILD_TYPE)
    set(CMAKE_BUILD_TYPE "Debug")
    message(STATUS "Coverage enabled, setting build type to Debug")
  endif()
  include(CodeCoverage)
  APPEND_COVERAGE_COMPILER_FLAGS()
endif()
add_feature_info("Coverage" ENABLE_COVERAGE "analyze test coverage and generate report")

############## PROCESS src/ DIRECTORIES ##############
add_subdirectory(src)

################### DOCUMENTATION ###################
# Find Doxygen (used for documentation)
include(cmake/Modules/UseDoxygen.cmake)

# Doxygen was found
if (TARGET doc)
	message(STATUS "Doxygen found, documentation target enabled")
	message("\nTo compile documentation in doc/html, run: 'make doc'")

  # Install docs, if the user builds them with `make doc`
  install(CODE "MESSAGE(\"Checking for documentation files to install...\")")
  install(CODE "MESSAGE(\"(Compile with 'make doc' command, requires Doxygen)\")")

  install(DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/doc/html/
          DESTINATION ${CMAKE_INSTALL_DOCDIR}/API
          MESSAGE_NEVER # Don't spew about file copies
          OPTIONAL )    # No error if the docs aren't found
endif()

############# PROCESS tests/ DIRECTORY ##############
if(NOT DISABLE_TESTS)
  add_subdirectory(tests)
endif()

############## COVERAGE REPORTING #################
if (ENABLE_COVERAGE)
  setup_target_for_coverage_lcov(
    NAME coverage
    LCOV_ARGS "--no-external"
    EXECUTABLE openshot-test
    DEPENDENCIES openshot-test)
    message("Generate coverage report with 'make coverage'")
endif()

########### PRINT FEATURE SUMMARY ##############
feature_summary(WHAT ALL
    INCLUDE_QUIET_PACKAGES
    FATAL_ON_MISSING_REQUIRED_PACKAGES
    DESCRIPTION "Displaying feature summary\n\nBuild configuration:")
## Detailed Install Instructions

Operating system specific install instructions are located in:

* doc/INSTALL-LINUX.md
* doc/INSTALL-MAC.md
* doc/INSTALL-WINDOWS.md

## Getting Started

The best way to get started with libopenshot, is to learn about our build system, obtain all the source code, 
install a development IDE and tools, and better understand our dependencies. So, please read through the 
following sections, and follow the instructions. And keep in mind, that your computer is likely different 
than the one used when writing these instructions. Your file paths and versions of applications might be 
slightly different, so keep an eye out for subtle file path differences in the commands you type.

## Build Tools

CMake is the backbone of our build system.  It is a cross-platform build system, which checks for dependencies, 
locates header files and libraries, generates makefiles, and supports the cross-platform compiling of 
libopenshot and libopenshot-audio.  CMake uses an out-of-source build concept, where all temporary build 
files, such as makefiles, object files, and even the final binaries, are created outside of the source 
code folder, inside a /build/ sub-folder.  This prevents the build process from cluttering up the source 
code.  These instructions have only been tested with the GNU compiler (including MSYS2/MinGW for Windows).

## Dependencies

The following libraries are required to build libopenshot.  Instructions on how to install these 
dependencies vary for each operating system.  Libraries and Executables have been labeled in the 
list below to help distinguish between them.

* ### FFmpeg (libavformat, libavcodec, libavutil, libavdevice, libavresample, libswscale)
  * http://www.ffmpeg.org/ `(Library)`
  * This library is used to decode and encode video, audio, and image files.  It is also used to obtain information about media files, such as frame rate, sample rate, aspect ratio, and other common attributes.

* ### ImageMagick++ (libMagick++, libMagickWand, libMagickCore)
  * http://www.imagemagick.org/script/magick++.php `(Library)`
  * This library is **optional**, and used to decode and encode images.

* ### OpenShot Audio Library (libopenshot-audio)
  * https://github.com/OpenShot/libopenshot-audio/ `(Library)`
  * This library is used to mix, resample, host plug-ins, and play audio. It is based on the JUCE project, which is an outstanding audio library used by many different applications

* ### Qt 5 (libqt5)
  * http://www.qt.io/qt5/ `(Library)`
  * Qt5 is used to display video, store image data, composite images, apply image effects, and many other utility functions, such as file system manipulation, high resolution timers, etc...

* ### CMake (cmake)
  * http://www.cmake.org/ `(Executable)`
  * This executable is used to automate the generation of Makefiles, check for dependencies, and is the backbone of libopenshot’s cross-platform build process.

* ### SWIG (swig)
  * http://www.swig.org/ `(Executable)`
  * This executable is used to generate the Python and Ruby bindings for libopenshot. It is a simple and powerful wrapper for C++ libraries, and supports many languages.

* ### Python 3 (libpython)
  * http://www.python.org/ `(Executable and Library)`
  * This library is used by swig to create the Python (version 3+) bindings for libopenshot. This is also the official language used by OpenShot Video Editor (a graphical interface to libopenshot).

* ### Doxygen (doxygen)
  * http://www.stack.nl/~dimitri/doxygen/ `(Executable)`
  * This executable is used to auto-generate the documentation used by libopenshot.

* ### UnitTest++ (libunittest++)
  * https://github.com/unittest-cpp/ `(Library)`
  * This library is used to execute unit tests for libopenshot.  It contains many macros used to keep our unit testing code very clean and simple.

* ### ZeroMQ (libzmq)
  * http://zeromq.org/ `(Library)`
  * This library is used to communicate between libopenshot and other applications (publisher / subscriber). Primarily used to send debug data from libopenshot.

* ### OpenMP (-fopenmp)
  * http://openmp.org/wp/ `(Compiler Flag)`
  * If your compiler supports this flag (GCC, Clang, and most other compilers), it provides libopenshot with easy methods of using parallel programming techniques to improve performance and take advantage of multi-core processors.

## CMake Flags (Optional)
There are many different build flags that can be passed to cmake to adjust how libopenshot is compiled. Some of these flags might be required when compiling on certain OSes, just depending on how your build environment is setup. To add a build flag, follow this general syntax:  $ cmake -DMAGICKCORE_HDRI_ENABLE=1 -DENABLE_TESTS=1 ../

* MAGICKCORE_HDRI_ENABLE (default 0)
* MAGICKCORE_QUANTUM_DEPTH (default 0)
* OPENSHOT_IMAGEMAGICK_COMPATIBILITY (default 0)
* DISABLE_TESTS (default 0)
* CMAKE_PREFIX_PATH (`/location/to/missing/library/`)
* PYTHON_INCLUDE_DIR (`/location/to/python/include/`)
* PYTHON_LIBRARY (`/location/to/python/lib.a`)
* PYTHON_FRAMEWORKS (`/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/`)
* CMAKE_CXX_COMPILER (`/location/to/mingw/g++`)
* CMAKE_C_COMPILER (`/location/to/mingw/gcc`)

## Obtaining Source Code

The first step in installing libopenshot is to obtain the most recent source code. The source code is available on [GitHub](https://github.com/OpenShot/libopenshot). Use the following command to obtain the latest libopenshot source code.

```
git clone https://github.com/OpenShot/libopenshot.git
git clone https://github.com/OpenShot/libopenshot-audio.git
```

## Folder Structure (libopenshot)

The source code is divided up into the following folders.

* ### build/
   * This folder needs to be manually created, and is used by cmake to store the temporary build files, such as makefiles, as well as the final binaries (library and test executables).

* ### cmake/
   * This folder contains custom modules not included by default in cmake, used to find dependency libraries and headers and determine if these libraries are installed.

* ### doc/
   * This folder contains documentation and related files, such as logos and images required by the doxygen auto-generated documentation.

* ### include/
   * This folder contains all headers (*.h) used by libopenshot.

* ### src/
   * This folder contains all source code (*.cpp) used by libopenshot.

* ### tests/
   * This folder contains all unit test code.  Each class has it’s own test file (*.cpp), and uses UnitTest++ macros to keep the test code simple and manageable.

* ### thirdparty/
   * This folder contains code not written by the OpenShot team. For example, jsoncpp, an open-source JSON parser.

## Linux Build Instructions (libopenshot-audio)
To compile libopenshot-audio, we need to go through a few additional steps to manually build and install it. Launch a terminal and enter:

```
cd [libopenshot-audio repo folder]
mkdir build
cd build
cmake ../
make
make install
./src/openshot-audio-test-sound  (This should play a test sound)
```

## Linux Build Instructions (libopenshot)
Run the following commands to compile libopenshot:

```
cd [libopenshot repo directory]
mkdir -p build
cd build
cmake ../
make
make install
```

For more detailed instructions, please see:

* doc/INSTALL-LINUX.md
* doc/INSTALL-MAC.md
* doc/INSTALL-WINDOWS.md
OpenShot Video Library (libopenshot) is a free, open-source C++ library dedicated to
delivering high quality video editing, animation, and playback solutions to the 
world.

## Build Status

[![Build Status](https://img.shields.io/travis/OpenShot/libopenshot/develop.svg?label=libopenshot)](https://travis-ci.org/OpenShot/libopenshot) [![Build Status](https://img.shields.io/travis/OpenShot/libopenshot-audio/develop.svg?label=libopenshot-audio)](https://travis-ci.org/OpenShot/libopenshot-audio)

## Features

* Cross-Platform (Linux, Mac, and Windows)
* Multi-Layer Compositing
* Video and Audio Effects (Chroma Key, Color Adjustment, Grayscale, etc…)
* Animation Curves (Bézier, Linear, Constant)
* Time Mapping (Curve-based Slow Down, Speed Up, Reverse)
* Audio Mixing & Resampling (Curve-based)
* Audio Plug-ins (VST & AU)
* Audio Drivers (ASIO, WASAPI, DirectSound, CoreAudio, iPhone Audio, ALSA, JACK, and Android)
* Telecine and Inverse Telecine (Film to TV, TV to Film)
* Frame Rate Conversions
* Multi-Processor Support (Performance)
* Python and Ruby Bindings (All Features Supported)
* Qt Video Player Included (Ability to display video on any QWidget)
* Unit Tests (Stability)
* All FFmpeg Formats and Codecs Supported (Images, Videos, and Audio files)
* Full Documentation with Examples (Doxygen Generated)

## Install

Detailed instructions for building libopenshot and libopenshot-audio for each OS. These instructions
are also available in the /docs/ source folder.

   * [Linux](https://github.com/OpenShot/libopenshot/wiki/Linux-Build-Instructions)
   * [Mac](https://github.com/OpenShot/libopenshot/wiki/Mac-Build-Instructions)
   * [Windows](https://github.com/OpenShot/libopenshot/wiki/Windows-Build-Instructions)

## Hardware Acceleration

OpenShot now supports experimental hardware acceleration, both for encoding and
decoding videos. When enabled, this can either speed up those operations or slow
them down, depending on the power and features supported by your graphics card.
Please see [doc/HW-ACCELL.md](doc/HW-ACCEL.md) for more information.

## Documentation

Beautiful HTML documentation can be generated using Doxygen.
```
make doc
```
(Also available online: http://openshot.org/files/libopenshot/)

## Developers

Are you interested in becoming more involved in the development of 
OpenShot? Build exciting new features, fix bugs, make friends, and become a hero! 
Please read the [step-by-step](https://github.com/OpenShot/openshot-qt/wiki/Become-a-Developer) 
instructions for getting source code, configuring dependencies, and building OpenShot.

## Report a bug

You can report a new libopenshot issue directly on GitHub:

https://github.com/OpenShot/libopenshot/issues

## Websites

- https://www.openshot.org/  (Official website and blog)
- https://github.com/OpenShot/libopenshot/ (source code and issue tracker)
- https://github.com/OpenShot/libopenshot-audio/ (source code for audio library)
- https://github.com/OpenShot/openshot-qt/ (source code for Qt client)
- https://launchpad.net/openshot/

### License

Copyright (c) 2008-2019 OpenShot Studios, LLC.

OpenShot Library (libopenshot) is free software: you can redistribute it
and/or modify it under the terms of the GNU Lesser General Public License
as published by the Free Software Foundation, either version 3 of the
License, or (at your option) any later version.

OpenShot Library (libopenshot) is distributed in the hope that it will be
useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with OpenShot Library. If not, see http://www.gnu.org/licenses/.

To release a closed-source product which uses libopenshot (i.e. video
editing and playback), commercial licenses are also available: contact
sales@openshot.org for more information.
cmake_minimum_required(VERSION 2.8.1)
project(UnitTest++)

# get the main sources
file(GLOB SRCS RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} src/*.cpp src/*.h)
source_group("" FILES ${SRCS})

# get platform specific sources
if (WIN32)
    set(PLAT_DIR Win32)
else()
    set(PLAT_DIR Posix)
endif(WIN32)
file(GLOB PLAT_SRCS RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} src/${PLAT_DIR}/*.cpp src/${PLAT_DIR}/*.h)
source_group(${PLAT_DIR} FILES ${PLAT_SRCS})

# create the lib
add_library(UnitTestPP SHARED ${SRCS} ${PLAT_SRCS})
set_target_properties(UnitTestPP PROPERTIES OUTPUT_NAME UnitTest++)
include_directories(src)

# build the test runner
file(GLOB TEST_SRCS RELATIVE ${CMAKE_CURRENT_SOURCE_DIR} src/tests/*.cpp src/tests/*.h)
source_group( "" FILES ${TEST_SRCS})
add_executable(TestUnitTestPP ${TEST_SRCS})
set_target_properties(TestUnitTestPP PROPERTIES OUTPUT_NAME TestUnitTest++)
target_link_libraries(TestUnitTestPP UnitTestPP)

# turn on testing
enable_testing()
add_custom_target(check COMMAND ${CMAKE_CTEST_COMMAND} -V)

# add the test runner as a test
add_test(NAME TestUnitTestPP COMMAND TestUnitTest++ ${CONFIG_PATH} ${CONFIG_TASKS_PATH} ${SOUND_LOG_PATH})
add_dependencies(check TestUnitTestPP)
## Hardware Acceleration

OpenShot now has experimental support for hardware acceleration, which uses 1 (or more)
graphics cards to offload some of the work for both decoding and encoding. This is
very new and experimental (as of May 2019), but we look forward to "accelerating"
our support for this in the future!

The following table summarizes our current level of support:

|                    |  Linux Decode   | Linux Encode   | Mac Decode |    Mac Encode  | Windows Decode | Windows Encode | Notes            |
|--------------------|:---------------:|:--------------:|:----------:|:--------------:|:--------------:|:--------------:|------------------|
| VA-API             |   ✔️ &nbsp;      |    ✔️ &nbsp;    |      -     |        -       |       -        |        -       | *Linux Only*     |
| VDPAU              | ✔️ <sup>1</sup>  | ✅ <sup>2</sup> |      -    |        -       |       -        |        -       | *Linux Only*     |
| CUDA (NVDEC/NVENC) | ❌ <sup>3</sup> |   ✔️ &nbsp;     |      -     |        -       |       -        |    ✔️ &nbsp;    | *Cross Platform* |
| VideoToolBox       |           -     |         -      |  ✔️ &nbsp;  | ❌ <sup>4</sup> |      -        |       -         | *Mac Only*       |
| DXVA2              |           -     |         -      |      -     |        -       | ❌ <sup>3</sup> |      -         | *Windows Only*   |
| D3D11VA            |           -     |         -      |      -     |        -       | ❌ <sup>3</sup> |      -         | *Windows Only*   |
| QSV                | ❌ <sup>3</sup> |   ❌ &nbsp;   |  ❌ &nbsp; |   ❌ &nbsp;    |   ❌ &nbsp;     |    ❌ &nbsp;   | *Cross Platform* |

#### Notes

1.  VDPAU for some reason needs a card number one higher than it really is
2.  VDPAU is a decoder only
3.  Green frames (pixel data not correctly tranferred back to system memory)
4.  Crashes and burns

## Supported FFmpeg Versions

* HW accel is supported from FFmpeg version 3.2 (3.3 for nVidia drivers)
* HW accel was removed for nVidia drivers in Ubuntu for FFmpeg 4+

**Notice:** The FFmpeg versions of Ubuntu and PPAs for Ubuntu show the
same behaviour. FFmpeg 3 has working nVidia hardware acceleration while
FFmpeg 4+ has no support for nVidia hardware acceleration
included.

## OpenShot Settings

The following settings are use by libopenshot to enable, disable, and control
the various hardware acceleration features.

```{cpp}
/// Use video codec for faster video decoding (if supported)
int HARDWARE_DECODER = 0;

/* 0 - No acceleration
   1 - Linux VA-API
   2 - nVidia NVDEC
   3 - Windows D3D9
   4 - Windows D3D11
   5 - MacOS / VideoToolBox
   6 - Linux VDPAU
   7 - Intel QSV */

/// Number of threads of OpenMP
int OMP_THREADS = 12;

/// Number of threads that FFmpeg uses
int FF_THREADS = 8;

/// Maximum rows that hardware decode can handle
int DE_LIMIT_HEIGHT_MAX = 1100;

/// Maximum columns that hardware decode can handle
int DE_LIMIT_WIDTH_MAX = 1950;

/// Which GPU to use to decode (0 is the first, LINUX ONLY)
int HW_DE_DEVICE_SET = 0;

/// Which GPU to use to encode (0 is the first, LINUX ONLY)
int HW_EN_DEVICE_SET = 0;
```

## Libva / VA-API (Video Acceleration API)

The correct version of libva is needed (libva in Ubuntu 16.04 or libva2
in Ubuntu 18.04) for the AppImage to work with hardware acceleration.
An AppImage that works on both systems (supporting libva and libva2),
might be possible when no libva is included in the AppImage.

*  vaapi is working for intel and AMD
*  vaapi is working for decode only for nouveau
*  nVidia driver is working for export only

## AMD Graphics Cards (RadeonOpenCompute/ROCm)

Decoding and encoding on the (AMD) GPU is possible with the default drivers.
On systems where ROCm is installed and run a future use for GPU acceleration
of effects could be implemented (contributions welcome).

## Multiple Graphics Cards

If the computer has multiple graphics cards installed, you can choose which
should be used by libopenshot. Also, you can optionally use one card for
decoding and the other for encoding (if both cards support acceleration).
This is currently only supported on Linux, due to the device name FFmpeg
expects (i.e. **/dev/dri/render128**). Contributions welcome if anyone can
determine what string format to pass for Windows and Mac.

## Help Us Improve Hardware Support

This information might be wrong, and we would love to continue improving
our support for hardware acceleration in OpenShot. Please help us update
this document if you find an error or discover new and/or useful information.

**FFmpeg 4 + nVidia** The manual at:
https://www.tal.org/tutorials/ffmpeg_nvidia_encode
works pretty well. We could compile and install a version of FFmpeg 4.1.3
on Mint 19.1 that supports the GPU on nVidia cards. A version of openshot
with hardware support using these libraries could use the nVidia GPU.

**BUG:** Hardware supported decoding still has some bugs (as you can see from
the chart above). Also, the speed gains with decoding are not as great
as with encoding. Currently, if hardware decoding fails, there is no
fallback (you either get green frames or an "invalid file" error in OpenShot).
This needs to be improved to successfully fall-back to software decoding.

**Needed:**
  * A way to get options and limits of the GPU, such as
 supported dimensions (width and height).
  *  A way to list the actual Graphic Cards available to FFmpeg (for the
  user to choose which card for decoding and encoding, as opposed
  to "Graphics Card X")

**Further improvement:** Right now the frame can be decoded on the GPU, but the
frame is then copied to CPU memory for modifications. It is then copied back to
GPU memory for encoding. Using the GPU for both decoding and modifications
will make it possible to do away with these two copies. A possible solution would
be to use Vulkan compute which would be available on Linux and Windows natively
and on MacOS via MoltenVK.

## Credit

A big thanks to Peter M (https://github.com/eisneinechse) for all his work
on integrating hardware acceleration into libopenshot! The community thanks
you for this major contribution!
# Building libopenshot for Linux

## Getting Started

The best way to get started with libopenshot, is to learn about our build system, obtain all the source code, 
install a development IDE and tools, and better understand our dependencies. So, please read through the 
following sections, and follow the instructions. And keep in mind, that your computer is likely different 
than the one used when writing these instructions. Your file paths and versions of applications might be 
slightly different, so keep an eye out for subtle file path differences in the commands you type.

## Build Tools

CMake is the backbone of our build system.  It is a cross-platform build system, which checks for 
dependencies, locates header files and libraries, generates makefiles, and supports the cross-platform 
compiling of libopenshot and libopenshot-audio.  CMake uses an out-of-source build concept, where 
all temporary build files, such as makefiles, object files, and even the final binaries, are created 
outside of the source code folder, inside a /build/ sub-folder.  This prevents the build process 
from cluttering up the source code.  These instructions have only been tested with the GNU compiler 
(including MSYS2/MinGW for Windows).

## Dependencies

The following libraries are required to build libopenshot.  Instructions on how to install these 
dependencies vary for each operating system.  Libraries and Executables have been labeled in the 
list below to help distinguish between them.

### FFmpeg (libavformat, libavcodec, libavutil, libavdevice, libavresample, libswscale)
  * http://www.ffmpeg.org/ `(Library)`
  * This library is used to decode and encode video, audio, and image files.  It is also used to obtain information about media files, such as frame rate, sample rate, aspect ratio, and other common attributes.

### ImageMagick++ (libMagick++, libMagickWand, libMagickCore)
  * http://www.imagemagick.org/script/magick++.php `(Library)`
  * This library is **optional**, and used to decode and encode images.

### OpenShot Audio Library (libopenshot-audio)
  * https://github.com/OpenShot/libopenshot-audio/ `(Library)`
  * This library is used to mix, resample, host plug-ins, and play audio. It is based on the JUCE project, which is an outstanding audio library used by many different applications

### Qt 5 (libqt5)
  * http://www.qt.io/qt5/ `(Library)`
  * Qt5 is used to display video, store image data, composite images, apply image effects, and many other utility functions, such as file system manipulation, high resolution timers, etc...

### CMake (cmake)
  * http://www.cmake.org/ `(Executable)`
  * This executable is used to automate the generation of Makefiles, check for dependencies, and is the backbone of libopenshot’s cross-platform build process.

### SWIG (swig)
  * http://www.swig.org/ `(Executable)`
  * This executable is used to generate the Python and Ruby bindings for libopenshot. It is a simple and powerful wrapper for C++ libraries, and supports many languages.

### Python 3 (libpython)
  * http://www.python.org/ `(Executable and Library)`
  * This library is used by swig to create the Python (version 3+) bindings for libopenshot. This is also the official language used by OpenShot Video Editor (a graphical interface to libopenshot).

### Doxygen (doxygen)
  * http://www.stack.nl/~dimitri/doxygen/ `(Executable)`
  * This executable is used to auto-generate the documentation used by libopenshot.

### UnitTest++ (libunittest++)
  * https://github.com/unittest-cpp/ `(Library)`
  * This library is used to execute unit tests for libopenshot.  It contains many macros used to keep our unit testing code very clean and simple.

### ZeroMQ (libzmq)
  * http://zeromq.org/ `(Library)`
  * This library is used to communicate between libopenshot and other applications (publisher / subscriber). Primarily used to send debug data from libopenshot.

### OpenMP (-fopenmp)
  * http://openmp.org/wp/ `(Compiler Flag)`
  * If your compiler supports this flag (GCC, Clang, and most other compilers), it provides libopenshot with easy methods of using parallel programming techniques to improve performance and take advantage of multi-core processors.


## CMake Flags (Optional)
There are many different build flags that can be passed to cmake to adjust how libopenshot is 
compiled. Some of these flags might be required when compiling on certain OSes, just depending 
on how your build environment is setup. To add a build flag, follow this general syntax: 
`cmake -DMAGICKCORE_HDRI_ENABLE=1 -DENABLE_TESTS=1 ../`

* MAGICKCORE_HDRI_ENABLE (default 0)
* MAGICKCORE_QUANTUM_DEPTH (default 0)
* OPENSHOT_IMAGEMAGICK_COMPATIBILITY (default 0)
* DISABLE_TESTS (default 0)
* CMAKE_PREFIX_PATH (`/location/to/missing/library/`)
* PYTHON_INCLUDE_DIR (`/location/to/python/include/`)
* PYTHON_LIBRARY (`/location/to/python/lib.a`)
* PYTHON_FRAMEWORKS (`/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/`)
* CMAKE_CXX_COMPILER (`/location/to/mingw/g++`)
* CMAKE_C_COMPILER (`/location/to/mingw/gcc`)

## Obtaining Source Code

The first step in installing libopenshot is to obtain the most recent source code. The source code is 
available on [GitHub](https://github.com/OpenShot/libopenshot). Use the following command 
to obtain the latest libopenshot source code.

```
git clone https://github.com/OpenShot/libopenshot.git
git clone https://github.com/OpenShot/libopenshot-audio.git
```

## Folder Structure (libopenshot)

The source code is divided up into the following folders.

### build/
   * This folder needs to be manually created, and is used by cmake to store the temporary build files, such as makefiles, as well as the final binaries (library and test executables).

### cmake/
   * This folder contains custom modules not included by default in cmake, used to find dependency libraries and headers and determine if these libraries are installed.

### doc/
   * This folder contains documentation and related files, such as logos and images required by the doxygen auto-generated documentation.

### include/
   * This folder contains all headers (*.h) used by libopenshot.

### src/
   * This folder contains all source code (*.cpp) used by libopenshot.

### tests/
   * This folder contains all unit test code.  Each class has it’s own test file (*.cpp), and uses UnitTest++ macros to keep the test code simple and manageable.

### thirdparty/
   * This folder contains code not written by the OpenShot team. For example, jsoncpp, an open-source JSON parser.

## Install Dependencies

In order to actually compile libopenshot, we need to install some dependencies on your system. The easiest 
way to accomplish this is with our Daily PPA. A PPA is an unofficial Ubuntu repository, which has our 
software packages available to download and install.

```
   sudo add-apt-repository ppa:openshot.developers/libopenshot-daily
   sudo apt-get update
   sudo apt-get install openshot-qt \
                        cmake \
                        libx11-dev \
                        libasound2-dev \
                        libavcodec-dev \
                        libavdevice-dev \
                        libavfilter-dev \
                        libavformat-dev \
                        libavresample-dev \
                        libavutil-dev \
                        libfdk-aac-dev \
                        libfreetype6-dev \
                        libjsoncpp-dev \
                        libmagick++-dev \
                        libopenshot-audio-dev \
                        libswscale-dev \
                        libunittest++-dev \
                        libxcursor-dev \
                        libxinerama-dev \
                        libxrandr-dev \
                        libzmq3-dev \
                        pkg-config \
                        python3-dev \
                        qtbase5-dev \
                        qtmultimedia5-dev \
                        swig
```

## Linux Build Instructions (libopenshot-audio)
To compile libopenshot-audio, we need to go through a few additional steps to manually build and 
install it. Launch a terminal and enter:

```
cd [libopenshot-audio repo folder]
mkdir build
cd build
cmake ../
make
make install
./src/openshot-audio-test-sound  (This should play a test sound)
```

## Linux Build Instructions (libopenshot)
Run the following commands to compile libopenshot:

```
cd [libopenshot repo directory]
mkdir -p build
cd build
cmake ../
make
```

If you are missing any dependencies for libopenshot, you might receive error messages at this point. 
Just install the missing packages (usually with a -dev suffix), and run the above commands again. 
Repeat until no error messages are displayed, and the build process completes. Also, if you manually
install Qt 5, you might need to specify the location for cmake:

```
cmake -DCMAKE_PREFIX_PATH=/qt5_path/qt5/5.2.0/ ../
```

To run all unit tests (and verify everything is working correctly), launch a terminal, and enter:

```
make test
```

To auto-generate documentation for libopenshot, launch a terminal, and enter:

```
make doc
```

This will use doxygen to generate a folder of HTML files, with all classes and methods documented. The 
folder is located at **build/doc/html/**. Once libopenshot has been successfully built, we need to 
install it (i.e. copy it to the correct folder, so other libraries can find it).

```
make install
```

This will copy the binary files to /usr/local/lib/, and the header files to /usr/local/include/openshot/... 
This is where other projects will look for the libopenshot files when building. Python 3 bindings are 
also installed at this point. let's verify the python bindings work:

```
python3
>>> import openshot
```

If no errors are displayed, you have successfully compiled and installed libopenshot on your system. 
Congratulations and be sure to read our wiki on [Becoming an OpenShot Developer](https://github.com/OpenShot/openshot-qt/wiki/Become-a-Developer)! 
Welcome to the OpenShot developer community! We look forward to meeting you!
# Building libopenshot for MacOS

## Getting Started

The best way to get started with libopenshot, is to learn about our build system, obtain all the source code, 
install a development IDE and tools, and better understand our dependencies. So, please read through the 
following sections, and follow the instructions. And keep in mind, that your computer is likely different 
than the one used when writing these instructions. Your file paths and versions of applications might be 
slightly different, so keep an eye out for subtle file path differences in the commands you type.

## Build Tools

CMake is the backbone of our build system.  It is a cross-platform build system, which checks for 
dependencies, locates header files and libraries, generates makefiles, and supports the cross-platform 
compiling of libopenshot and libopenshot-audio.  CMake uses an out-of-source build concept, where 
all temporary build files, such as makefiles, object files, and even the final binaries, are created 
outside of the source code folder, inside a /build/ sub-folder.  This prevents the build process 
from cluttering up the source code.  These instructions have only been tested with the GNU compiler 
(including MSYS2/MinGW for Windows).

## Dependencies

The following libraries are required to build libopenshot.  Instructions on how to install these 
dependencies vary for each operating system.  Libraries and Executables have been labeled in the 
list below to help distinguish between them.

### FFmpeg (libavformat, libavcodec, libavutil, libavdevice, libavresample, libswscale)
  * http://www.ffmpeg.org/ `(Library)`
  * This library is used to decode and encode video, audio, and image files.  It is also used to obtain information about media files, such as frame rate, sample rate, aspect ratio, and other common attributes.

### ImageMagick++ (libMagick++, libMagickWand, libMagickCore)
  * http://www.imagemagick.org/script/magick++.php `(Library)`
  * This library is **optional**, and used to decode and encode images.

### OpenShot Audio Library (libopenshot-audio)
  * https://github.com/OpenShot/libopenshot-audio/ `(Library)`
  * This library is used to mix, resample, host plug-ins, and play audio. It is based on the JUCE project, which is an outstanding audio library used by many different applications

### Qt 5 (libqt5)
  * http://www.qt.io/qt5/ `(Library)`
  * Qt5 is used to display video, store image data, composite images, apply image effects, and many other utility functions, such as file system manipulation, high resolution timers, etc...

### CMake (cmake)
  * http://www.cmake.org/ `(Executable)`
  * This executable is used to automate the generation of Makefiles, check for dependencies, and is the backbone of libopenshot’s cross-platform build process.

### SWIG (swig)
  * http://www.swig.org/ `(Executable)`
  * This executable is used to generate the Python and Ruby bindings for libopenshot. It is a simple and powerful wrapper for C++ libraries, and supports many languages.

### Python 3 (libpython)
  * http://www.python.org/ `(Executable and Library)`
  * This library is used by swig to create the Python (version 3+) bindings for libopenshot. This is also the official language used by OpenShot Video Editor (a graphical interface to libopenshot).

### Doxygen (doxygen)
  * http://www.stack.nl/~dimitri/doxygen/ `(Executable)`
  * This executable is used to auto-generate the documentation used by libopenshot.

### UnitTest++ (libunittest++)
  * https://github.com/unittest-cpp/ `(Library)`
  * This library is used to execute unit tests for libopenshot.  It contains many macros used to keep our unit testing code very clean and simple.

### ZeroMQ (libzmq)
  * http://zeromq.org/ `(Library)`
  * This library is used to communicate between libopenshot and other applications (publisher / subscriber). Primarily used to send debug data from libopenshot.

### OpenMP (-fopenmp)
  * http://openmp.org/wp/ `(Compiler Flag)`
  * If your compiler supports this flag (GCC, Clang, and most other compilers), it provides libopenshot with easy methods of using parallel programming techniques to improve performance and take advantage of multi-core processors.

## CMake Flags (Optional)
There are many different build flags that can be passed to cmake to adjust how libopenshot is compiled. 
Some of these flags might be required when compiling on certain OSes, just depending on how your build 
environment is setup. To add a build flag, follow this general syntax: 
`cmake -DMAGICKCORE_HDRI_ENABLE=1 -DENABLE_TESTS=1 ../`

* MAGICKCORE_HDRI_ENABLE (default 0)
* MAGICKCORE_QUANTUM_DEPTH (default 0)
* OPENSHOT_IMAGEMAGICK_COMPATIBILITY (default 0)
* DISABLE_TESTS (default 0)
* CMAKE_PREFIX_PATH (`/location/to/missing/library/`)
* PYTHON_INCLUDE_DIR (`/location/to/python/include/`)
* PYTHON_LIBRARY (`/location/to/python/lib.a`)
* PYTHON_FRAMEWORKS (`/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/`)
* CMAKE_CXX_COMPILER (`/location/to/mingw/g++`)
* CMAKE_C_COMPILER (`/location/to/mingw/gcc`)

## Obtaining Source Code

The first step in installing libopenshot is to obtain the most recent source code. The source code 
is available on [GitHub](https://github.com/OpenShot/libopenshot). Use the following command to 
obtain the latest libopenshot source code.

```
git clone https://github.com/OpenShot/libopenshot.git
git clone https://github.com/OpenShot/libopenshot-audio.git
```

## Folder Structure (libopenshot)

The source code is divided up into the following folders.

### build/
   * This folder needs to be manually created, and is used by cmake to store the temporary build files, such as makefiles, as well as the final binaries (library and test executables).

### cmake/
   * This folder contains custom modules not included by default in cmake, used to find dependency libraries and headers and determine if these libraries are installed.

### doc/
   * This folder contains documentation and related files, such as logos and images required by the doxygen auto-generated documentation.

### include/
   * This folder contains all headers (*.h) used by libopenshot.

### src/
   * This folder contains all source code (*.cpp) used by libopenshot.

### tests/
   * This folder contains all unit test code.  Each class has it’s own test file (*.cpp), and uses UnitTest++ macros to keep the test code simple and manageable.

### thirdparty/
   * This folder contains code not written by the OpenShot team. For example, jsoncpp, an open-source JSON parser.

## Install Dependencies

In order to actually compile libopenshot and libopenshot-audio, we need to install some dependencies on 
your system. Most packages needed by libopenshot can be installed easily with Homebrew. However, first 
install Xcode with the following options ("UNIX Development", "System Tools", "Command Line Tools", or 
"Command Line Support"). Be sure to refresh your list of Homebrew packages with the “brew update” command.

**NOTE:** Homebrew seems to work much better for most users (compared to MacPorts), so I am going to 
focus on brew for this guide.

Install the following packages using the Homebrew package installer (http://brew.sh/). Pay close attention 
to any warnings or errors during these brew installs. NOTE: You might have some conflicting libraries in 
your /usr/local/ folders, so follow the directions from brew if these are detected.

```
brew install gcc48 --enable-all-languages
brew install ffmpeg
brew install librsvg
brew install swig
brew install doxygen
brew install unittest-cpp --cc=gcc-4.8. You must specify the c++ compiler with the --cc flag to be 4.7 or 4.8.
brew install qt5
brew install cmake
brew install zeromq
```

## Mac Build Instructions (libopenshot-audio)
Since libopenshot-audio is not available in a Homebrew or MacPorts package, we need to go through a 
few additional steps to manually build and install it. Launch a terminal and enter:

```
cd [libopenshot-audio repo folder]
mkdir build
cd build
cmake -d -G "Unix Makefiles" -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_COMPILER=clang ../   (CLang must be used due to GNU incompatible Objective-C code in some of the Apple frameworks)
make
make install
./src/openshot-audio-test-sound  (This should play a test sound)
```

## Mac Build Instructions (libopenshot)
Run the following commands to build libopenshot:

```
$ cd [libopenshot repo folder]
$ mkdir build
$ cd build
$ cmake -G "Unix Makefiles"  -DCMAKE_CXX_COMPILER=/usr/local/opt/gcc48/bin/g++-4.8 -DCMAKE_C_COMPILER=/usr/local/opt/gcc48/bin/gcc-4.8 -DCMAKE_PREFIX_PATH=/usr/local/Cellar/qt5/5.4.2/ -DPYTHON_INCLUDE_DIR=/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/Versions/3.3/include/python3.3m/ -DPYTHON_LIBRARY=/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/Versions/3.3/lib/libpython3.3.dylib -DPython_FRAMEWORKS=/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/ ../ -D"CMAKE_BUILD_TYPE:STRING=Debug"
```

The extra arguments on the cmake command make sure the compiler will be gcc4.8 and that cmake 
knows where to look for the Qt header files and Python library. Double check these file paths, 
as yours will likely be different.

```
make
```

If you are missing any dependencies for libopenshot, you will receive error messages at this point. 
Just install the missing dependencies, and run the above commands again. Repeat until no error 
messages are displayed and the build process completes.

Also, if you are having trouble building, please see the CMake Flags section above, as it might 
provide a solution for finding a missing folder path, missing Python 3 library, etc...

To run all unit tests (and verify everything is working correctly), launch a terminal, and enter:

```
make test
```

To auto-generate the documentation for libopenshot, launch a terminal, and enter:

```
make doc
```

This will use doxygen to generate a folder of HTML files, with all classes and methods documented. 
The folder is located at build/doc/html/. Once libopenshot has been successfully built, we need 
to install it (i.e. copy it to the correct folder, so other libraries can find it).

```
make install
```

This should copy the binary files to /usr/local/lib/, and the header files to /usr/local/include/openshot/... 
This is where other projects will look for the libopenshot files when building. Python 3 bindings are 
also installed at this point. let's verify the python bindings work:

```
python3 (or python)
>>> import openshot
```

If no errors are displayed, you have successfully compiled and installed libopenshot on your 
system. Congratulations and be sure to read our wiki on [Becoming an OpenShot Developer](https://github.com/OpenShot/openshot-qt/wiki/Become-a-Developer)! 
Welcome to the OpenShot developer community! We look forward to meeting you!
# Building libopenshot for Windows

## Getting Started

The best way to get started with libopenshot, is to learn about our build system, obtain all the 
source code, install a development IDE and tools, and better understand our dependencies. So, 
please read through the following sections, and follow the instructions. And keep in mind, 
that your computer is likely different than the one used when writing these instructions. 
Your file paths and versions of applications might be slightly different, so keep an eye out 
for subtle file path differences in the commands you type.

## Build Tools

CMake is the backbone of our build system.  It is a cross-platform build system, which 
checks for dependencies, locates header files and libraries, generates makefiles, and 
supports the cross-platform compiling of libopenshot and libopenshot-audio.  CMake uses 
an out-of-source build concept, where all temporary build files, such as makefiles, 
object files, and even the final binaries, are created outside of the source code 
folder, inside a /build/ sub-folder.  This prevents the build process from cluttering 
up the source code.  These instructions have only been tested with the GNU compiler 
(including MSYS2/MinGW for Windows).

## Dependencies

The following libraries are required to build libopenshot.  Instructions on how to 
install these dependencies vary for each operating system.  Libraries and Executables 
have been labeled in the list below to help distinguish between them.

### FFmpeg (libavformat, libavcodec, libavutil, libavdevice, libavresample, libswscale)
  * http://www.ffmpeg.org/ `(Library)`
  * This library is used to decode and encode video, audio, and image files.  It is also used to obtain information about media files, such as frame rate, sample rate, aspect ratio, and other common attributes.

### ImageMagick++ (libMagick++, libMagickWand, libMagickCore)
  * http://www.imagemagick.org/script/magick++.php `(Library)`
  * This library is **optional**, and used to decode and encode images.

### OpenShot Audio Library (libopenshot-audio)
  * https://github.com/OpenShot/libopenshot-audio/ `(Library)`
  * This library is used to mix, resample, host plug-ins, and play audio. It is based on the JUCE project, which is an outstanding audio library used by many different applications

### Qt 5 (libqt5)
  * http://www.qt.io/qt5/ `(Library)`
  * Qt5 is used to display video, store image data, composite images, apply image effects, and many other utility functions, such as file system manipulation, high resolution timers, etc...

### CMake (cmake)
  * http://www.cmake.org/ `(Executable)`
  * This executable is used to automate the generation of Makefiles, check for dependencies, and is the backbone of libopenshot’s cross-platform build process.

### SWIG (swig)
  * http://www.swig.org/ `(Executable)`
  * This executable is used to generate the Python and Ruby bindings for libopenshot. It is a simple and powerful wrapper for C++ libraries, and supports many languages.

### Python 3 (libpython)
  * http://www.python.org/ `(Executable and Library)`
  * This library is used by swig to create the Python (version 3+) bindings for libopenshot. This is also the official language used by OpenShot Video Editor (a graphical interface to libopenshot).

### Doxygen (doxygen)
  * http://www.stack.nl/~dimitri/doxygen/ `(Executable)`
  * This executable is used to auto-generate the documentation used by libopenshot.

### UnitTest++ (libunittest++)
  * https://github.com/unittest-cpp/ `(Library)`
  * This library is used to execute unit tests for libopenshot.  It contains many macros used to keep our unit testing code very clean and simple.

### ZeroMQ (libzmq)
  * http://zeromq.org/ `(Library)`
  * This library is used to communicate between libopenshot and other applications (publisher / subscriber). Primarily used to send debug data from libopenshot.

### OpenMP (-fopenmp)
  * http://openmp.org/wp/ `(Compiler Flag)`
  * If your compiler supports this flag (GCC, Clang, and most other compilers), it provides libopenshot with easy methods of using parallel programming techniques to improve performance and take advantage of multi-core processors.

## CMake Flags (Optional)
There are many different build flags that can be passed to cmake to adjust how libopenshot 
is compiled. Some of these flags might be required when compiling on certain OSes, just 
depending on how your build environment is setup. To add a build flag, follow this general 
syntax: `cmake -DMAGICKCORE_HDRI_ENABLE=1 -DENABLE_TESTS=1 ../`

* MAGICKCORE_HDRI_ENABLE (default 0)
* MAGICKCORE_QUANTUM_DEPTH (default 0)
* OPENSHOT_IMAGEMAGICK_COMPATIBILITY (default 0)
* DISABLE_TESTS (default 0)
* CMAKE_PREFIX_PATH (`/location/to/missing/library/`)
* PYTHON_INCLUDE_DIR (`/location/to/python/include/`)
* PYTHON_LIBRARY (`/location/to/python/lib.a`)
* PYTHON_FRAMEWORKS (`/usr/local/Cellar/python3/3.3.2/Frameworks/Python.framework/`)
* CMAKE_CXX_COMPILER (`/location/to/mingw/g++`)
* CMAKE_C_COMPILER (`/location/to/mingw/gcc`)

## Environment Variables

Many environment variables will need to be set during this Windows installation guide. 
The command line will need to be closed and re-launched after any changes to your environment 
variables. Also, dependency libraries will not be found during linking or execution without 
being found in the PATH environment variable. So, if you get errors related to missing 
commands or libraries, double check the PATH variable.

The following environment variables need to be added to your “System Variables”.  Be sure to 
check each folder path for accuracy, as your paths will likely be different than this list.

### Example Variables

* DL_DIR (`C:\libdl`)
* DXSDK_DIR (`C:\Program Files\Microsoft DirectX SDK (June 2010)\`)
* FFMPEGDIR (`C:\ffmpeg-git-95f163b-win32-dev`)
* FREETYPE_DIR (`C:\Program Files\GnuWin32`)
* HOME (`C:\msys\1.0\home`)
* LIBOPENSHOT_AUDIO_DIR (`C:\Program Files\libopenshot-audio`)
* QTDIR (`C:\qt5`)
* SNDFILE_DIR (`C:\Program Files\libsndfile`)
* UNITTEST_DIR (`C:\UnitTest++`)
* ZMQDIR (`C:\msys2\usr\local\`)
* PATH (`The following paths are an example`)
   * `C:\Qt5\bin; C:\Qt5\MinGW\bin\; C:\msys\1.0\local\lib; C:\Program Files\CMake 2.8\bin; C:\UnitTest++\build; C:\libopenshot\build\src; C:\Program Files\doxygen\bin; C:\ffmpeg-git-95f163b-win32-dev\lib; C:\swigwin-2.0.4; C:\Python33; C:\Program Files\Project\lib; C:\msys2\usr\local\`





## Obtaining Source Code

The first step in installing libopenshot is to obtain the most recent source code. The source code 
is available on [GitHub](https://github.com/OpenShot/libopenshot). Use the following command to 
obtain the latest libopenshot source code.

```
git clone https://github.com/OpenShot/libopenshot.git
git clone https://github.com/OpenShot/libopenshot-audio.git
```

## Folder Structure (libopenshot)

The source code is divided up into the following folders.

### build/
   * This folder needs to be manually created, and is used by cmake to store the temporary 
   build files, such as makefiles, as well as the final binaries (library and test executables).

### cmake/
   * This folder contains custom modules not included by default in cmake, used to find 
   dependency libraries and headers and determine if these libraries are installed.

### doc/
   * This folder contains documentation and related files, such as logos and images 
   required by the doxygen auto-generated documentation.

### include/
   * This folder contains all headers (*.h) used by libopenshot.

### src/
   * This folder contains all source code (*.cpp) used by libopenshot.

### tests/
   * This folder contains all unit test code.  Each class has it’s own test file (*.cpp), and 
   uses UnitTest++ macros to keep the test code simple and manageable.

### thirdparty/
   * This folder contains code not written by the OpenShot team. For example, jsoncpp, an 
   open-source JSON parser.

## Install MSYS2 Dependencies

Most Windows dependencies needed for libopenshot-audio, libopenshot, and openshot-qt
can be installed easily with MSYS2 and the pacman package manager. Follow these
directions to setup a Windows build environment for OpenShot.

1) Install MSYS2: http://www.msys2.org/

2) Run MSYS2 command prompt (for example: `C:\msys64\msys2_shell.cmd`)

3) Append PATH (so MSYS2 can find executables and libraries):

```
PATH=$PATH:/c/msys64/mingw64/bin:/c/msys64/mingw64/lib     (64-bit PATH)
  or 
PATH=$PATH:/c/msys32/mingw32/bin:/c/msys32/mingw32/lib     (32-bit PATH)
```

4) Update and upgrade all packages

```
pacman -Syu
```

5a) Install the following packages (**64-Bit**)

```
pacman -S --needed base-devel mingw-w64-x86_64-toolchain
pacman -S mingw64/mingw-w64-x86_64-ffmpeg
pacman -S mingw64/mingw-w64-x86_64-python3-pyqt5
pacman -S mingw64/mingw-w64-x86_64-swig
pacman -S mingw64/mingw-w64-x86_64-cmake
pacman -S mingw64/mingw-w64-x86_64-doxygen
pacman -S mingw64/mingw-w64-x86_64-python3-pip
pacman -S mingw32/mingw-w64-i686-zeromq
pacman -S mingw64/mingw-w64-x86_64-python3-pyzmq
pacman -S mingw64/mingw-w64-x86_64-python3-cx_Freeze
pacman -S git

# Install ImageMagick if needed (OPTIONAL and NOT NEEDED)
pacman -S mingw64/mingw-w64-x86_64-imagemagick
```
  
5b) **Or** Install the following packages (**32-Bit**)

```
pacman -S --needed base-devel mingw32/mingw-w64-i686-toolchain
pacman -S mingw32/mingw-w64-i686-ffmpeg
pacman -S mingw32/mingw-w64-i686-python3-pyqt5
pacman -S mingw32/mingw-w64-i686-swig
pacman -S mingw32/mingw-w64-i686-cmake
pacman -S mingw32/mingw-w64-i686-doxygen
pacman -S mingw32/mingw-w64-i686-python3-pip
pacman -S mingw32/mingw-w64-i686-zeromq
pacman -S mingw32/mingw-w64-i686-python3-pyzmq
pacman -S mingw32/mingw-w64-i686-python3-cx_Freeze
pacman -S git

# Install ImageMagick if needed (OPTIONAL and NOT NEEDED)
pacman -S mingw32/mingw-w32-x86_32-imagemagick
```

6) Install Python PIP Dependencies
 
```
pip3 install httplib2
pip3 install slacker
pip3 install tinys3
pip3 install github3.py
pip3 install requests
```  

7) Download Unittest++ (https://github.com/unittest-cpp/unittest-cpp) into /MSYS2/[USER]/unittest-cpp-master/

``` 
cmake -G "MSYS Makefiles" ../ -DCMAKE_MAKE_PROGRAM=mingw32-make -DCMAKE_INSTALL_PREFIX:PATH=/usr
mingw32-make install
```

8) ZMQ++ Header (This might not be needed anymore)
  NOTE: Download and copy zmq.hpp into the /c/msys64/mingw64/include/ folder

## Manual Dependencies

### DLfcn
   * https://github.com/dlfcn-win32/dlfcn-win32
   * Download and Extract the Win32 Static (.tar.bz2) archive to a local folder: `C:\libdl\`
   * Create an environment variable called DL_DIR and set the value to `C:\libdl\`. This environment variable will be used by CMake to find the binary and header file.

### DirectX SDK / Windows SDK
   * Windows 7: (DirectX SDK) http://www.microsoft.com/download/en/details.aspx?displaylang=en&id=6812
   * Windows 8: (Windows SDK)
   * https://msdn.microsoft.com/en-us/windows/desktop/aa904949
   * Download and Install the SDK Setup program.  This is needed for the JUCE library to play audio on Windows.
Create an environment variable called DXSDK_DIR and set the value to `C:\Program Files\Microsoft DirectX SDK (June 2010)\` (your path might be different). This environment variable will be used by CMake to find the binaries and header files.

### libSndFile
   * http://www.mega-nerd.com/libsndfile/#Download
   * Download and Install the Win32 Setup program.
   * Create an environment variable called SNDFILE_DIR and set the value to `C:\Program Files\libsndfile`. This environment variable will be used by CMake to find the binary and header files.

### libzmq
   * http://zeromq.org/intro:get-the-software
   * Download source code (zip)
   * Follow their instructions, and build with mingw
   * Create an environment variable called ZMQDIR and set the value to `C:\libzmq\build\` (the location of the compiled version). This environment variable will be used by CMake to find the binary and header files.

## Windows Build Instructions (libopenshot-audio)
In order to compile libopenshot-audio, launch a command prompt and enter the following commands. This does not require the MSYS2 prompt, but it should work in both the Windows command prompt and the MSYS2 prompt.

```
cd [libopenshot-audio repo folder]
mkdir build
cd build
cmake -G “MinGW Makefiles” ../
mingw32-make
mingw32-make install
openshot-audio-test-sound  (This should play a test sound)
```

## Windows Build Instructions (libopenshot)
Run the following commands to build libopenshot:

```
cd [libopenshot repo folder]
mkdir build
cd build
cmake -G "MinGW Makefiles" -DPYTHON_INCLUDE_DIR="C:/Python34/include/" -DPYTHON_LIBRARY="C:/Python34/libs/libpython34.a" ../
mingw32-make
```

If you are missing any dependencies for libopenshot, you will receive error messages at this point. 
Just install the missing dependencies, and run the above commands again. Repeat until no error 
messages are displayed and the build process completes.

Also, if you are having trouble building, please see the CMake Flags section above, as 
it might provide a solution for finding a missing folder path, missing Python 3 library, etc...

To run all unit tests (and verify everything is working correctly), launch a terminal, and enter:

```
mingw32-make test
```

To auto-generate the documentation for libopenshot, launch a terminal, and enter:

```
mingw32-make doc
```

This will use doxygen to generate a folder of HTML files, with all classes and methods 
documented. The folder is located at build/doc/html/. Once libopenshot has been successfully 
built, we need to install it (i.e. copy it to the correct folder, so other libraries can find it).

```
mingw32-make install
```

This should copy the binary files to `C:\Program Files\openshot\lib\`, and the header 
files to `C:\Program Files\openshot\include\...`  This is where other projects will 
look for the libopenshot files when building.. Python 3 bindings are also installed 
at this point. let's verify the python bindings work:

```
python3
>>> import openshot
```

If no errors are displayed, you have successfully compiled and installed libopenshot on 
your system. Congratulations and be sure to read our wiki on [Becoming an OpenShot Developer](https://github.com/OpenShot/openshot-qt/wiki/Become-a-Developer)! 
Welcome to the OpenShot developer community! We look forward to meeting you!
####################### CMakeLists.txt (libopenshot) #########################
# @brief CMake build file for libopenshot (used to generate makefiles)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################

# Collect and display summary of options/dependencies
include(FeatureSummary)

# Automatically process Qt classes with meta-object compiler
set(CMAKE_AUTOMOC True)

################ WINDOWS ##################
# Set some compiler options for Windows
# required for libopenshot-audio headers
IF (WIN32)
	add_definitions( -DIGNORE_JUCE_HYPOT=1 )
	SET(CMAKE_CXX_FLAGS " ${CMAKE_CXX_FLAGS} -include cmath")
ENDIF(WIN32)
IF (APPLE)
	# If you still get errors compiling with GCC 4.8, mac headers need to be patched: http://hamelot.co.uk/programming/osx-gcc-dispatch_block_t-has-not-been-declared-invalid-typedef/
	SET_PROPERTY(GLOBAL PROPERTY JUCE_MAC "JUCE_MAC")
	ADD_DEFINITIONS(-DNDEBUG)
	SET(EXTENSION "mm")

	SET(JUCE_PLATFORM_SPECIFIC_DIR build/macosx/platform_specific_code)
	SET(JUCE_PLATFORM_SPECIFIC_LIBRARIES "-framework Carbon -framework Cocoa -framework CoreFoundation -framework CoreAudio -framework CoreMidi -framework IOKit -framework AGL -framework AudioToolbox -framework QuartzCore -lobjc -framework Accelerate")
ENDIF(APPLE)

################ IMAGE MAGICK ##################
# Set the Quantum Depth that ImageMagick was built with (default to 16 bits)
IF (MAGICKCORE_QUANTUM_DEPTH)
	add_definitions( -DMAGICKCORE_QUANTUM_DEPTH=${MAGICKCORE_QUANTUM_DEPTH} )
ELSE (MAGICKCORE_QUANTUM_DEPTH)
	add_definitions( -DMAGICKCORE_QUANTUM_DEPTH=16 )
ENDIF (MAGICKCORE_QUANTUM_DEPTH)
IF (MAGICKCORE_HDRI_ENABLE)
	add_definitions( -DMAGICKCORE_HDRI_ENABLE=${MAGICKCORE_HDRI_ENABLE} )
ELSE (MAGICKCORE_HDRI_ENABLE)
	add_definitions( -DMAGICKCORE_HDRI_ENABLE=0 )
ENDIF (MAGICKCORE_HDRI_ENABLE)
IF (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)
	add_definitions( -DOPENSHOT_IMAGEMAGICK_COMPATIBILITY=${OPENSHOT_IMAGEMAGICK_COMPATIBILITY} )
ELSE (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)
	add_definitions( -DOPENSHOT_IMAGEMAGICK_COMPATIBILITY=0 )
ENDIF (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)

# Find the ImageMagick++ library
FIND_PACKAGE(ImageMagick COMPONENTS Magick++ MagickWand MagickCore)
IF (ImageMagick_FOUND)
	# Include ImageMagick++ headers (needed for compile)
	include_directories(${ImageMagick_INCLUDE_DIRS})

	# define a global var (used in the C++)
	add_definitions( -DUSE_IMAGEMAGICK=1 )
	SET(CMAKE_SWIG_FLAGS "-DUSE_IMAGEMAGICK=1")

ENDIF (ImageMagick_FOUND)

################# LIBOPENSHOT-AUDIO ###################
# Find JUCE-based openshot Audio libraries
FIND_PACKAGE(OpenShotAudio 0.1.9 REQUIRED)

# Include Juce headers (needed for compile)
include_directories(${LIBOPENSHOT_AUDIO_INCLUDE_DIRS})

################# BLACKMAGIC DECKLINK ###################
# Find BlackMagic DeckLinkAPI libraries
IF (ENABLE_BLACKMAGIC)
	FIND_PACKAGE(BlackMagic)

	IF (BLACKMAGIC_FOUND)
		# Include Blackmagic headers (needed for compile)
		include_directories(${BLACKMAGIC_INCLUDE_DIR})

		# define a global var (used in the C++)
		add_definitions( -DUSE_BLACKMAGIC=1 )
		SET(CMAKE_SWIG_FLAGS "-DUSE_BLACKMAGIC=1")

	ENDIF (BLACKMAGIC_FOUND)
ENDIF (ENABLE_BLACKMAGIC)

###############  PROFILING  #################
#set(PROFILER "/usr/lib/libprofiler.so.0.3.2")
#set(PROFILER "/usr/lib/libtcmalloc.so.4")

if(CMAKE_VERSION VERSION_LESS 3.3)
  # IWYU wasn't supported internally in 3.2
  set(ENABLE_IWYU FALSE)
endif()

if(ENABLE_IWYU)
	find_program(IWYU_PATH NAMES "iwyu"
		DOC "include-what-you-use source code scanner executable")
	if(IWYU_PATH)
		if(IWYU_OPTS)
			separate_arguments(IWYU_OPTS)
			list(APPEND _iwyu_opts "-Xiwyu" ${IWYU_OPTS})
		endif()
		set(CMAKE_CXX_INCLUDE_WHAT_YOU_USE ${IWYU_PATH} ${_iwyu_opts})
	else()
		set(ENABLE_IWYU FALSE)
	endif()
endif()
add_feature_info("IWYU (include-what-you-use)" ENABLE_IWYU "Scan all source files with 'iwyu'")

# Main library sources
set(OPENSHOT_SOURCES
  AudioBufferSource.cpp
  AudioReaderSource.cpp
  AudioResampler.cpp
  CacheBase.cpp
  CacheDisk.cpp
  CacheMemory.cpp
  ChunkReader.cpp
  ChunkWriter.cpp
  Color.cpp
  Clip.cpp
  ClipBase.cpp
  Coordinate.cpp
  CrashHandler.cpp
  DummyReader.cpp
  ReaderBase.cpp
  RendererBase.cpp
  WriterBase.cpp
  EffectBase.cpp
  EffectInfo.cpp
  FFmpegReader.cpp
  FFmpegWriter.cpp
  Fraction.cpp
  Frame.cpp
  FrameMapper.cpp
  KeyFrame.cpp
  OpenShotVersion.cpp
  ZmqLogger.cpp
  PlayerBase.cpp
  Point.cpp
  Profiles.cpp
  QtHtmlReader.cpp
  QtImageReader.cpp
  QtPlayer.cpp
  QtTextReader.cpp
  Settings.cpp
  Timeline.cpp)

# Video effects
set(EFFECTS_SOURCES
  effects/Bars.cpp
  effects/Blur.cpp
  effects/Brightness.cpp
  effects/ChromaKey.cpp
  effects/ColorShift.cpp
  effects/Crop.cpp
  effects/Deinterlace.cpp
  effects/Hue.cpp
  effects/Mask.cpp
  effects/Negate.cpp
  effects/Pixelate.cpp
  effects/Saturation.cpp
  effects/Shift.cpp
  effects/Wave.cpp)

# Qt video player components
set(QT_PLAYER_SOURCES
  Qt/AudioPlaybackThread.cpp
  Qt/PlayerDemo.cpp
  Qt/PlayerPrivate.cpp
  Qt/VideoCacheThread.cpp
  Qt/VideoPlaybackThread.cpp
  Qt/VideoRenderer.cpp
  Qt/VideoRenderWidget.cpp)


# Get list of headers
file(GLOB_RECURSE headers ${CMAKE_SOURCE_DIR}/include/*.h)

# Disable RPATH
SET(CMAKE_MACOSX_RPATH 0)

############### CREATE LIBRARY #################
# Create shared openshot library
add_library(openshot SHARED)

target_sources(openshot
  PRIVATE
    ${OPENSHOT_SOURCES} ${EFFECTS_SOURCES} ${QT_PLAYER_SOURCES}
  PUBLIC
    ${headers})

# Set SONAME and other library properties
set_target_properties(openshot
		PROPERTIES
		VERSION ${PROJECT_VERSION}
		SOVERSION ${PROJECT_SO_VERSION}
		INSTALL_NAME_DIR "${CMAKE_INSTALL_PREFIX}/lib"
		)

# Add optional ImageMagic-dependent sources
if(ImageMagick_FOUND)
	target_sources(openshot PRIVATE
    ImageReader.cpp
    ImageWriter.cpp
    TextReader.cpp)
endif()

# BlackMagic related files
if(BLACKMAGIC_FOUND)
  target_sources(openshot PRIVATE
    DecklinkInput.cpp
    DecklinkReader.cpp
    DecklinkOutput.cpp
    DecklinkWriter.cpp)
endif()

# Location of our includes, both internally and when installed
target_include_directories(openshot
  PRIVATE
    ${CMAKE_SOURCE_DIR}/include
    ${CMAKE_BINARY_DIR}/include
  PUBLIC
    $<BUILD_INTERFACE:${CMAKE_SOURCE_DIR}/include>
    $<BUILD_INTERFACE:${CMAKE_BINARY_DIR}/include>
    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}/libopenshot>)


################### JSONCPP #####################
# Include jsoncpp headers (needed for JSON parsing)
if (USE_SYSTEM_JSONCPP)
	message(STATUS "Looking for system JsonCpp")
	find_package(JsonCpp)
	if (JSONCPP_FOUND AND NOT TARGET jsoncpp_lib)
		# Create the expected target, for older installs that don't
		add_library(jsoncpp_lib INTERFACE)
		target_include_directories(jsoncpp_lib INTERFACE
			${JSONCPP_INCLUDE_DIRS})
		target_link_libraries(jsoncpp_lib INTERFACE ${JSONCPP_LIBRARY})
	endif ()
endif ()

if (NOT JSONCPP_FOUND AND NOT DISABLE_BUNDLED_JSONCPP)
  message(STATUS "Using embedded JsonCpp (not found or USE_SYSTEM_JSONCPP disabled)")
  if (NOT TARGET jsoncpp_lib)
    add_library(jsoncpp_lib INTERFACE)
    target_include_directories(jsoncpp_lib INTERFACE
      "${PROJECT_SOURCE_DIR}/thirdparty/jsoncpp")
    target_sources(jsoncpp_lib INTERFACE "${PROJECT_SOURCE_DIR}/thirdparty/jsoncpp/jsoncpp.cpp")
    # Because this satisfies the requirement, an installed JsonCpp is optional
    set_package_properties(JsonCpp PROPERTIES TYPE OPTIONAL)
  endif ()
  add_feature_info("JsonCpp (embedded)" TRUE "JsonCpp will be compiled from the bundled sources")
endif ()

if (JSONCPP_FOUND)
  # JsonCpp is actually required, even though we probe for it optionally
  # (This tells feature_summary() to bail if it's not found, later)
  set_package_properties(JsonCpp PROPERTIES TYPE REQUIRED)
endif ()

# If we found any usable JsonCpp, use it. Otherwise, bail.
if (TARGET jsoncpp_lib)
  target_link_libraries(openshot PUBLIC jsoncpp_lib)
endif ()

################# QT5 ###################
# Find QT5 libraries
set(_qt_components Widgets Core Gui Multimedia MultimediaWidgets)
find_package(Qt5 COMPONENTS ${_qt_components} REQUIRED)

foreach(_qt_comp IN LISTS _qt_components)
  if(TARGET Qt5::${_qt_comp})
    target_link_libraries(openshot PUBLIC Qt5::${_qt_comp})
  endif()
endforeach()

################### FFMPEG #####################
# Find FFmpeg libraries (used for video encoding / decoding)
FIND_PACKAGE(FFmpeg REQUIRED COMPONENTS avcodec avdevice avformat avutil swscale)

foreach(ff_comp avcodec avdevice avformat avfilter avutil postproc swscale swresample avresample)
  if(TARGET FFmpeg::${ff_comp})
		target_link_libraries(openshot PUBLIC FFmpeg::${ff_comp})
  endif()
endforeach()

################### Threads ####################
# Threading library -- uses IMPORTED target Threads::Threads (since CMake 3.1)
set(CMAKE_THREAD_PREFER_PTHREAD TRUE)
set(THREADS_PREFER_PTHREAD_FLAG TRUE)
find_package(Threads REQUIRED)
target_link_libraries(openshot PUBLIC Threads::Threads)

################### OPENMP #####################
# Check for OpenMP (used for multi-core processing)

# OpenMP is required by FFmpegReader/Writer
find_package(OpenMP REQUIRED)

if(NOT TARGET OpenMP::OpenMP_CXX)
    # Older CMake versions (< 3.9) don't create find targets.
    add_library(OpenMP_TARGET INTERFACE)
    add_library(OpenMP::OpenMP_CXX ALIAS OpenMP_TARGET)
    target_compile_options(OpenMP_TARGET INTERFACE ${OpenMP_CXX_FLAGS})
    target_link_libraries(OpenMP_TARGET INTERFACE Threads::Threads)
    target_link_libraries(OpenMP_TARGET INTERFACE ${OpenMP_CXX_FLAGS})
endif()

target_link_libraries(openshot PUBLIC OpenMP::OpenMP_CXX)

################### ZEROMQ #####################
# Find ZeroMQ library (used for socket communication & logging)
find_package(ZeroMQ REQUIRED) # Creates libzmq target

# Some platforms package the header-only cppzmq C++ bindings separately,
# others (Ubuntu) bundle them in with libzmq itself
find_package(cppzmq QUIET) # Creates cppzmq target

# Link ZeroMQ library
if (TARGET libzmq)
	target_link_libraries(openshot PUBLIC libzmq)
endif()
# Include cppzmq headers, if not bundled into libzmq
if (TARGET cppzmq)
  target_link_libraries(openshot PUBLIC cppzmq)
endif()

################### RESVG #####################
# Migrate some legacy variable names
if(DEFINED RESVGDIR AND NOT DEFINED RESVG_ROOT)
  set(RESVG_ROOT ${RESVGDIR})
endif()
if(DEFINED ENV{RESVGDIR} AND NOT DEFINED RESVG_ROOT)
  set(RESVG_ROOT $ENV{RESVGDIR})
endif()

# Find resvg library (used for rendering svg files)
FIND_PACKAGE(RESVG)

# Include resvg headers (optional SVG library)
if (TARGET RESVG::resvg)
  #include_directories(${RESVG_INCLUDE_DIRS})
  target_link_libraries(openshot PUBLIC RESVG::resvg)

  target_compile_definitions(openshot PUBLIC "-DUSE_RESVG=1")
  set(CMAKE_SWIG_FLAGS "-DUSE_RESVG=1")
endif()

###############  LINK LIBRARY  #################
# Link remaining dependency libraries
target_link_libraries(openshot PUBLIC
	${LIBOPENSHOT_AUDIO_LIBRARIES}
  ${PROFILER})

if(ImageMagick_FOUND)
  target_link_libraries(openshot PUBLIC ${ImageMagick_LIBRARIES})
endif()

if(BLACKMAGIC_FOUND)
  target_link_libraries(openshot PUBLIC ${BLACKMAGIC_LIBRARY_DIR})
endif()

if(WIN32)
	# Required for exception handling on Windows
	target_link_libraries(openshot PUBLIC "imagehlp" "dbghelp" )
endif()


############### CLI EXECUTABLES ################
# Create test executable
add_executable(openshot-example examples/Example.cpp)

# Define path to test input files
SET(TEST_MEDIA_PATH "${PROJECT_SOURCE_DIR}/src/examples/")
IF (WIN32)
        STRING(REPLACE "/" "\\\\" TEST_MEDIA_PATH TEST_MEDIA_PATH)
ENDIF(WIN32)
target_compile_definitions(openshot-example PRIVATE
	-DTEST_MEDIA_PATH="${TEST_MEDIA_PATH}" )

# Link test executable to the new library
target_link_libraries(openshot-example openshot)

add_executable(openshot-html-test examples/ExampleHtml.cpp)
target_link_libraries(openshot-html-test openshot Qt5::Gui)

############### PLAYER EXECUTABLE ################
# Create test executable
add_executable(openshot-player Qt/demo/main.cpp)

# Link test executable to the new library
target_link_libraries(openshot-player openshot)

############### TEST BLACKMAGIC CAPTURE APP ################
IF (BLACKMAGIC_FOUND)
	# Create test executable
	add_executable(openshot-blackmagic
			examples/ExampleBlackmagic.cpp)

	# Link test executable to the new library
	target_link_libraries(openshot-blackmagic openshot)
ENDIF (BLACKMAGIC_FOUND)

############### INCLUDE SWIG BINDINGS ################
add_subdirectory(bindings)

############### INSTALL HEADERS & LIBRARY ################
set(LIB_INSTALL_DIR lib${LIB_SUFFIX}) # determine correct lib folder

# Install primary library
INSTALL(TARGETS openshot
		ARCHIVE DESTINATION ${LIB_INSTALL_DIR}
		LIBRARY DESTINATION ${LIB_INSTALL_DIR}
		RUNTIME DESTINATION ${LIB_INSTALL_DIR}
		COMPONENT library )

INSTALL(DIRECTORY ${CMAKE_SOURCE_DIR}/include/
		DESTINATION ${CMAKE_INSTALL_PREFIX}/include/libopenshot
		FILES_MATCHING PATTERN "*.h")

############### CPACK PACKAGING ##############
IF(MINGW)
	SET(CPACK_GENERATOR "NSIS")
ENDIF(MINGW)
IF(UNIX AND NOT APPLE)
	SET(CPACK_GENERATOR "DEB")
ENDIF(UNIX AND NOT APPLE)
#IF(UNIX AND APPLE)
#	SET(CPACK_GENERATOR "DragNDrop")
#ENDIF(UNIX AND APPLE)
SET(CPACK_DEBIAN_PACKAGE_MAINTAINER "Jonathan Thomas") #required

INCLUDE(CPack)
####################### CMakeLists.txt (libopenshot) #########################
# @brief CMake build file for libopenshot (used to generate makefiles)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to 
# delivering high quality video editing and animation solutions to the 
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################

IF(NOT DEFINED ENABLE_PYTHON)
    SET(ENABLE_PYTHON 1)
ENDIF()

IF(NOT DEFINED ENABLE_RUBY)
    SET(ENABLE_RUBY 1)
ENDIF()

############### INCLUDE EACH LANGUAGE BINDING ################
IF (ENABLE_PYTHON)
    add_subdirectory(python)
ENDIF (ENABLE_PYTHON)

IF (ENABLE_RUBY)
    add_subdirectory(ruby)
ENDIF (ENABLE_RUBY)

####################### CMakeLists.txt (libopenshot) #########################
# @brief CMake build file for libopenshot (used to generate Python SWIG bindings)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################


############### SWIG PYTHON BINDINGS ################
FIND_PACKAGE(SWIG 3.0 REQUIRED)
INCLUDE(${SWIG_USE_FILE})

### Enable some legacy SWIG behaviors, in newer CMAKEs
if (POLICY CMP0078)
	cmake_policy(SET CMP0078 OLD)
endif()
if (POLICY CMP0086)
	cmake_policy(SET CMP0086 OLD)
endif()

FIND_PACKAGE(PythonInterp 3)
FIND_PACKAGE(PythonLibs 3)
if (PYTHONLIBS_FOUND AND PYTHONINTERP_FOUND)

	### Include Python header files
	INCLUDE_DIRECTORIES(${PYTHON_INCLUDE_PATH})
	INCLUDE_DIRECTORIES(${CMAKE_CURRENT_SOURCE_DIR})

	### Enable C++ support in SWIG
	set_property(SOURCE openshot.i PROPERTY CPLUSPLUS ON)
	set_property(SOURCE openshot.i PROPERTY SWIG_MODULE_NAME openshot)

	### Suppress a ton of warnings in the generated SWIG C++ code
	set(SWIG_CXX_FLAGS "-Wno-unused-variable -Wno-unused-function -Wno-deprecated-copy -Wno-class-memaccess -Wno-cast-function-type \
-Wno-unused-parameter -Wno-catch-value -Wno-sign-compare -Wno-ignored-qualifiers")
	separate_arguments(sw_flags UNIX_COMMAND ${SWIG_CXX_FLAGS})
	set_property(SOURCE openshot.i PROPERTY GENERATED_COMPILE_OPTIONS ${sw_flags})

  ### Take include dirs from target, automatically if possible
  if (CMAKE_VERSION VERSION_GREATER 3.13)
    set_property(SOURCE openshot.i PROPERTY USE_TARGET_INCLUDE_DIRECTORIES True)
  else ()
    set_property(SOURCE openshot.i PROPERTY INCLUDE_DIRECTORIES $<TARGET_PROPERTY:openshot,INCLUDE_DIRECTORIES>)
  endif ()

	### Add the SWIG interface file (which defines all the SWIG methods)
	if (CMAKE_VERSION VERSION_LESS 3.8.0)
		swig_add_module(pyopenshot python openshot.i)
	else()
		swig_add_library(pyopenshot LANGUAGE python SOURCES openshot.i)
	endif()

	### Set output name of target
	set_target_properties(${SWIG_MODULE_pyopenshot_REAL_NAME} PROPERTIES
	                      PREFIX "_" OUTPUT_NAME "openshot")

	### Link the new python wrapper library with libopenshot
	target_link_libraries(${SWIG_MODULE_pyopenshot_REAL_NAME}
                        PUBLIC ${PYTHON_LIBRARIES} openshot)

	### Check if the following Debian-friendly python module path exists
	SET(PYTHON_MODULE_PATH "${CMAKE_INSTALL_PREFIX}/lib/python${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR}/dist-packages")
	if (NOT EXISTS ${PYTHON_MODULE_PATH})

		### Calculate the python module path (using distutils)
		execute_process ( COMMAND ${PYTHON_EXECUTABLE} -c "\
from distutils.sysconfig import get_python_lib; \
print( get_python_lib( plat_specific=True, prefix='${CMAKE_INSTALL_PREFIX}' ) )"
			OUTPUT_VARIABLE _ABS_PYTHON_MODULE_PATH
			OUTPUT_STRIP_TRAILING_WHITESPACE )

		GET_FILENAME_COMPONENT(_ABS_PYTHON_MODULE_PATH
				"${_ABS_PYTHON_MODULE_PATH}" ABSOLUTE)
		FILE(RELATIVE_PATH _REL_PYTHON_MODULE_PATH
				${CMAKE_INSTALL_PREFIX} ${_ABS_PYTHON_MODULE_PATH})
		SET(PYTHON_MODULE_PATH ${_ABS_PYTHON_MODULE_PATH})
	endif()
	message("PYTHON_MODULE_PATH: ${PYTHON_MODULE_PATH}")

	############### INSTALL HEADERS & LIBRARY ################
	### Install Python bindings
	INSTALL(TARGETS ${SWIG_MODULE_pyopenshot_REAL_NAME}
	        LIBRARY DESTINATION ${PYTHON_MODULE_PATH} )
	INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/openshot.py
	        DESTINATION ${PYTHON_MODULE_PATH} )

endif ()
####################### CMakeLists.txt (libopenshot) #########################
# @brief CMake build file for libopenshot (used to generate Ruby SWIG bindings)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################

############### RUBY BINDINGS ################
FIND_PACKAGE(SWIG 3.0 REQUIRED)
INCLUDE(${SWIG_USE_FILE})

### Enable some legacy SWIG behaviors, in newer CMAKEs
if (POLICY CMP0078)
	cmake_policy(SET CMP0078 OLD)
endif()
if (POLICY CMP0086)
	cmake_policy(SET CMP0086 OLD)
endif()

FIND_PACKAGE(Ruby)
IF (RUBY_FOUND)

	### Include the Ruby header files
	INCLUDE_DIRECTORIES(${RUBY_INCLUDE_DIRS})
	INCLUDE_DIRECTORIES(${CMAKE_CURRENT_SOURCE_DIR})

	### Enable C++ in SWIG
	set_property(SOURCE openshot.i PROPERTY CPLUSPLUS ON)
	set_property(SOURCE openshot.i PROPERTY SWIG_MODULE_NAME openshot)

	### Suppress a ton of warnings in the generated SWIG C++ code
	set(SWIG_CXX_FLAGS "-Wno-unused-variable -Wno-unused-function -Wno-deprecated-copy -Wno-class-memaccess -Wno-cast-function-type \
-Wno-unused-parameter -Wno-catch-value -Wno-sign-compare -Wno-ignored-qualifiers")
	separate_arguments(sw_flags UNIX_COMMAND ${SWIG_CXX_FLAGS})
	set_property(SOURCE openshot.i PROPERTY GENERATED_COMPILE_OPTIONS ${sw_flags})

	### Take include dirs from target, automatically if possible
	if (CMAKE_VERSION VERSION_GREATER 3.13)
		set_property(SOURCE openshot.i PROPERTY USE_TARGET_INCLUDE_DIRECTORIES True)
	else ()
		set_property(SOURCE openshot.i PROPERTY INCLUDE_DIRECTORIES $<TARGET_PROPERTY:openshot,INCLUDE_DIRECTORIES>)
	endif ()

	### Add the SWIG interface file (which defines all the SWIG methods)
	if (CMAKE_VERSION VERSION_LESS 3.8.0)
		swig_add_module(rbopenshot ruby openshot.i)
	else()
		swig_add_library(rbopenshot LANGUAGE ruby SOURCES openshot.i)
	endif()

	### Set name of target (with no prefix, since Ruby does not like that)
	SET_TARGET_PROPERTIES(${SWIG_MODULE_rbopenshot_REAL_NAME} PROPERTIES
	                      PREFIX "" OUTPUT_NAME "openshot")

	### Link the new Ruby wrapper library with libopenshot
	target_link_libraries(${SWIG_MODULE_rbopenshot_REAL_NAME}
	                      ${RUBY_LIBRARY} openshot)

	### FIND THE RUBY INTERPRETER (AND THE LOAD_PATH FOLDER)
	EXECUTE_PROCESS(COMMAND ${RUBY_EXECUTABLE}
	                -r rbconfig -e "print RbConfig::CONFIG['vendorarchdir']"
	                OUTPUT_VARIABLE RUBY_VENDOR_ARCH_DIR)
	MESSAGE(STATUS "Ruby executable: ${RUBY_EXECUTABLE}")
	MESSAGE(STATUS "Ruby vendor arch dir: ${RUBY_VENDOR_ARCH_DIR}")
	MESSAGE(STATUS "Ruby include path: ${RUBY_INCLUDE_PATH}")

	############### INSTALL HEADERS & LIBRARY ################
	# Install Ruby bindings
	install(TARGETS ${SWIG_MODULE_rbopenshot_REAL_NAME}
	        LIBRARY DESTINATION ${RUBY_VENDOR_ARCH_DIR} )

ENDIF (RUBY_FOUND)
##################### tests/CMakeLists.txt (libopenshot) ######################
# @brief CMake build file for libopenshot (used to generate makefiles)
# @author Jonathan Thomas <jonathan@openshot.org>
#
# @section LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
################################################################################

SET(TEST_MEDIA_PATH "${PROJECT_SOURCE_DIR}/src/examples/")

################ WINDOWS ##################
# Set some compiler options for Windows
# required for libopenshot-audio headers
IF (WIN32)
	STRING(REPLACE "/" "\\\\" TEST_MEDIA_PATH TEST_MEDIA_PATH)
	add_definitions( -DIGNORE_JUCE_HYPOT=1 )
	SET(CMAKE_CXX_FLAGS " ${CMAKE_CXX_FLAGS} -include cmath")
ENDIF(WIN32)

add_definitions( -DTEST_MEDIA_PATH="${TEST_MEDIA_PATH}" )

################### UNITTEST++ #####################
# Find UnitTest++ libraries (used for unit testing)
FIND_PACKAGE(UnitTest++ REQUIRED)

# Include UnitTest++ headers (needed for compile)
include_directories(${UNITTEST++_INCLUDE_DIR})

################ IMAGE MAGICK ##################
# Set the Quantum Depth that ImageMagick was built with (default to 16 bits)
IF (MAGICKCORE_QUANTUM_DEPTH)
	add_definitions( -DMAGICKCORE_QUANTUM_DEPTH=${MAGICKCORE_QUANTUM_DEPTH} )
ELSE (MAGICKCORE_QUANTUM_DEPTH)
	add_definitions( -DMAGICKCORE_QUANTUM_DEPTH=16 )
ENDIF (MAGICKCORE_QUANTUM_DEPTH)
IF (MAGICKCORE_HDRI_ENABLE)
	add_definitions( -DMAGICKCORE_HDRI_ENABLE=${MAGICKCORE_HDRI_ENABLE} )
ELSE (MAGICKCORE_HDRI_ENABLE)
	add_definitions( -DMAGICKCORE_HDRI_ENABLE=0 )
ENDIF (MAGICKCORE_HDRI_ENABLE)
IF (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)
	add_definitions( -DOPENSHOT_IMAGEMAGICK_COMPATIBILITY=${OPENSHOT_IMAGEMAGICK_COMPATIBILITY} )
ELSE (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)
	add_definitions( -DOPENSHOT_IMAGEMAGICK_COMPATIBILITY=0 )
ENDIF (OPENSHOT_IMAGEMAGICK_COMPATIBILITY)

# Find the ImageMagick++ library
FIND_PACKAGE(ImageMagick COMPONENTS Magick++ MagickWand MagickCore)
IF (ImageMagick_FOUND)
	# Include ImageMagick++ headers (needed for compile)
	include_directories(${ImageMagick_INCLUDE_DIRS})

	# define a global var (used in the C++)
	add_definitions( -DUSE_IMAGEMAGICK=1 )
	SET(CMAKE_SWIG_FLAGS "-DUSE_IMAGEMAGICK=1")

ENDIF (ImageMagick_FOUND)

################# LIBOPENSHOT-AUDIO ###################
# Find JUCE-based openshot Audio libraries
FIND_PACKAGE(OpenShotAudio 0.1.9 REQUIRED)

# Include Juce headers (needed for compile)
include_directories(${LIBOPENSHOT_AUDIO_INCLUDE_DIRS})


################# BLACKMAGIC DECKLINK ###################
IF (ENABLE_BLACKMAGIC)
	# Find BlackMagic DeckLinkAPI libraries
	FIND_PACKAGE(BlackMagic)

	IF (BLACKMAGIC_FOUND)
		# Include Blackmagic headers (needed for compile)
		include_directories(${BLACKMAGIC_INCLUDE_DIR})
	ENDIF (BLACKMAGIC_FOUND)
ENDIF (ENABLE_BLACKMAGIC)


###############  SET TEST SOURCE FILES  #################
SET ( OPENSHOT_TEST_FILES
	   Cache_Tests.cpp
	   Clip_Tests.cpp
	   Color_Tests.cpp
	   Coordinate_Tests.cpp
	   ReaderBase_Tests.cpp
	   ImageWriter_Tests.cpp
	   FFmpegReader_Tests.cpp
	   FFmpegWriter_Tests.cpp
	   Fraction_Tests.cpp
     Frame_Tests.cpp
	   FrameMapper_Tests.cpp
	   KeyFrame_Tests.cpp
	   Point_Tests.cpp
	   Settings_Tests.cpp
	   Timeline_Tests.cpp )

################ TESTER EXECUTABLE #################
# Create unit test executable (openshot-test)
message (STATUS "Tests enabled, test executable will be built as tests/openshot-test")
add_executable(openshot-test
			   tests.cpp
			   ${OPENSHOT_TEST_FILES} )

# Link libraries to the new executable
target_link_libraries(openshot-test openshot ${UNITTEST++_LIBRARY})

##### RUNNING TESTS (make os_test / make test) #####
# Hook up the 'make os_test' target to the 'openshot-test' executable
ADD_CUSTOM_TARGET(os_test COMMAND openshot-test)
list(APPEND OS_TEST_CMDS "'make os_test'")

# Also hook up 'make test', if possible
# This requires CMake 3.11+, where the CMP0037 policy
# configured to 'NEW' mode will not reserve target names
# unless the corresponding feature is actually used
if (POLICY CMP0037)
	cmake_policy(SET CMP0037 NEW)
endif()
if (CMAKE_VERSION VERSION_GREATER 3.11)
	message(STATUS "Cmake 3.11+ detected, enabling 'test' target")
	add_custom_target(test COMMAND openshot-test)
	list(APPEND OS_TEST_CMDS " or " "'make test'")
endif()

string(CONCAT t ${OS_TEST_CMDS})
message("\nTo run unit tests, use: ${t}")
The JsonCpp library's source code, including accompanying documentation, 
tests and demonstration applications, are licensed under the following
conditions...

Baptiste Lepilleur and The JsonCpp Authors explicitly disclaim copyright in all 
jurisdictions which recognize such a disclaimer. In such jurisdictions, 
this software is released into the Public Domain.

In jurisdictions which do not recognize Public Domain property (e.g. Germany as of
2010), this software is Copyright (c) 2007-2010 by Baptiste Lepilleur and
The JsonCpp Authors, and is released under the terms of the MIT License (see below).

In jurisdictions which recognize Public Domain property, the user of this 
software may choose to accept it either as 1) Public Domain, 2) under the 
conditions of the MIT License (see below), or 3) under the terms of dual 
Public Domain/MIT License conditions described here, as they choose.

The MIT License is about as close to Public Domain as a license can get, and is
described in clear, concise terms at:

   http://en.wikipedia.org/wiki/MIT_License
   
The full text of the MIT License follows:

========================================================================
Copyright (c) 2007-2010 Baptiste Lepilleur and The JsonCpp Authors

Permission is hereby granted, free of charge, to any person
obtaining a copy of this software and associated documentation
files (the "Software"), to deal in the Software without
restriction, including without limitation the rights to use, copy,
modify, merge, publish, distribute, sublicense, and/or sell copies
of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
========================================================================
(END LICENSE TEXT)

The MIT license is compatible with both the GPL and commercial
software, affording one all of the rights of Public Domain with the
minor nuisance of being required to keep the above copyright notice
and license text in the source code. Note also that by accepting the
Public Domain "license" you can re-license your copy using whatever
license you like.
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor
// Destructor
// forget the AudioSampleBuffer. It still exists; we just don't know about it.
// Get the next block of audio samples
// Determine how many samples to copy
// copy the full amount requested
// copy nothing
// only copy what is left in the buffer
// copy nothing
// Determine if any samples need to be copied
// Loop through each channel and copy some samples
// Update the position of this audio source
// Prepare to play this audio source
// Release all resources
// Set the next read position of this source
// set position (if the new position is in range)
// Get the next read position of this source
// return the next read position
// Get the total length (in samples) of this audio source
// Get the length
// Determines if this audio source should repeat when it reaches the end
// return if this source is looping
// Set if this audio source should repeat when it reaches the end
// Set the repeat flag
// Use a different AudioSampleBuffer for this source
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor that reads samples from a reader
// Initialize an audio buffer (based on reader)
// initialize the audio samples to zero (silence)
// Destructor
// Clear and delete the buffer
// Get more samples from the reader
// Determine the amount of samples needed to fill up this buffer
// replace these used samples
// these are unused samples, and need to be carried forward
// If no frame, load entire buffer
// Debug
// Init estimated buffer equal to the current frame position (before getting more samples)
// Init new buffer
// Move the remaining samples into new buffer (if any)
// reset position to 0
// Loop through frames until buffer filled
// Get the next frame (if position is zero)
// Get frame object
// Don't copy too many samples (we don't want to overflow the buffer)
// Not enough to fill the buffer (so use the entire frame)
// Load all of its samples into the buffer
// Adjust remaining samples
// Reset frame buffer position (which will load a new frame on the next loop)
// Continue tracking the current frame's position
// Delete old buffer
// Replace buffer and reset position
// Reverse an audio buffer
// Debug
// Reverse array (create new buffer to hold the reversed version)
// Copy the samples back to the original array
// Loop through channels, and get audio samples
// Get the audio samples for this channel
// return pointer or passed in object (so this method can be chained together)
// Get the next block of audio samples
// Do we need more samples?
// Only refill buffers if speed is normal
// Refill buffer from reader
// Fill buffer with silence and clear current frame
// Determine how many samples to copy
// copy the full amount requested
// copy nothing
// only copy what is left in the buffer
// copy nothing
// Determine if any samples need to be copied
// Debug
// Loop through each channel and copy some samples
// Update the position of this audio source
// Adjust estimate frame number (the estimated frame number that is being played)
// Prepare to play this audio source
// Release all resources
// Set the next read position of this source
// set position (if the new position is in range)
// Get the next read position of this source
// return the next read position
// Get the total length (in samples) of this audio source
// Get the length
// Determines if this audio source should repeat when it reaches the end
// return if this source is looping
// Set if this audio source should repeat when it reaches the end
// Set the repeat flag
// Update the internal buffer used by this source
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor, max frames to cache is 20 // resample_source(NULL), buffer_source(NULL), num_of_samples(0), new_num_of_samples(0), dest_ratio(0), source_ratio(0), resampled_buffer(NULL), isPrepared(false)
// Init buffer source
// Init resampling source
// Init resampled buffer
// Init callback buffer
// Descructor
// Clean up
// Sets the audio buffer and updates the key settings
// Set the sample ratio (the ratio of sample rate change)
// Call SetBuffer with ratio
// Sets the audio buffer and key settings
// Update buffer & buffer source
// Set the sample ratio (the ratio of sample rate change)
// Set resample ratio
// Prepare to play resample source
// Prepare to play the audio sources (and set the # of samples per chunk to a little more than expected)
// Resize buffer for the newly resampled data
// Get the resampled audio buffer
// Resample the current frame's audio buffer (into the temp callback buffer)
// Return buffer pointer to this newly resampled buffer
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor, no max frames
// Init the critical section
// Constructor that sets the max frames to cache
// Init the critical section
// Set maximum bytes to a different amount based on a ReaderInfo struct
// n frames X height X width X 4 colors of chars X audio channels X 4 byte floats
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor, no max bytes
// Set cache type name
// Init path directory
// Constructor that sets the max bytes to cache
// Set cache type name
// Init path directory
// Initialize cache directory
// Init QDir with cache directory
// Init QDir with user's temp directory
// Init QDir with cache directory
// Check if cache directory exists
// Create
// Calculate ranges of frames
// Only calculate when something has changed
// Create a scoped lock, to protect the cache from multiple threads
// Sort ordered frame #s, and calculate JSON ranges
// Clear existing JSON variable
// Increment range version
// Loop through all known frames (in sequential order)
// End of range detected
// Add JSON object with start/end attributes
// Use strings, since int64_ts are supported in JSON
// Set new starting range
// Set current frame as end of range, and keep looping
// APPEND FINAL VALUE
// Add JSON object with start/end attributes
// Use strings, since int64_ts are supported in JSON
// Cache range JSON as string
// Reset needs_range_processing
// Default destructor
// remove critical section
// Add a Frame to the cache
// Create a scoped lock, to protect the cache from multiple threads
// Freshen frame if it already exists
// Move frame to front of queue
// Add frame to queue and map
// Save image to disk (if needed)
// Get compressed size of frame image (to correctly apply max size against)
// Save audio data (if needed)
// Loop through all samples
// Get audio for this channel
// Clean up old frames
// Get a frame from the cache (or NULL shared_ptr if no frame is found)
// Create a scoped lock, to protect the cache from multiple threads
// Does frame exists in cache?
// Does frame exist on disk
// Load image file
// Set pixel formatimage->
// Create frame object
// Get audio data (if found)
// Open audio file
// Set basic audio properties
// Loop through audio samples and add to frame
// Add sample to channel array
// Add audio to frame
// Increment channel, and reset sample position
// return the Frame object
// no Frame found
// Get the smallest frame number (or NULL shared_ptr if no frame is found)
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frame numbers
// Return frame
// Gets the maximum bytes value
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frames, and calculate total bytes
// Remove a specific frame
// Remove range of frames
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frame numbers
//deque<int64_t>::iterator current = itr++;
// erase frame number
// Loop through ordered frame numbers
// erase frame number
// Remove the image file (if it exists)
// Remove audio file (if it exists)
// Needs range processing (since cache has changed)
// Move frame to front of queue (so it lasts longer)
// Does frame exists in cache?
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frame numbers
// erase frame number
// add frame number to 'front' of queue
// Clear the cache of all frames
// Create a scoped lock, to protect the cache from multiple threads
// Clear all containers
// Delete cache directory, and recreate it
// Re-init folder
// Count the frames in the queue
// Create a scoped lock, to protect the cache from multiple threads
// Return the number of frames in the cache
// Clean up cached frames that exceed the number in our max_bytes variable
// Do we auto clean up?
// Create a scoped lock, to protect the cache from multiple threads
// Get the oldest frame number.
// Remove frame_number and frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Process range data (if anything has changed)
// Create root json object
// get parent properties
// Parse and append range data (if any)
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Close timeline before we do anything (this also removes all open and closing clips)
// Set parent data
// Update duration of timeline
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor, no max bytes
// Set cache type name
// Constructor that sets the max bytes to cache
// Set cache type name
// Default destructor
// remove critical section
// Calculate ranges of frames
// Only calculate when something has changed
// Create a scoped lock, to protect the cache from multiple threads
// Sort ordered frame #s, and calculate JSON ranges
// Clear existing JSON variable
// Increment range version
// Loop through all known frames (in sequential order)
// End of range detected
// Add JSON object with start/end attributes
// Use strings, since int64_ts are supported in JSON
// Set new starting range
// Set current frame as end of range, and keep looping
// APPEND FINAL VALUE
// Add JSON object with start/end attributes
// Use strings, since int64_ts are not supported in JSON
// Cache range JSON as string
// Reset needs_range_processing
// Add a Frame to the cache
// Create a scoped lock, to protect the cache from multiple threads
// Freshen frame if it already exists
// Move frame to front of queue
// Add frame to queue and map
// Clean up old frames
// Get a frame from the cache (or NULL shared_ptr if no frame is found)
// Create a scoped lock, to protect the cache from multiple threads
// Does frame exists in cache?
// return the Frame object
// no Frame found
// Get the smallest frame number (or NULL shared_ptr if no frame is found)
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frame numbers
// Return frame
// Gets the maximum bytes value
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frames, and calculate total bytes
// Remove a specific frame
// Remove range of frames
// Create a scoped lock, to protect the cache from multiple threads
// Loop through frame numbers
// erase frame number
// Loop through ordered frame numbers
// erase frame number
// Needs range processing (since cache has changed)
// Move frame to front of queue (so it lasts longer)
// Create a scoped lock, to protect the cache from multiple threads
// Does frame exists in cache?
// Loop through frame numbers
// erase frame number
// add frame number to 'front' of queue
// Clear the cache of all frames
// Create a scoped lock, to protect the cache from multiple threads
// Count the frames in the queue
// Create a scoped lock, to protect the cache from multiple threads
// Return the number of frames in the cache
// Clean up cached frames that exceed the number in our max_bytes variable
// Do we auto clean up?
// Create a scoped lock, to protect the cache from multiple threads
// Get the oldest frame number.
// Remove frame_number and frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Process range data (if anything has changed)
// Create root json object
// get parent properties
// Parse and append range data (if any)
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Close timeline before we do anything (this also removes all open and closing clips)
// Set parent data
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Check if folder exists?
// Raise exception
// Init previous location
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Check if folder path existing
// Load JSON meta data about this chunk folder
// Load path of chunk folder
// Read the JSON file
// Parse JSON string into JSON objects
// Raise exception
// Set info from the JSON objects
// Error parsing JSON (or missing keys)
// Find the location of a frame in a chunk
// Determine which chunk contains this frame.
// Determine which frame in this chunk
// Add 1 to adjust for the 1st frame of every chunk is just there to "stoke" the audio samples from the previous chunk.
// Prepare chunk location struct
// Open chunk folder or file
// Open reader if not already open
// parse JSON and load info.json file
// Mark as "open"
// Close image file
// Close all objects, if reader is 'open'
// Mark as "closed"
// get a formatted path of a specific chunk
// Create path of new chunk video
//chunk_count_string.str().c_str();
// Return path with FOLDER and EXTENSION name
// Return path with NO FOLDER and EXTENSION name
// Return path with FOLDER and NO EXTENSION
// Get an openshot::Frame object for a specific frame number of this reader.
// Determine what chunk contains this frame
// New Chunk (Close the old reader, and open the new one)
// Determine version of chunk
// Load path of chunk video
// Close existing reader (if needed)
// Close and delete old reader
// Load new FFmpegReader
// open reader
// Invalid Chunk (possibly it is not found)
// Set the new location
// Get the frame (from the current reader)
// Update the frame number property
// Return the frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Change codecs to default
// Copy info struct from the source reader
// Create folder (if it does not exist)
// Write JSON meta data file
// Open reader
// get a formatted path of a specific chunk
// Create path of new chunk video
//chunk_count_string.str().c_str();
// Return path with FOLDER and EXTENSION name
// Return path with NO FOLDER and EXTENSION name
// Return path with FOLDER and NO EXTENSION
// Add a frame to the queue waiting to be encoded.
// Check for open reader (or throw exception)
// Check if currently writing chunks?
// Save thumbnail of chunk start frame
// Create FFmpegWriter (FINAL quality)
// Create FFmpegWriter (PREVIEW quality)
// Create FFmpegWriter (LOW quality)
// Prepare Streams
// Write header
// Keep track that a chunk is being written
// If this is not the 1st chunk, always start frame 1 with the last frame from the previous
// chunk. This helps to prevent audio resampling issues (because it "stokes" the sample array)
// Write the previous chunks LAST FRAME to the current chunk
// Write the 1st frame (of the 1st chunk)... since no previous chunk is available
// disable last frame
//////////////////////////////////////////////////
// WRITE THE CURRENT FRAME TO THE CURRENT CHUNK
//////////////////////////////////////////////////
// Write the frames once it reaches the correct chunk size
// Pad an additional 12 frames
// Repeat frame
// Write Footer
// Close writer & reader
// Increment chunk count
// Stop writing chunk
// Increment frame counter
// Keep track of the last frame added
// Write a block of frames from a reader
// Loop through each frame (and encoded it)
// Get the frame
// Encode frame
// Write a block of frames from the local cached reader
// Loop through each frame (and encoded it)
// Get the frame
// Encode frame
// Close the writer
// Write the frames once it reaches the correct chunk size
// Pad an additional 12 frames
// Repeat frame
// Write Footer
// Close writer & reader
// Increment chunk count
// Stop writing chunk
// close writer
// Reset frame counters
// Open reader
// write JSON meta data
// Load path of chunk folder
// Write JSON file
// check for chunk folder
// check for valid chunk json
// Open the writer
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Init default settings for a clip
// Init clip settings
// Init scale curves
// Init location curves
// Init alpha
// Init rotation
// Init time & volume
// Init audio waveform color
// Init crop settings
// Init shear and perspective curves
// Init audio channel filter and mappings
// Init audio and video overrides
// Init reader's rotation (if any)
// Only init rotation from reader when needed
// Do nothing if more than 1 rotation Point
// Do nothing if 1 Point, and it's not the default value
// Init rotation
// Use reader metadata rotation (if any)
// This is typical with cell phone videos filmed in different orientations
// Default no rotation
// Default Constructor for a clip
// Init all default settings
// Constructor with reader
// Init all default settings
// Open and Close the reader (to set the duration of the clip)
// Update duration
// Constructor with filepath
// Init all default settings
// Get file extension (and convert to lower case)
// Determine if common video formats
// Open common video format
// If no video found, try each reader
// Try an image reader
// Try a video reader
// Update duration
// Destructor
// Delete the reader if clip created it
// Close the resampler
/// Set the current reader
// set reader pointer
// set parent
// Init rotation (if any)
/// Get the current reader
// Throw error if reader not initialized
// Open the internal reader
// Open the reader
// Set some clip properties from the file reader
// Throw error if reader not initialized
// Close the internal reader
// Close the reader
// Throw error if reader not initialized
// Get end position of clip (trim end of video), which can be affected by the time curve.
// if a time curve is present, use its length
// Determine the FPS fo this clip
// file reader
// Throw error if reader not initialized
// just use the duration (as detected by the reader)
// Get an openshot::Frame object for a specific frame number of this reader.
// Adjust out of bounds frame number
// Adjust has_video and has_audio overrides
// Is a time map detected
// Now that we have re-mapped what frame number is needed, go and get the frame pointer
// Create a new frame
// Copy the image from the odd field
// Loop through each channel, add audio
// Get time mapped frame number (used to increase speed, change direction, etc...)
// Apply effects to the frame (if any)
// Return processed 'frame'
// Throw error if reader not initialized
// Get file extension
// return last part of path
// Reverse an audio buffer
// Reverse array (create new buffer to hold the reversed version)
// Copy the samples back to the original array
// Loop through channels, and get audio samples
// Get the audio samples for this channel
// Adjust the audio and image of a time mapped frame
// Check for valid reader
// Throw error if reader not initialized
// Check for a valid time map curve
// create buffer and resampler
// Get new frame number
// Get delta (difference in previous Y value)
// Init audio vars
// Only resample audio if needed
// Determine if we are speeding up or slowing down
// SLOWING DOWN AUDIO
// Resample data, and return new buffer pointer
// SLOW DOWN audio (split audio)
// Loop through channels, and get audio samples
// Get the audio samples for this channel
// Reverse the samples (if needed)
// Resample audio to be X times slower (where X is the denominator of the repeat fraction)
// Resample the data (since it's the 1st slice)
// Get the length of the resampled buffer (if one exists)
// Just take the samples we need for the requested frame
// Add new (slower) samples, to the frame object
// Clean up
// SPEED UP (multiple frames of audio), as long as it's not more than X frames
// Allocate a new sample buffer for these delta frames
// Loop through each frame in this delta
// buffer to hold detal samples
// Reverse the samples (if needed)
// Copy the samples to
// Get the audio samples for this channel
// Clean up
// Increment start position
// SPEED UP (multiple frames of audio), as long as it's not more than X frames
// Allocate a new sample buffer for these delta frames
// Loop through each frame in this delta
// buffer to hold delta samples
// Reverse the samples (if needed)
// Copy the samples to
// Get the audio samples for this channel
// Clean up
// Increment start position
// Resample audio to be X times faster (where X is the delta of the repeat fraction)
// Resample data, and return new buffer pointer
// Add the newly resized audio samples to the current frame
// Add new (slower) samples, to the frame object
// Clean up
// Use the samples on this frame (but maybe reverse them if needed)
// Loop through channels, and get audio samples
// Get the audio samples for this channel
// reverse the samples
// Add reversed samples to the frame object
// Adjust frame number minimum value
// Never return a frame number 0 or below
// Get or generate a blank frame
// Init some basic properties about this frame
// Debug output
// Attempt to get a frame (but this could fail if a reader has just been closed)
// Return real frame
// ...
// ...
// ...
// Debug output
// Create blank frame
// Generate JSON string of this object
// Return formatted string
// Get all properties for a specific frame
// Generate JSON properties list
// Add gravity choices (dropdown style)
// Add scale choices (dropdown style)
// Add frame number display choices (dropdown style)
// Add volume mixing choices (dropdown style)
// Add waveform choices (dropdown style)
// Keyframes
// Add enable audio/video choices (dropdown style)
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// Add array of effects
// loop through effects
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Clear existing effects
// loop through effects
// Create Effect
// Create instance of effect
// Load Json into Effect
// Add Effect to Timeline
// does Json contain a reader?
// does the reader Json contain a 'type'?
// Close previous reader (if any)
// Track if reader was open
// Close and delete existing reader (if any)
// Create new reader (and load properties)
// Create new reader
// Create new reader
// Create new reader
// Create new reader
// Create new reader
// Create new reader
// mark as managed reader and set parent
// Re-Open reader (if needed)
// Sort effects by order
// sort clips
// Add an effect to the clip
// Add effect to list
// Sort effects
// Remove an effect from the clip
// Apply effects to the source frame (if any)
// Find Effects at this position and layer
// Apply the effect to this frame
// end effect loop
// Return modified frame
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
// Generate JSON for a property
// Requested Point
// Create JSON Object
// return JsonValue
// Create choice
// return JsonValue
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor which takes R,G,B,A
// Set initial points
// Constructor which takes 4 existing Keyframe curves
// Assign existing keyframes
// Constructor which takes a HEX color code
// Create a QColor from hex
// Get the HEX value of a color at a specific frame
// Get the distance between 2 RGB pairs (alpha is ignored)
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor for a coordinate, which defaults the X and Y to zero (0,0)
// Constructor which also allows the user to set the X and Y
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
//root["increasing"] = increasing;
//root["repeated"] = Json::Value(Json::objectValue);
//root["repeated"]["num"] = repeated.num;
//root["repeated"]["den"] = repeated.den;
//root["delta"] = delta;
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Global reference to logger
// Create or Get an instance of the logger singleton
// Create the actual instance of crash handler only once
// TODO: Windows exception handling methods
// Register abortHandler function callback
// Windows exception handler
// Associate each signal with a signal name string.
// Notify the user which signal was caught
// Dump a stack trace.
// Quit
// Linux and Mac Exception Handler
// Associate each signal with a signal name string.
// Notify the user which signal was caught
// Dump a stack trace.
// Quit
// Windows stack unwinding
// Loop through the entire stack
// Skip the first 3 elements (those relate to these functions)
// Linux and Mac stack unwinding
// Storage array for stack trace address data
// Retrieve current stack addresses
// Resolve addresses into strings containing "filename(function+address)",
// Actually it will be ## program address function + offset
// this array must be free()-ed
// Iterate over the returned symbol lines. Skip the first 4, it is the
// address of this function.
// Find parentheses and +address offset surrounding the mangled name
// OSX style stack trace
// Mangled name is now in [begin_name, begin_offset) and caller
// offset in [begin_offset, end_offset). now apply
// __cxa_demangle():
// Use possibly realloc()-ed string
// Demangling failed. Output function name as a C function with
// no arguments.
// !DARWIN - but is posix
// not OSX style
// ./module(function+0x15c) [0x8048a6d]
// Mangled name is now in [begin_name, begin_offset) and caller
// offset in [begin_offset, end_offset). now apply
// __cxa_demangle():
// !DARWIN - but is posix
// Couldn't parse the line? print the whole line.
// Free array
// Write stacktrace to file (if log path set)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Set cache size (20 1080p frames)
// Is this frame for the future?
// Get the frame and remove it from the cache
// Handle Video Frame
//			fprintf(stderr, "Frame received (#%lu) [%s] - Size: %li bytes\n",
//				frameCount,
//				timecodeString != NULL ? timecodeString : "No timecode",
//				videoFrame->GetRowBytes() * videoFrame->GetHeight());
// Create a new copy of the YUV frame object
// Copy pixel and audio to copied frame
// Add raw YUV frame to queue
// Process frames once we have a few (to take advantage of multiple threads)
//omp_set_num_threads(1);
// Temp frame counters (to keep the frames in order)
//frameCount = 0;
// Loop through each queued image frame
// Get front frame (from the queue)
// declare local variables (for OpenMP)
// *********** CONVERT YUV source frame to RGB ************
// Create a new RGB frame object
// Create a RGB version of this YUV video frame
// Get RGB Byte array
// *********** CREATE OPENSHOT FRAME **********
// Add Image data to openshot frame
// TODO: Fix Decklink support with QImage Upgrade
//f->AddImage(width, height, "ARGB", Magick::CharPixel, (uint8_t*)frameBytes);
// Add processed frame to cache (to be recalled in order after the thread pool is done)
// Release RGB data
// Release RGB data
// end task
// Increment frame count
// end while
// omp single
// omp parallel
// Update final frameCount (since they are done processing now)
// if size > num processors
// has video source
// if videoFrame
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// reference to output device
// init some variables
// Get framerate
// Allocate audio array
// Zero the buffer (interpreted as audio silence)
/************************* DeckLink API Delegate Methods *****************************/
//cout << "Scheduled Successfully!" << endl;
// When a video frame has been released by the API, schedule another video frame to be output
//cout << "PLAYBACK HAS STOPPED!!!" << endl;
//	// Provide further audio samples to the DeckLink API until our preferred buffer waterlevel is reached
//	const unsigned long kAudioWaterlevel = 48000;
//	unsigned int bufferedSamples;
//
//	// Try to maintain the number of audio samples buffered in the API at a specified waterlevel
//	if ((deckLinkOutput->GetBufferedAudioSampleFrameCount(&bufferedSamples) == S_OK) && (bufferedSamples < kAudioWaterlevel))
//	{
//		unsigned int samplesToEndOfBuffer;
//		unsigned int samplesToWrite;
//		unsigned int samplesWritten;
//
//		samplesToEndOfBuffer = (m_audioBufferSampleLength - m_audioBufferOffset);
//		samplesToWrite = (kAudioWaterlevel - bufferedSamples);
//		if (samplesToWrite > samplesToEndOfBuffer)
//			samplesToWrite = samplesToEndOfBuffer;
//
//		if (deckLinkOutput->ScheduleAudioSamples((void*)((unsigned long)m_audioBuffer + (m_audioBufferOffset * m_audioChannelCount * m_audioSampleDepth/8)), samplesToWrite, 0, 0, &samplesWritten) == S_OK)
//		{
//			m_audioBufferOffset = ((m_audioBufferOffset + samplesWritten) % m_audioBufferSampleLength);
//		}
//	}
//
//
//	if (preroll)
//	{
//		// Start audio and video output
//		deckLinkOutput->StartScheduledPlayback(0, 100, 1.0);
//	}
// Schedule the next frame
// Get oldest frame (if any)
// Get the next frame off the queue
// remove this frame from the queue
// Release the current frame (if any)
// Create a new one
// Copy pixel data to frame
// Delete temp array
// critical
//else
//	cout << "Queue: empty on writer..." << endl;
// Schedule a frame to be displayed
// Update the timestamp (regardless of previous frame's success)
// Add raw OpenShot frame object
// Process frames once we have a few (to take advantage of multiple threads)
//omp_set_num_threads(1);
// Temp frame counters (to keep the frames in order)
// Loop through each queued image frame
// Get front frame (from the queue)
// copy of frame count
// *********** CONVERT YUV source frame to RGB ************
// Get RGB Byte array
// TODO: Fix Decklink support with QImage Upgrade
// Get a list of pixels in our frame's image.  Each pixel is represented by
// a PixelPacket struct, which has 4 properties: .red, .blue, .green, .alpha
//					const Magick::PixelPacket *pixel_packets = frame->GetPixels();
//
//					// loop through ImageMagic pixel structs, and put the colors in a regular array, and move the
//					// colors around to match the Decklink order (ARGB).
//					for (int packet = 0, row = 0; row < numBytes; packet++, row+=4)
//					{
//						// Update buffer (which is already linked to the AVFrame: pFrameRGB)
//						// Each color needs to be scaled to 8 bit (using the ImageMagick built-in ScaleQuantumToChar function)
//						castBytes[row] = MagickCore::ScaleQuantumToChar((Magick::Quantum) 0); // alpha
//						castBytes[row+1] = MagickCore::ScaleQuantumToChar((Magick::Quantum) pixel_packets[packet].red);
//						castBytes[row+2] = MagickCore::ScaleQuantumToChar((Magick::Quantum) pixel_packets[packet].green);
//						castBytes[row+3] = MagickCore::ScaleQuantumToChar((Magick::Quantum) pixel_packets[packet].blue);
//					}
//if (20 == frame->number)
//	frame->Display();
// Add processed frame to cache (to be recalled in order after the thread pool is done)
// end task
// Increment frame count
// end while
// omp single
// omp parallel
// Add frames to final queue (in order)
// Add to final queue
// Clear temp cache
//cout << "final_frames.size(): " << final_frames.size() << ", raw_video_frames.size(): " << raw_video_frames.size() << endl;
// Start playback when enough frames have been processed
// Be sure we don't have too many extra frames
//cout << "Too many, so remove some..." << endl;
// Remove oldest frame
// if
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Init decklink variables
// Attempt to open blackmagic card
/* Connect to a DeckLink instance */
// Check for requested device
// Obtain an IDeckLinkDisplayModeIterator to enumerate the display modes supported on output
// Init deckLinkOutput (needed for color conversion)
// Init the YUV to RGB conversion
// Create Delegate & Pass in pointers to the output and converters
// Loop through all available display modes, until a match is found (if any)
// Get framerate
// Check for video input
// Check for audio input
// destructor
// Open image file
// Open reader if not already open
// Start the streams
// Update image properties
// 24 hour duration... since we're capturing a live stream
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close device and video stream
// Close all objects, if reader is 'open'
// Stop streams
// Mark as "closed"
// Get an openshot::Frame object for the next available LIVE frame
// Get a frame from the delegate decklink class (which is collecting them on another thread)
//	cout << "Change the frame number to " << requested_frame << endl;
//	f->SetFrameNumber(requested_frame);
// frame # does not matter, since it always gets the oldest frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Init decklink variables
// Open decklink writer
// Open reader if not already open
// Attempt to open blackmagic card
/* Connect to a DeckLink instance */
// Check for requested device
// Obtain an IDeckLinkDisplayModeIterator to enumerate the display modes supported on output
// Loop through all available display modes, until a match is found (if any)
//deckLinkOutput->DoesSupportVideoMode(selectedDisplayMode, pixelFormat, bmdVideoOutputFlagDefault, &result, NULL);
// Get framerate
//if (result == bmdDisplayModeNotSupported)
//{
//	cout << "The display mode does not support the selected pixel format." << endl;
//	throw DecklinkError("The display mode does not support the selected pixel format.");
//}
// Calculate FPS
// Create Delegate & Pass in pointers to the output and converters
// Provide this class as a delegate to the audio and video output interfaces
//deckLinkOutput->SetAudioCallback(delegate);
// Check for video input
// Check for audio input
//if (deckLinkOutput->EnableAudioOutput(bmdAudioSampleRate48kHz, g_audioSampleDepth, g_audioChannels, bmdAudioOutputStreamContinuous) != S_OK)
//	throw DecklinkError("Failed to enable audio output. Is another application using the card?");
// Begin video preroll by scheduling a second of frames in hardware
//std::shared_ptr<Frame> f(new Frame(1, displayMode->GetWidth(), displayMode->GetHeight(), "Blue"));
//f->AddColor(displayMode->GetWidth(), displayMode->GetHeight(), "Blue");
// Preroll 1 second of video
//for (unsigned i = 0; i < 16; i++)
//{
//	// Write 30 blank frames (for preroll)
//	delegate->WriteFrame(f);
//	delegate->ScheduleNextFrame(true);
//}
//deckLinkOutput->StartScheduledPlayback(0, 100, 1.0);
//if (deckLinkOutput->BeginAudioPreroll() != S_OK)
//	throw DecklinkError("Failed to begin audio preroll.");
// Update image properties
// 24 hour duration... since we're capturing a live stream
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close device and video stream
// Close all objects, if reader is 'open'
// Stop the audio and video output streams immediately
// Release DisplayMode
// Mark as "closed"
// This method is required for all derived classes of WriterBase.  Write a Frame to the video file.
// Check for open reader (or throw exception)
// This method is required for all derived classes of WriterBase.  Write a block of frames from a reader.
// Loop through each frame (and encoded it)
// Get the frame
// Encode frame
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Blank constructor for DummyReader, with default settings.
// Call actual constructor with default values
// Constructor for DummyReader.  Pass a framerate and samplerate.
// Set key info settings
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open image file
// Open reader if not already open
// Create or get frame object
// Mark as "open"
// Close image file
// Close all objects, if reader is 'open'
// Mark as "closed"
// Get an openshot::Frame object for a specific frame number of this reader.
// Check for open reader (or throw exception)
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Always return same frame (regardless of which frame number was requested)
// no frame loaded
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Initialize the values of the EffectInfo struct
// Init clip settings
// Display file information
// Constrain a color value from 0 to 255
// Constrain new color from 0 to 255
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Generate JSON string of this object
// Return formatted string
// Create a new effect instance
// Init the matching effect object
// Generate Json::JsonValue for this object
// Create root json object
// Append info JSON from each supported effect
// return JsonValue
/**
/* LICENSE
//www.openshotstudios.com). This file is part of
//www.openshot.org), an open-source project
//www.gnu.org/licenses/>.
// FF_DISABLE_DEPRECATION_WARNINGS
// FF_ENABLE_DEPRECATION_WARNINGS
// Initialize FFMpeg, and register all formats and codecs
// Init cache
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Initialize FFMpeg, and register all formats and codecs
// Init cache
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Auto close reader if not already done
// This struct holds the associated video frame and starting sample # for an audio packet.
// Is frame even close to this one?
// This is too far away to be considered
// Note that samples_per_frame can vary slightly frame to frame when the
// audio sampling rate is not an integer multiple of the video fps.
// close
// not close
// Get hardware pix format
// Linux pix formats
// Windows pix formats
// Apple pix formats
// Cross-platform pix formats
// This is only here to silence unused-enum warnings
// Open reader if not already open
// Initialize format context
// Open video file
// Retrieve stream information
// Loop through each stream, and identify the video and audio stream index
// Is this a video stream?
// Is this an audio stream?
// Is there a video stream?
// Set the stream index
// Set the codec and codec context pointers
// Find the codec ID from stream
// Get codec and codec context from stream
// If hw accel is selected but hardware cannot handle repeat with software decoding
// Up to here no decision is made if hardware or software decode
// Set number of threads equal to number of processors (not to exceed 16)
// Init options
// Open Hardware Acceleration
// Set hardware pix format (callback)
// Just to be sure
// Check if it is there and writable
// use default
// Here the first hardware initialisations are made
/*
// Open video codec
// TODO: needs va_config!
// All is just peachy
//max_h = ((getenv( "LIMIT_HEIGHT_MAX" )==NULL) ? MAX_SUPPORTED_HEIGHT : atoi(getenv( "LIMIT_HEIGHT_MAX" )));
//max_w = ((getenv( "LIMIT_WIDTH_MAX" )==NULL) ? MAX_SUPPORTED_WIDTH : atoi(getenv( "LIMIT_WIDTH_MAX" )));
//cerr << "Constraints could not be found using default limit\n";
// if hw_de_on && hw_de_supported
// retry_decode_open
// Free options
// Update the File Info struct with video details (if a video stream is found)
// Is there an audio stream?
// Set the stream index
// Get a pointer to the codec context for the audio stream
// Find the codec ID from stream
// Get codec and codec context from stream
// Set number of threads equal to number of processors (not to exceed 16)
// Init options
// Open audio codec
// Free options
// Update the File Info struct with audio details (if an audio stream is found)
// Add format metadata (if any)
// Init previous audio location to zero
// Adjust cache size based on size of frame and audio
// Mark as "open"
// Close all objects, if reader is 'open'
// Mark as "closed"
// Remove previous packet before getting next one
// Close the codec
// Clear final cache
// Clear processed lists
// Close the video file
// Reset some variables
// Set values of FileInfo struct
// Set audio timebase
// Get timebase of audio stream (if valid) and greater than the current duration
// Check for an invalid video length
// Calculate the video length from the audio duration
// Set video timebase (if no video stream was found)
// Set a few important default video settings (so audio can be divided into frames)
// Fix invalid video lengths for certain types of files (MP3 for example)
// Add audio metadata (if any found)
// Already initialized all the video metadata, no reason to do it again
// Set values of FileInfo struct
// set frames per second (fps)
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Get scan type and order from codec context/params
// Check again later?
// check_interlace will prevent these checks being repeated,
// unless it was cleared because we got an AV_FIELD_UNKNOWN response.
// Set the video timebase
// Set the duration in seconds, and video length (# of frames)
// Check for valid duration (if found)
// Use the format's duration
// Calculate duration from filesize and bitrate (if any)
// Estimate from bitrate, total bytes, and framerate
// No duration found in stream of file
// No duration is found in the video stream
// Yes, a duration was found
// Calculate number of frames
// Override an invalid framerate
// Calculate FPS, duration, video bit rate, and video length manually
// by scanning through all the video stream packets
// Add video metadata (if any)
// Check for open reader (or throw exception)
// Adjust for a requested frame that is too small or too large
// Invalid duration of video file
// Debug output
// Check the cache for this frame
// Debug output
// Return the cached frame
// Check the cache a 2nd time (due to a potential previous lock)
// Debug output
// Return the cached frame
// Frame is not in cache
// Reset seek count
// Check for first frame (always need to get frame 1 before other frames, to correctly calculate offsets)
// Get first frame
// Are we within X frames of the requested frame?
// Continue walking the stream
// Greater than 30 frames away, or backwards, we need to seek to the nearest key frame
// Only seek if enabled
// Start over, since we can't seek, and the requested frame is smaller than our position
// Then continue walking the stream
//omp critical
// Read the stream until we find the requested Frame
// Allocate video frame
// Minimum number of packets to process (for performance reasons)
// Set the number of threads in OpenMP
// Allow nested OpenMP sections
// Debug output
// Loop through the stream until the correct frame is found
// Get the next packet into a local variable called packet
// Wait if too many frames are being processed
// Get the next packet (if any)
// Break loop when no more packets found
// Debug output
// Video packet
// Reset this counter, since we have a video packet
// Check the status of a seek (if any)
// Jump to the next iteration of this loop
// Packet may become NULL on Close inside Seek if CheckSeek returns false
// Jump to the next iteration of this loop
// Get the AVFrame from the current packet
// Check if the AVFrame is finished and set it
// Update PTS / Frame Offset (if any)
// Process Video Packet
// Wait on each OMP task to complete before moving on to the next one. This slows
// down processing considerably, but might be more stable on some systems.
// Audio packet
// Increment this (to track # of packets since the last video packet)
// Check the status of a seek (if any)
// Jump to the next iteration of this loop
// Packet may become NULL on Close inside Seek if CheckSeek returns false
// Jump to the next iteration of this loop
// Update PTS / Frame Offset (if any)
// Determine related video frame and starting sample # from audio PTS
// Process Audio Packet
// Check if working frames are 'finished'
// Check for final frames
// Check if requested 'final' frame is available
// Increment frames processed
// Break once the frame is found
// end while
// end omp single
// end omp parallel
// Debug output
// End of stream?
// Mark the any other working frames as 'finished'
// Return requested frame (if found)
// Return prepared frame
// Check if largest frame is still cached
// return the largest processed frame (assuming it was the last in the video file)
// The largest processed frame is no longer in cache, return a blank frame
// Get the next packet (if any)
// Remove previous packet before getting next one
// Update current packet pointer
// Return if packet was found (or error number)
// Get an AVFrame (if any)
// Decode video frame
// Get the format from the variables set in get_hw_dec_format
// No hardware acceleration used -> no copy from GPU memory needed
// TODO also handle possible further frames
// Use only the first frame like avcodec_decode_video2
// always allocate pFrame (because we do that in the ffmpeg >= 3.2 as well); it will always be freed later
// is frame finished
// AVFrames are clobbered on the each call to avcodec_decode_video, so we
// must make a copy of the image data before this method is called again.
// deallocate the frame
// Did we get a video frame?
// Check the current seek position and determine if we need to seek again
// Are we seeking for a specific frame?
// Determine if both an audio and video packet have been decoded since the seek happened.
// If not, allow the ReadStream method to keep looping
// Check for both streams
// Determine max seeked frame
// determine max seeked frame
// determine if we are "before" the requested frame
// SEEKED TOO FAR
// Seek again... to the nearest Keyframe
// SEEK WORKED
// Seek worked, and we are "before" the requested frame
// return the pts to seek to (if any)
// Process a video packet
// Calculate current frame #
// Track 1st video packet after a successful seek
// Are we close enough to decode the frame? and is this frame # valid?
// Remove frame and packet
// Debug output
// Skip to next frame without decoding or caching
// Debug output
// Init some things local (for OpenMP)
// Add video frame to list of processing video frames
// Create variables for a RGB Frame (since most videos are not in RGB, we must convert it)
// Allocate an AVFrame structure
// Determine the max size of this source image (based on the timeline's size, the scaling mode,
// and the scaling keyframes). This is a performance improvement, to keep the images as small as possible,
// without losing quality. NOTE: We cannot go smaller than the timeline itself, or the add_layer timeline
// method will scale it back to timeline size before scaling it smaller again. This needs to be fixed in
// the future.
// Best fit or Stretch scaling (based on max timeline size * scaling keyframes)
// Cropping scale mode (based on max timeline size * cropped size * scaling keyframes)
// respect aspect ratio
// No scaling, use original image size (slower)
// Determine if image needs to be scaled (for performance reasons)
// Override width and height (but maintain aspect ratio)
// use calculated width, and max_height
// use max_width, and calculated height
// Determine required buffer size and allocate buffer
// Copy picture data from one AVFrame (or AVPicture) to another one.
// Resize / Convert to RGB
// Create or get the existing frame object
// Add Image data to frame
// Update working cache
// Keep track of last last_video_frame
// Free the RGB image
// Remove frame and packet
// Remove video frame from list of processing video frames
// Debug output
// end omp task
// Process an audio packet
// Track 1st audio packet after a successful seek
// Are we close enough to decode the frame's audio?
// Debug output
// Skip to next frame without decoding or caching
// Debug output
// Init an AVFrame to hold the decoded audio samples
// re-initialize buffer size (it gets changed in the avcodec_decode_audio2 method call)
// determine how many samples were decoded
// Calculate total number of samples
// Estimate the # of samples and the end of this packet's location (to prevent GAPS for the next timestamp)
// Adjust for zero based array
// DEBUG (FOR AUDIO ISSUES) - Get the audio packet start time (in seconds)
// Debug output
// DEBUG (FOR AUDIO ISSUES)
// Add audio frame to list of processing audio frames
// Get Samples per frame (for this frame number)
// Calculate # of samples to add to this frame
// Decrement remaining samples
// next frame
// Add audio frame to list of processing audio frames
// Increment sample start
// Allocate audio buffer
// Create output frame
// setup resample context
// Convert audio samples
// audio resample context
// output data pointers
// output plane size, in bytes. (0 if unknown)
// maximum number of samples that the output buffer can hold
// input data pointers
// input plane size, in bytes (0 if unknown)
// number of input samples to convert
// Copy audio samples over original samples
// Deallocate resample buffer
// Free AVFrames
// Array of floats (to hold samples for each channel)
// Init buffer array
// Loop through all samples and add them to our Frame based on channel.
// Toggle through each channel number, since channel data is stored like (left right left right)
// Only add samples for current channel
// Add sample (convert from (-32768 to 32768)  to (-1.0 to 1.0))
// Increment audio position
// increment channel (if needed)
// move to next channel
// reset channel
// Loop through samples, and add them to the correct frames
// pointer to channel buffer
// Get Samples per frame (for this frame number)
// Calculate # of samples to add to this frame
// Create or get the existing frame object
// Determine if this frame was "partially" filled in
// Add samples for current channel to the frame. Reduce the volume to 98%, to prevent
// some louder samples from maxing out at 1.0 (not sure why this happens)
// Debug output
// Add or update cache
// Decrement remaining samples
// Increment buffer (to next set of samples)
// Increment frame number
// Reset starting sample #
// clear channel buffer
// Clean up some arrays
// Remove audio frame from list of processing audio frames
// Update all frames as completed
// Remove the frame # from the processing list. NOTE: If more than one thread is
// processing this frame, the frame # will be in this list multiple times. We are only
// removing a single instance of it here.
// Check and see if this frame is also being processed by another thread
// No other thread is processing it. Mark the audio as processed (final)
// This typically never happens, but just in case, remove the currently processing number
// Free audio frame
// Debug output
// Seek to a specific frame.  This is not always frame accurate, it's more of an estimation on many codecs.
// Adjust for a requested frame that is too small or too large
// Debug output
// Wait for any processing frames to complete
// Clear working cache (since we are seeking to another location in the file)
// Clear processed lists
// Reset the last frame variable
// Increment seek count
// If seeking near frame 1, we need to close and re-open the file (this is more reliable than seeking)
// Close and re-open file (basically seeking to frame 1)
// Update overrides (since closing and re-opening might update these)
// Not actually seeking, so clear these flags
// Don't redefine this on multiple seek attempts for a specific frame
// used to detect which frames to throw away after a seek
// used to detect which frames to throw away after a seek
// Seek to nearest key-frame (aka, i-frame)
// Seek video stream (if any)
// VIDEO SEEK
// Seek audio stream (if not already seeked... and if an audio stream is found)
// AUDIO SEEK
// Was the seek successful?
// Flush audio buffer
// Flush video buffer
// Reset previous audio location to zero
// init seek flags
// Don't redefine this on multiple seek attempts for a specific frame
// used to detect which frames to throw away after a seek
// used to detect which frames to throw away after a seek
// seek failed
// dislable seeking for this reader (since it failed)
// TODO: Find a safer way to do this... not sure how common it is for a seek to fail.
// Close and re-open file (basically seeking to frame 1)
// Update overrides (since closing and re-opening might update these)
// Get the PTS for the current video packet
// Return adjusted PTS
// Update PTS Offset (if any)
// Determine the offset between the PTS and Frame number (only for 1st frame)
// VIDEO PACKET
// Has the offset been set yet?
// Find the difference between PTS and frame number (no more than 10 timebase units allowed)
// debug output
// AUDIO PACKET
// Has the offset been set yet?
// Find the difference between PTS and frame number (no more than 10 timebase units allowed)
// debug output
// Convert PTS into Frame Number
// Apply PTS offset
// Get the video packet start time (in seconds)
// Divide by the video timebase, to get the video frame number (frame # is decimal at this point)
// Keep track of the expected video frame #
// Sometimes frames are duplicated due to identical (or similar) timestamps
// return -1 frame number
// Increment expected frame
// has missing frames
// Sometimes frames are missing due to varying timestamps, or they were dropped. Determine
// if we are missing a video frame.
// Mark this reader as containing missing frames
// Increment current frame
// Return frame #
// Convert Frame Number into Video PTS
// Get timestamp of this frame (in seconds)
// Calculate the # of video packets in this timestamp
// Apply PTS offset (opposite)
// Convert Frame Number into Video PTS
// Get timestamp of this frame (in seconds)
// Calculate the # of audio packets in this timestamp
// Apply PTS offset (opposite)
// Calculate Starting video frame and sample # for an audio PTS
// Apply PTS offset
// Get the audio packet start time (in seconds)
// Divide by the video timebase, to get the video frame number (frame # is decimal at this point)
// Frame # as a whole number (no more decimals)
// Remove the whole number, and only get the decimal of the frame
// Get Samples per frame
// Calculate the sample # to start on
// Protect against broken (i.e. negative) timestamps
// Prepare final audio packet location
// Compare to previous audio packet (and fix small gaps due to varying PTS timestamps)
// Update sample start, to prevent gaps in audio
// Debug output
// Debug output
// Set previous location
// Return the associated video frame and starting sample #
// Create a new Frame (or return an existing one) and add it to the working queue.
// Check working cache
// Lock
// (re-)Check working cache
// Create a new frame on the working cache
// update pixel ratio
// update audio channel layout from the parent reader
// update the frame's sample rate of the parent reader
// Set the largest processed frame (if this is larger)
// Return frame
// Determine if frame is partial due to seek
// Sometimes a seek gets partial frames, and we need to remove them
// determine max seeked frame
// Check if a frame is missing and attempt to replace its frame image (and
// Lock
// Increment check count for this frame (or init to 1)
// Debug output
// Missing frames (sometimes frame #'s are skipped due to invalid or missing timestamps)
// Special MP3 Handling (ignore more than 1 video frame)
// If MP3 with single video frame, handle this special case by copying the previously
// decoded image to the new frame. Otherwise, it will spend a huge amount of
// CPU time looking for missing images for all the audio-only frames.
// Check if requested video frame is a missing
// Increment missing source frame check count (or init to 1)
// Get the previous frame of this missing frame (if it's available in missing cache)
// Add missing final frame to missing cache
// Create blank missing frame
// Debug output
// If previous frame found, copy image from previous to missing frame (else we'll just wait a bit and try again later)
// Debug output
// Add this frame to the processed map (since it's already done)
// Check if requested audio frame is a missing
// Create blank missing frame
// Get Samples per frame (for this frame number)
// Debug output
// Add this frame to the processed map (since it's already done)
// Check the working queue, and move finished frames to the finished queue
// Loop through all working queue frames
// Check if requested frame is 'missing'
// Get the front frame of working cache
// Was a frame found?
// No frames found
// Remove frames which are too old
// Check if this frame is 'missing'
// Init # of times this frame has been checked so far
// limit scope of next few lines
// Get check count for this frame
// Force checked count over the limit
// don't finalize the last processed audio frame
// Adjust for available streams
// Make final any frames that get stuck (for whatever reason)
// Debug output
// Trigger checked count tripped mode (clear out all frames before requested frame)
// Copy image from last frame
// Mark audio as processed, and indicate the frame has audio data
// Debug output
// Check if working frame is final
// Debug output
// Add missing image (if needed - sometimes end_of_stream causes frames with only audio)
// Copy image from last frame
// Reset counter since last 'final' frame
// Move frame to final cache
// Add to missing cache (if another frame depends on it)
// Debug output
// Remove from 'checked' count
// Remove frame from working cache
// Update last frame processed
// Seek trash, so delete the frame from the working cache, and never add it to the final cache.
// Stop looping
// Check for the correct frames per second (FPS) value by scanning the 1st few seconds of video packets.
// Loop through the stream
// Get the next packet (if any)
// Break loop when no more packets found
// Video packet
// Check if the AVFrame is finished and set it
// Update PTS / Frame Offset (if any)
// Get PTS of this packet
// Remove pFrame
// Apply PTS offset
// Get the video packet start time (in seconds)
// Increment the correct counter
// Increment counters
// Double check that all counters have greater than zero (or give up)
// Calculate average FPS (average of first few seconds)
// Update FPS
// Update Duration and Length
// Update video bit rate
// Calculate average FPS (only on second 2)
// Update FPS
// Update Duration and Length
// Update video bit rate
// Too short to determine framerate, just default FPS
// Set a few important default video settings (so audio can be divided into frames)
// Calculate number of frames
// Remove AVFrame from cache (and deallocate its memory)
// Remove pFrame (if exists)
// Free memory
// Remove AVPacket from cache (and deallocate its memory)
// deallocate memory for packet
// Delete the object
/// Get the smallest video frame that is still being processed
// Loop through frame numbers
// Return frame number
/// Get the smallest audio frame that is still being processed
// Loop through frame numbers
// Return frame number
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com). This file is part of
//www.openshot.org), an open-source project
//www.gnu.org/licenses/>.
// Multiplexer parameters temporary storage
// Is set in UI
// Is set by FFmpegWriter
// Disable audio & video (so they can be independently enabled)
// Initialize FFMpeg, and register all formats and codecs
// auto detect format
// Open the writer
// Open the writer
// Prepare streams (if needed)
// Now that all the parameters are set, we can open the audio and video codecs and allocate the necessary encode buffers
// Write header (if needed)
// auto detect format (from path)
// Auto detect the output format from the name. default is mpeg.
// Allocate the output media context
// Set the AVOutputFormat for the current AVFormatContext
// Update codec names
// Update video codec name
// Update audio codec name
// initialize streams
// Add the audio and video streams using the default format codecs and initialize the codecs
// Add video stream
// Add audio stream
// Set video export options
// Set the video options
// Check if the codec selected is a hardware accelerated codec
// is FFmpeg 3 but not linux
//__linux__
// not ffmpeg 3
//IS_FFMPEG_3_2
// Set video codec
// Update video codec in fmt
// Set frames per second (if provided)
// Set the timebase (inverse of fps)
// bit_rate is the bitrate in b/s
// bit_rate is the bitrate in crf
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Enable / Disable video
// Set audio export options
// Set audio options
// Set audio codec
// Update audio codec in fmt
// init resample options (if zero)
// Enable / Disable audio
// Set custom options (some codecs accept additional params)
// Declare codec context
// Get codec context
// Get codec context
// Init AVOption
// Was a codec / stream found?
// Find AVOption (if it exists)
// Was option found?
// Check for specific named options
// Set gop_size
// Minimum quantizer
// Maximum quantizer
// Maximum number of B-frames between non-B-frames
// Macroblock decision mode
// Set codec level
// Set codec profile
// Indicates number of picture subdivisions
// Minimum bitrate
// Maximum bitrate
// Buffer size
// encode quality and special settings like lossless
// This might be better in an extra methods as more options
// and way to set quality are possible
// 0-63
// 0-63
// 4-63
// Must be zero!
// 0-63
// 0-51
// 0-51
// For all other codecs assume a range of 0-63
// 0-63
// encode quality and special settings like lossless
// This might be better in an extra methods as more options
// and way to set quality are possible
// 4-63
// Must be zero!
// 0-63
// 0-51
// 0-51
// If this codec doesn't support crf calculate a bitrate
// TODO: find better formula
// Set AVOption
// Muxing dictionary is not part of the codec context.
// Just reusing SetOption function to set popular multiplexing presets.
// 'moov' box to the beginning; only for MOV, MP4
// write selfcontained fragmented file, minimum length of the fragment 8 sec; only for MOV, MP4
/// Determine if codec name is valid
// Initialize FFMpeg, and register all formats and codecs
// Find the codec (if any)
// Prepare & initialize streams and open codecs
// Initialize the streams (i.e. add the streams)
// Mark as 'prepared'
// Write the file header (after the options are set)
// Open the output file, if needed
// Force the output filename (which doesn't always happen for some reason)
// Add general metadata (if any)
// Set multiplexing parameters
// Set dictionary preset only for MP4 and MOV files
// Write the stream header
// Free multiplexing dictionaries sets
// Mark as 'written'
// Add a frame to the queue waiting to be encoded.
// Check for open reader (or throw exception)
// Add frame pointer to "queue", waiting to be processed the next
// time the WriteFrames() method is called.
// Write the frames once it reaches the correct cache size
// Is writer currently writing?
// Write frames to video file
// Write frames to video file
// Keep track of the last frame added
// Write all frames in the queue to the video file.
// Flip writing flag
// Transfer spool to queue
// Empty spool
// Set the number of threads in OpenMP
// Allow nested OpenMP sections
// Create blank exception
// Process all audio frames (in a separate thread)
// Loop through each queued image frame
// Get front frame (from the queue)
// Add to processed queue
// Encode and add the frame to the output file
// Remove front item
// end while
// end omp single
// Loop back through the frames (in order), and write them to the video file
// Get front frame (from the queue)
// Add to deallocate queue (so we can remove the AVFrames when we are done)
// Does this frame's AVFrame still exist
// Get AVFrame
// Write frame to video file
// Remove front item
// Loop through, and deallocate AVFrames
// Get front frame (from the queue)
// Does this frame's AVFrame still exist
// Get AVFrame
// Deallocate AVPicture and AVFrame
// Remove front item
// Done writing
// end omp single
// end omp parallel
// Raise exception from main thread
// Write a block of frames from a reader
// Loop through each frame (and encoded it)
// Get the frame
// Encode frame
// Write the file trailer (after all frames are written)
// Write any remaining queued frames to video file
// Process final audio frame (if any)
// Flush encoders (who sometimes hold on to frames)
/* write the trailer, if any. The trailer must be written
// Mark as 'written'
// Flush encoders
// FLUSH VIDEO ENCODER
// Increment PTS (in frames and scaled to the codec's timebase)
// Pointer for video buffer (if using old FFmpeg version)
/* encode the image */
// Encode video packet (latest version of FFmpeg)
// Write packet
// IS_FFMPEG_3_2
// Encode video packet (older than FFmpeg 3.2)
// Encode video packet (even older version of FFmpeg)
/* encode the image */
/* if zero size, it means the image was buffered */
// got data back (so encode this frame)
// LIBAVFORMAT_VERSION_MAJOR >= 54
// IS_FFMPEG_3_2
// Override PTS (in frames and scaled to the codec's timebase)
//pkt.pts = write_video_count;
// set the timestamp
// Write packet
// Deallocate memory (if needed)
// FLUSH AUDIO ENCODER
// Increment PTS (in samples and scaled to the codec's timebase)
// for some reason, it requires me to multiply channels X 2
/* encode the image */
// Since the PTS can change during encoding, set the value again.  This seems like a huge hack,
// but it fixes lots of PTS related issues when I do this.
// Scale the PTS to the audio stream timebase (which is sometimes different than the codec's timebase)
// set stream
// Write packet
// deallocate memory for packet
// Close the video codec
//  #if defined(__linux__)
//  #endif
// Close the audio codec
// Clear buffers
// Deallocate resample buffer
// Close the writer
// Write trailer (if needed)
// Close each codec
// Deallocate image scalers
/* close the output file */
// Reset frame counters
// Free the context which frees the streams too
// Close writer
// Add an AVFrame to the cache
// Add AVFrame to map (if it does not already exist)
// Add av_frame
// Do not add, and deallocate this AVFrame
// Add an audio output stream
// Find the audio codec
// Create a new audio stream
// Set the sample parameters
// Set valid sample rate (or throw error)
// Set the valid sample rate
// Set sample rate
// Set a valid number of channels (or throw error)
// Set valid channel layout
// Set valid channel layout
// Choose a valid sample_fmt
// Set sample format to 1st valid format (and then exit loop)
// Default if no sample formats found
// some formats want stream headers to be separate
// Add a video output stream
// Find the video codec
// Create a new video stream
/* Init video encoder options */
// Here should be the setting for low fixed bitrate
// Defaults are used because mpeg2 otherwise had problems
// Check if codec supports crf
// Here should be the setting for codecs that don't support crf
// For now defaults are used
//TODO: Implement variable bitrate feature (which actually works). This implementation throws
//invalid bitrate errors and rc buffer underflow errors, etc...
//c->rc_min_rate = info.video_bit_rate;
//c->rc_max_rate = info.video_bit_rate;
//c->rc_buffer_size = FFMAX(c->rc_max_rate, 15000000) * 112L / 15000000 * 16384;
//if ( !c->rc_initial_buffer_occupancy )
//	c->rc_initial_buffer_occupancy = c->rc_buffer_size * 3/4;
/* resolution must be a multiple of two */
// TODO: require /2 height and width
/* time base: this is the fundamental unit of time (in seconds) in terms
// AVCodecContext->framerate was added in FFmpeg 2.2
/* TODO: add this to "info"... emit one intra frame every twelve frames at most */
/* just for testing, we also add B frames */
/* Needed to avoid using macroblocks in which some coeffs overflow.
// some formats want stream headers to be separate
// Find all supported pixel formats for this codec
// Assign the 1st valid pixel format (if one is missing)
// Codec doesn't have any pix formats?
// Raw video should use RGB24
// If not GIF format, skip the encoding process
// Set raw picture flag (so we don't encode this video)
// Set the default codec
// open audio codec
// Set number of threads equal to number of processors (not to exceed 16)
// Find the audio encoder
// Init options
// Open the codec
// Free options
// Calculate the size of the input frame (i..e how many samples per packet), and the output buffer
// TODO: Ugly hack for PCM codecs (will be removed ASAP with new PCM support to compute the input frame size in samples
// No frame size found... so calculate
// Set frame size based on the codec
// Set the initial frame size (since it might change during resampling)
// Allocate array for samples
// Set audio output buffer (used to store the encoded audio)
// Set audio packet encoding buffer
// Add audio metadata (if any)
// open video codec
// Set number of threads equal to number of processors (not to exceed 16)
//char *dev_hw = NULL;
// Use the hw device given in the environment variable HW_EN_DEVICE_SET or the default if not set
// Maybe 127 is better because the first card would be 1?!
// Just to be sure
// Check if it is there and writable
// use default
/* find the video encoder */
/* Force max_b_frames to 0 in some cases (i.e. for mjpeg image sequences */
// Init options
// for the list of possible options, see the list of codec-specific options:
// e.g. ffmpeg -h encoder=h264_vaapi or ffmpeg -h encoder=hevc_vaapi
// and "man ffmpeg-codecs"
// For VAAPI, it is safer to explicitly set rc_mode instead of relying on auto-selection
// which is ffmpeg version-specific.
// unless "qp" was set for CQP, switch to VBR RC mode
// In the current state (ffmpeg-4.2-4 libva-mesa-driver-19.1.5-1) to use VBR,
// one has to specify both bit_rate and maxrate, otherwise a small low quality file is generated on Intel iGPU).
// At least this GPU doesn't support b-frames
// tested to work with defaults
// tested to work with defaults
// set hw_frames_ctx for encoder's AVCodecContext
/* open the codec */
// Free options
// Add video metadata (if any)
// write all queued frames' audio to the video file
// Init audio buffers / variables
// default channel layout
// Create a new array (to hold all S16 audio samples, for the current queued frames
// Loop through each queued audio frame
// Get front frame (from the queue)
// Get the audio details from this frame
// Get audio sample array
// Get samples interleaved together (c1 c2 c1 c2 c1 c2)
// Calculate total samples
// Translate audio sample values back to 16 bit integers
// Translate sample value and copy into buffer
// Deallocate float array
// Remove front item
// end while
// Update total samples (since we've combined all queued frames)
// Keep track of the original sample format
// Create input frame (and allocate arrays)
// Fill input frame with sample data
// Do not convert audio to planar format (yet). We need to keep everything interleaved at this point.
// This is only here to silence unused-enum warnings
// Update total samples & input frame size (due to bigger or smaller data types)
// adjust for different byte sizes
// adjust for different # of channels
// Create output frame (and allocate arrays)
// setup resample context
// planar not allowed here
// Convert audio samples
// audio resample context
// output data pointers
// output plane size, in bytes. (0 if unknown)
// maximum number of samples that the output buffer can hold
// input data pointers
// input plane size, in bytes (0 if unknown)
// number of input samples to convert
// Set remaining samples
// Create a new array (to hold all resampled S16 audio samples)
// Copy audio samples over original samples
// Remove converted audio
// this array cleared with above call
// Loop until no more samples
// Get remaining samples needed for this packet
// Determine how many samples we need
// Copy frame samples into the packet samples array
//TODO: Make this more sane
// Increment counters
// Do we have enough samples to proceed?
// Not enough samples to encode... so wait until the next frame
// Convert to planar (if needed by audio codec)
// setup resample context
// planar not allowed here
// Create input frame (and allocate arrays)
// Create a new array
// Copy audio into buffer for frame
// Fill input frame with sample data
// Create output frame (and allocate arrays)
// Convert audio samples
// audio resample context
// output data pointers
// output plane size, in bytes. (0 if unknown)
// maximum number of samples that the output buffer can hold
// input data pointers
// input plane size, in bytes (0 if unknown)
// number of input samples to convert
// Copy audio samples over original samples
// deallocate AVFrame
// this array cleared with above call
// Create a new array
// Copy audio into buffer for frame
// Init the nb_samples property
// Fill the final_frame AVFrame with audio (non planar)
// Increment PTS (in samples)
// Set the AVFrame's PTS
// Init the packet
// Set the packet's PTS prior to encoding
/* encode the audio samples */
// Encode audio (latest version of FFmpeg)
// Encode audio (older versions of FFmpeg)
/* if zero size, it means the image was buffered */
// Since the PTS can change during encoding, set the value again.  This seems like a huge hack,
// but it fixes lots of PTS related issues when I do this.
// Scale the PTS to the audio stream timebase (which is sometimes different than the codec's timebase)
// set stream
/* write the compressed frame in the media file */
// deallocate AVFrame
// deallocate memory for packet
// Reset position
// Delete arrays (if needed)
// end task
// Allocate an AVFrame object
// Create an RGB AVFrame
// Allocate an AVFrame structure
// Determine required buffer size and allocate buffer
// Create buffer (if not provided)
// New Buffer
// Attach buffer to AVFrame
// return AVFrame
// process video frame
// Determine the height & width of the source image
// Do nothing if size is 1x1 (i.e. no image in this frame)
// Init rescalers (if not initialized yet)
// Get a unique rescaler (for this thread)
// Allocate an RGB frame & final output frame
// Get a list of pixels from source image
// Init AVFrame for source image & final (converted image)
// Fill with data
// Resize & convert pixel format
// Add resized AVFrame to av_frames map
// Deallocate memory
// end task
// write video frame
// Raw video case.
// Increment PTS (in frames and scaled to the codec's timebase)
/* write the compressed frame in the media file */
// Deallocate packet
// Pointer for video buffer (if using old FFmpeg version)
// Increment PTS (in frames and scaled to the codec's timebase)
// Assign the initial AVFrame PTS from the frame counter
/* encode the image */
// Write video packet (latest version of FFmpeg)
//hw_frame!!!
// Write video packet (older than FFmpeg 3.2)
// Write video packet (even older versions of FFmpeg)
/* encode the image */
/* if zero size, it means the image was buffered */
// got data back (so encode this frame)
/* if zero size, it means the image was buffered */
// Since the PTS can change during encoding, set the value again.  This seems like a huge hack,
// but it fixes lots of PTS related issues when I do this.
//pkt.pts = pkt.dts = write_video_count;
// set the timestamp
/* write the compressed frame in the media file */
// Deallocate memory (if needed)
// Deallocate packet
// Success
// Output the ffmpeg info about this format, streams, and codecs (i.e. dump format)
// output debug info
// Init a collection of software rescalers (thread safe)
// Init software rescalers vector (many of them, one for each thread)
// Init the software scaler from FFMpeg
// Add rescaler to vector
// Set audio resample options
// Remove & deallocate all software scalers
// Close all rescalers
// Clear vector
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor
// Return this fraction as a float (i.e. 1/2 = 0.5)
// Return this fraction as a double (i.e. 1/2 = 0.5)
// Return a rounded integer of the frame rate (for example 30000/1001 returns 30 fps)
// Calculate the greatest common denominator
// Find the biggest whole number that will divide into both the numerator
// and denominator
// Get the greatest common denominator
// Reduce this fraction to the smallest possible whole numbers
// Return the reciprocal as a new Fraction
// flip the fraction
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor - blank frame (300x200 blank image, 48kHz audio silence)
// Init the image magic and audio buffer
// initialize the audio samples to zero (silence)
// Constructor - image only (48kHz audio silence)
// Init the image magic and audio buffer
// initialize the audio samples to zero (silence)
// Constructor - audio only (300x200 blank image)
// Init the image magic and audio buffer
// initialize the audio samples to zero (silence)
// Constructor - image & audio
// Init the image magic and audio buffer
// initialize the audio samples to zero (silence)
// Copy constructor
// copy pointers and data
// Assignment operator
// copy pointers and data
// Copy data and pointers from another Frame instance
// Destructor
// Clear all pointers
// Display the frame image to the screen (primarily used for debugging reasons)
// Only create the QApplication once
// Get preview image
// Update the image to reflect the correct pixel aspect ration (i.e. to fix non-squar pixels)
// Calculate correct DAR (display aspect ratio)
// Resize to fix DAR
// Create window
// Create label with current frame's image
// Show the window
// Get an audio waveform image
// Clear any existing waveform image
// Init a list of lines
// Calculate width of an image based on the # of samples
// If samples are present...
// Loop through each audio channel
// Get audio for this channel
// Sample value (scaled to -100 to 100)
// Append a line segment for each sample
// LINE
// DOT
// Add Channel Label Coordinate
// Increment Y
// Create blank image
// Load QPainter with wave_image device
// Set pen color
// Draw the waveform
// Loop through the channels labels (and draw the text)
// TODO: Configure Fonts in Qt5 correctly, so the drawText method does not crash
//		painter.setFont(QFont(QString("Arial"), 16, 1, false));
//		for (int channel = 0; channel < labels.size(); channel++) {
//			stringstream label;
//			label << "Channel " << channel;
//		    painter.drawText(labels.at(channel), QString::fromStdString(label.str()));
//		}
// Resize Image (if requested)
// No audio samples present
// Return new image
// Clear the waveform image (and deallocate its memory)
// Get an audio waveform image pixels
// Get audio wave form image
// Return array of pixel packets
// Display the wave form
// Get audio wave form image
// Only create the QApplication once
// Create window
// Create label with current frame's waveform image
// Show the window
// Deallocate waveform image
// Get magnitude of range of samples (if channel is -1, return average of all channels for that sample)
// return average magnitude for a specific channel/sample range
// Return average magnitude for all channels
// Get an array of sample data
// return JUCE audio data for this channel
// Get a planar array of sample data, using any sample rate
// Resample to new sample rate (if needed)
// YES, RESAMPLE AUDIO
// Resample data, and return new buffer pointer
// Update num_of_samples
// INTERLEAVE all samples together (channel 1 + channel 2 + channel 1 + channel 2, etc...)
// Loop through samples in each channel (combining them)
// Add sample to output array
// increment position
// Update sample count (since it might have changed due to resampling)
// return combined array
// Get an array of sample data (all channels interleaved together), using any sample rate
// Resample to new sample rate (if needed)
// YES, RESAMPLE AUDIO
// Resample data, and return new buffer pointer
// Update num_of_samples
// INTERLEAVE all samples together (channel 1 + channel 2 + channel 1 + channel 2, etc...)
// Loop through samples in each channel (combining them)
// Add sample to output array
// increment position
// Update sample count (since it might have changed due to resampling)
// return combined array
// Get number of audio channels
// Get number of audio samples
// Get the size in bytes of this frame (rough estimate)
// approximate audio size (sample rate / 24 fps)
// return size of this frame
// Get pixel data (as packets)
// Check for blank image
// Fill with black
// Return array of pixel packets
// Get pixel data (for only a single scan-line)
// Return array of pixel packets
// Check a specific pixel color value (returns True/False)
// Find column array position
// invalid row / col
// Check pixel color
// Pixel color matches successfully
// Pixel color does not match
// Set Pixel Aspect Ratio
// Set frame number
// Calculate the # of samples per video frame (for a specific frame number and frame rate)
// Get the total # of samples for the previous frame, and the current frame (rounded)
// Determine previous samples total, and make sure it's evenly divisible by the # of channels
// subtract the remainder to the total (to make it evenly divisible)
// Determine the current samples total, and make sure it's evenly divisible by the # of channels
// subtract the remainder to the total (to make it evenly divisible)
// Subtract the previous frame's total samples with this frame's total samples.  Not all sample rates can
// be evenly divided into frames, so each frame can have have different # of samples.
// Calculate the # of samples per video frame (for the current frame number)
// Get height of image
// Get height of image
// Get the original sample rate of this frame's audio data
// Get the original sample rate of this frame's audio data
// Save the frame image to the specified path.  The image format is determined from the extension (i.e. image.PNG, image.JPEG)
// Get preview image
// scale image if needed
// Update the image to reflect the correct pixel aspect ration (i.e. to fix non-squar pixels)
// Calculate correct DAR (display aspect ratio)
// Resize to fix DAR
// Resize image
// Save image
// Thumbnail the frame image to the specified path.  The image format is determined from the extension (i.e. image.PNG, image.JPEG)
// Create blank thumbnail image & fill background color
// Create painter
// Get preview image
// Update the image to reflect the correct pixel aspect ration (i.e. to fix non-squar pixels)
// Calculate correct DAR (display aspect ratio)
// Resize to fix DAR
// Resize frame image
// Ignore aspect ratio
// Maintain aspect ratio
// Composite frame image onto background (centered)
// center
// center
// Create transform and rotate (if needed)
// Draw image onto QImage
// Overlay Image (if any)
// Open overlay
// Set pixel format
// Resize to fit
// Composite onto thumbnail
// Mask Image (if any)
// Open mask
// Set pixel format
// Resize to fit
// Negate mask
// Get pixels
// Convert the mask image to grayscale
// Loop through pixels
// Get the RGB values from the pixel
// Set all alpha pixels to gray value
// End painter
// Save image
// Constrain a color value from 0 to 255
// Constrain new color from 0 to 255
// Add (or replace) pixel data to the frame (based on a solid color)
// Set color
// Create new image object, and fill with pixel data
// Fill with solid color
// Update height and width
// Add (or replace) pixel data to the frame
// Create new buffer
// Copy buffer data
// Create new image object, and fill with pixel data
// Always convert to RGBA8888 (if different)
// Update height and width
// Add (or replace) pixel data to the frame
// Ignore blank images
// assign image data
// Always convert to RGBA8888 (if different)
// Update height and width
// Add (or replace) pixel data to the frame (for only the odd or even lines)
// Ignore blank new_image
// Check for blank source image
// Replace the blank source image
// Ignore image of different sizes or formats
// Get the frame's image
// Loop through the scanlines of the image (even or odd)
// Update height and width
// Resize audio container to hold more (or less) samples and channels
// Resize JUCE audio buffer
// Calculate max audio sample added
// Add audio samples to a specific channel
// Clamp starting sample to 0
// Extend audio container to hold more (or less) samples and channels.. if needed
// Clear the range of samples first (if needed)
// Add samples to frame's audio buffer
// Calculate max audio sample added
// Apply gain ramp (i.e. fading volume)
// Apply gain ramp
// Get pointer to Magick++ image object
// Check for blank image
// Fill with black
// Get pointer to ImageMagick image object
// Check for blank image
// Fill with black
// Get the pixels from the frame image
// Create new image object, and fill with pixel data
// Give image a transparent background color
// Get pointer to QImage of frame
/// Use realloc for fast memory allocation.
/// TODO: consider locking the buffer for mt safety
//qbuffer = reinterpret_cast<unsigned char*>(realloc(qbuffer, bufferSize));
// TODO: Actually do something, if we get an exception here
// Create QImage of frame data
// Update height and width
// Play audio samples for this frame
// Check if samples are present
/* number of input channels */
/* number of output channels */
/* no XML settings.. */
/* select default device on failure */);
// Output error (if any)
// Create TimeSliceThread for audio buffering
// Start thread
// tells it to buffer this many samples ahead
// sample rate of source
// Create MIXER
// Start transports
// Clean up buffer after QImage is deleted
// Remove buffer since QImage tells us to
// Add audio silence
// Resize audio container
// Calculate max audio sample added
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Set the original frame rate from the reader
// Set all info struct members equal to the internal reader
// Used to toggle odd / even fields
// Adjust cache size based on size of frame and audio
// Destructor
// Auto Close if not already
/// Get the current reader
// Throw error if reader not initialized
// Add a field, and toggle the odd / even field
// Add a field to the end of the field list
// toggle the odd / even flag
// Use the original and target frame rates and a pull-down technique to create
// a mapping between the original fields and frames or a video to a new frame rate.
// This might repeat or skip fields and frames of the original video, depending on
// whether the frame rate is increasing or decreasing.
// Do not initialize anything if just a picture with no audio
// Skip initialization
// Clear the fields & frames lists
// Mark as not dirty
// Clear cache
// Some framerates are handled special, and some use a generic Keyframe curve to
// map the framerates. These are the special framerates:
// Get the difference (in frames) between the original and target frame rates
// Find the number (i.e. interval) of fields that need to be skipped or repeated
// Get frame interval (2 fields per frame)
// Calculate # of fields to map
// Loop through all fields in the original video file
// Same frame rate, NO pull-down or special techniques required
// Add fields
// Need to ADD fake fields & frames, because original video has too few frames
// Add current field
// Add extra field for each 'field interval
// Add both extra fields in the middle 'together' (i.e. 2:3:3:2 technique)
// add field for current frame
// add field for next frame (if the next frame exists)
// No pull-down technique needed, just repeat this frame
// Need to SKIP fake fields & frames, because we want to return to the original film frame rate
// skip current field and toggle the odd/even flag
// skip this field, plus the next field
// skip this field, plus the next one
// No skipping needed, so add the field
// increment frame number (if field is divisible by 2)
// Map the remaining framerates using a linear algorithm
// Calculate the value difference
// Loop through curve, and build list of frames
// Add 2 fields per frame
// Increment original frame number
// Loop through the target frames again (combining fields into frames)
// temp field used to track the ODD field
// temp field used to track the EVEN field
// Variables used to remap audio samples
// Get the current field
// Is field divisible by 2?
// New frame number
// Set the bottom frame
// Determine the range of samples (from the original rate). Resampling happens in real-time when
// calling the GetFrame() method. So this method only needs to redistribute the original samples with
// the original sample rate.
// get original samples
// Enough samples
// Take all that we need, and break loop
// Not enough samples (take them all, and keep looping)
// next frame
// next frame, starting on 1st sample
// reduce the remaining amount
// Create the sample mapping struct
// Reset the audio variables
// increment the frame (since we need to wrap onto the next one)
// reset to 0, since we wrapped
// Create a frame and ADD it to the frames collection
// Set the top field
// Clear the internal fields list (no longer needed)
// Check if mappings are dirty (and need to be recalculated)
// Recalculate mappings
// Ignore mapping on single image readers
// Return the same number
// Check if frame number is valid
// frame too small, return error
// frame too large, set to end frame
// Debug output
// Return frame
// Get or generate a blank frame
// Init some basic properties about this frame (keep sample rate and # channels the same as the original reader for now)
// Debug output
// Attempt to get a frame (but this could fail if a reader has just been closed)
// Return real frame
// ...
// ...
// ...
// Debug output
// Create blank frame
// Get an openshot::Frame object for a specific frame number of this reader.
// Check final cache, and just return the frame (if it's available)
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Check if mappings are dirty (and need to be recalculated)
// Recalculate mappings
// Check final cache a 2nd time (due to potential lock already generating this frame)
// Minimum number of frames to process (for performance reasons)
// Dialing this down to 1 for now, as it seems to improve performance, and reduce export crashes
// Debug output
// Loop through all requested frames
// Debug output
// Get the mapped frame
// Get the mapped frame (keeping the sample rate and channels the same as the original... for the moment)
// Get # of channels in the actual frame
// Determine if mapped frame is identical to source frame
// including audio sample distribution according to mapped.Samples,
// and frame_number. In some cases such as end of stream, the reader
// will return a frame with a different frame number. In these cases,
// we cannot use the frame as is, nor can we modify the frame number,
// otherwise the reader's cache object internals become invalid.
// in some conditions (e.g. end of stream)
// Add original frame to cache, and skip the rest (for performance reasons)
// Create a new frame
// Copy the image from the odd field
// Add even lines (if different than the previous image)
// Resample audio on frame (if needed)
// Resample audio and correct # of channels if needed
// create a copy of mapped.Samples that will be used by copy loop
// Resampling needed, modify copy of SampleRange object that
// includes some additional input samples on first iteration,
// and continues the offset to ensure that the sample rate
// converter isn't input limited.
// Extend end sample count by an additional EXTRA_INPUT_SAMPLES samples
// check for wrapping
// Sample rate conversion has been allocated on this clip, so
// this is not the first iteration. Extend start position by
// EXTRA_INPUT_SAMPLES to keep step with previous frame
// check for wrapping
// Copy the samples
// Init number of samples to copy this iteration
// number of original samples on this frame
// Loop through each channel
// Starting frame (take the ending samples)
// Add samples to new frame
// Middle frame (take all samples)
// Add samples to new frame
// Ending frame (take the beginning samples)
// Add samples to new frame
// increment frame
// Resample audio on frame (if needed)
// Resample audio and correct # of channels if needed
// Add frame to final cache
// for loop
// Return processed openshot::Frame
// Check if mappings are dirty (and need to be recalculated)
// Recalculate mappings
// Get the difference (in frames) between the original and target frame rates
// Find the number (i.e. interval) of fields that need to be skipped or repeated
// Get frame interval (2 fields per frame)
// Loop through frame mappings
// Determine if reader is open or closed
// Open the internal reader
// Open the reader
// Close the internal reader
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Close internal reader
// Clear the fields & frames lists
// Mark as dirty
// Clear cache
// Deallocate resample buffer
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Re-Open path, and re-init everything (if needed)
// Change frame rate or audio mapping details
// Mark as dirty
// Update mapping details
// Clear cache
// Adjust cache size based on size of frame and audio
// Deallocate resample buffer
// Resample audio and map channels (if needed)
// Check if mappings are dirty (and need to be recalculated)
// Recalculate mappings
// Init audio buffers / variables
// Get audio sample array
// Get samples interleaved together (c1 c2 c1 c2 c1 c2)
// Calculate total samples
// Create a new array (to hold all S16 audio samples for the current queued frames)
// Translate audio sample values back to 16 bit integers
// Translate sample value and copy into buffer
// Deallocate float array
// Create input frame (and allocate arrays)
// Update total samples & input frame size (due to bigger or smaller data types)
// Create output frame (and allocate arrays)
// setup resample context
// Convert audio samples
// audio resample context
// output data pointers
// output plane size, in bytes. (0 if unknown)
// maximum number of samples that the output buffer can hold
// input data pointers
// input plane size, in bytes (0 if unknown)
// number of input samples to convert
// Create a new array (to hold all resampled S16 audio samples)
// Copy audio samples over original samples
// Free frames
// Resize the frame to hold the right # of channels and samples
// Array of floats (to hold samples for each channel)
// Divide audio into channels. Loop through each channel
// Init array
// Loop through all samples and add them to our Frame based on channel.
// Toggle through each channel number, since channel data is stored like (left right left right)
// Only add samples for current channel
// Add sample (convert from (-32768 to 32768)  to (-1.0 to 1.0))
// Increment audio position
// increment channel (if needed)
// move to next channel
// reset channel
// Add samples to frame for this channel
// Update frame's audio meta data
// clear channel buffer
// Delete arrays
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Require ImageMagick support
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open image file
// Open reader if not already open
// Attempt to open file
// load image
// Give image a transparent background color
// raise exception
// Update image properties
// 1 hour duration
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close image file
// Close all objects, if reader is 'open'
// Mark as "closed"
// Delete the image
// Get an openshot::Frame object for a specific frame number of this reader.
// Check for open reader (or throw exception)
// Create or get frame object
// Add Image data to frame
// return frame object
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
//USE_IMAGEMAGICK
/**
/* LICENSE
//www.openshotstudios.com). This file is part of
//www.openshot.org), an open-source project
//www.gnu.org/licenses/>.
//Require ImageMagick support
// Disable audio & video (so they can be independently enabled)
// Set video export options
// Set frames per second (if provided)
// Set image magic properties
// Set the timebase (inverse of fps)
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Open the writer
// Add a frame to the queue waiting to be encoded.
// Check for open reader (or throw exception)
// Copy and resize image
// Calculate correct DAR (display aspect ratio)
// Resize image
// Put resized frame in vector (waiting to be written)
// Keep track of the last frame added
// Write a block of frames from a reader
// Loop through each frame (and encoded it)
// Get the frame
// Encode frame
// Close the writer and encode/output final image to the disk.
// Write frame's image to file
// Clear frames vector
// Reset frame counters
// Close writer
//USE_IMAGEMAGICK
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Bernstein polynoms
// Constructor which sets the default point & coordinate at X=1
// Add initial point
// Add a new point on the key-frame.  Each point has a primary coordinate,
// a left handle, and a right handle.
// candidate is not less (greater or equal) than the new point in
// the X coordinate.
// New point X is greater than all other points' X, add to
// back.
// New point is at same X coordinate as some point, overwrite
// point.
// New point needs to be inserted before candidate; thus move
// candidate and all following one to the right and insert new
// point then where candidate was.
// Make space; could also be a dummy point. INVALIDATES candidate!
// Add a new point on the key-frame, with some defaults set (BEZIER)
// Create a point
// Add the point
// Add a new point on the key-frame, with a specific interpolation type
// Create a point
// Add the point
// Get the index of a point by matching a coordinate
// loop through points, and find a matching coordinate
// Get each point
// find a match
// Remove the matching point, and break out of loop
// no matching point found
// Determine if point already exists
// Get current point (or closest point) from the X coordinate (i.e. the frame number)
// Finds a point with an X coordinate which is "not less" (greater
// or equal) than the queried X coordinate.
// All points are before the queried point.
//
// Note: Behavior the same regardless of useLeft!
// First point is greater or equal to the queried point.
//
// Note: Behavior the same regardless of useLeft!
// Get current point (or closest point to the right) from the X coordinate (i.e. the frame number)
// Get previous point (if any)
// Lookup the index of this point
// If not the 1st point
// No previous point
// Get max point (by Y coordinate)
// Get the value at a specific index
// index is behind last point
// index is at or before first point
// index is directly on a point
// Get the rounded INT value at a specific index
// Get the rounded INT value at a specific index
// Get the direction of the curve at a specific index (increasing or decreasing)
// After the last point, thus constant.
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// loop through points, and find a matching coordinate
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Clear existing points
// loop through points
// Create Point
// Load Json into Point
// Add Point to Keyframe
// Get the fraction that represents how many times this value is repeated in the curve
// This is depreciated and will be removed soon.
// Frame numbers (index) outside of the "defined" range of this
// keyframe result in a 1/1 default value.
// Due to ! ((index + 1) >= GetLength) there are at least two points!
// First, get the value at the given frame and the closest point
// to the right.
// Due to the (index + 1) >= GetLength check above!
// Calculate how many of the next values are going to be the same:
// If the index (frame number) is the X coordinate of the closest
// point, then look at the segment to the right; the "current"
// segement is not interesting because we're already at the last
// value of it.
// Skip over "constant" (when rounded) segments.
// Found a point which defines a segment which will give a
// different value than the current value.  This means we
// moved at least one segment to the right, thus we cannot be
// at the first point.
// All values to the right are the same!
// Now look to the left, to the previous values.
// The binary search below assumes i to be the left point;
// candidate is the right point of the current segment
// though. So change this if possible. If this branch is NOT
// taken, then we're at/before the first point and all is
// constant!
// Skip over constant (when rounded) segments!
// Special case when skipped until the first point, but the first
// point is actually different.  Will not happen if index is
// before the first point!
// There are at least two points, and we're not at the end,
// thus the following is safe!
// Every previous value is the same (rounded) as the current
// value.
// Get the change in Y value (from the previous Y value)
// Get a point at a specific index
// Is index a valid point?
// Invalid index
// Get the number of values (i.e. coordinates on the X axis)
// Get the number of points (i.e. # of points)
// Remove a point by matching a coordinate
// loop through points, and find a matching coordinate
// Get each point
// find a match
// Remove the matching point, and break out of loop
// no matching point found
// Remove a point by index
// Is index a valid point?
// Remove a specific point by index
// Invalid index
// Remove matching point
// Add new point
// Scale all points by a percentage (good for evenly lengthening or shortening an openshot::Keyframe)
// 1.0 = same size, 1.05 = 5% increase, etc...
// TODO: What if scale is small so that two points land on the
// same X coordinate?
// TODO: What if scale < 0?
// Loop through each point (skipping the 1st point)
// Scale X value
// Flip all the points in this openshot::Keyframe (useful for reversing an effect or transition, etc...)
// Flip the points
// TODO: check that this has the desired effect even with
// regards to handles!
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Display a loading animation
// Play the video
// Pause the video
// Get the Playback speed
// Set the Playback speed multiplier (1.0 = normal speed, <1.0 = slower, >1.0 faster)
// Stop the video player and clear the cached frames
// Get the current reader, such as a FFmpegReader
// Set the current reader, such as a FFmpegReader
// Get the Volume
// Set the Volume multiplier (1.0 = normal volume, <1.0 = quieter, >1.0 louder)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor (defaults to 1,0)
// set new coorinate
// set handles
// Constructor which creates a single coordinate at X=1
// set new coorinate
// set handles
// set new coorinate
// set handles
// Constructor which also creates a Point and sets the X,Y, and interpolation of the Point.
// set new coorinate
// set handles
// set handles
// set handles
// set handles
// initialize left and right handles (in percentages from 0 to 1)
// default to a smooth curve
// initialize left handle (in percentages from 0 to 1)
// initialize right handle (in percentages from 0 to 1)
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// update coordinate
// update coordinate
// update coordinate
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// @brief Constructor for Profile.
// @param path 	The folder path / location of a profile file
// Initialize info values
// Split current line
// update struct (based on line number)
// Error parsing profile file
// Throw error if file was not read
// Error parsing profile file
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Default constructor (blank text)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...)
// Open reader
// Open reader if not already open
// create image
//start painting
//set background
//draw text
//disable redo/undo stack as not needed
//create the HTML/CSS document
// Draw image
// Update image properties
// 1 hour duration
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close reader
// Close all objects, if reader is 'open'
// Mark as "closed"
// Delete the image
// Get an openshot::Frame object for a specific frame number of this reader.
// Create or get frame object
// Add Image data to frame
// return frame object
// return empty frame
// return frame object
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// If defined and found in CMake, utilize the libresvg for parsing
// SVG files and rasterizing them to QImages.
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open image file
// Open reader if not already open
// If defined and found in CMake, utilize the libresvg for parsing
// SVG files and rasterizing them to QImages.
// Only use resvg for files ending in '.svg' or '.svgz'
// Attempt to open file using Qt's build in image processing capabilities
// raise exception
// Convert to proper format
// Update image properties
// 1 hour duration
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Set current max size
// Mark as "open"
// Close image file
// Close all objects, if reader is 'open'
// Mark as "closed"
// Delete the image
// Get an openshot::Frame object for a specific frame number of this reader.
// Check for open reader (or throw exception)
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Determine the max size of this source image (based on the timeline's size, the scaling mode,
// and the scaling keyframes). This is a performance improvement, to keep the images as small as possible,
// without losing quality. NOTE: We cannot go smaller than the timeline itself, or the add_layer timeline
// method will scale it back to timeline size before scaling it smaller again. This needs to be fixed in
// the future.
// Best fit or Stretch scaling (based on max timeline size * scaling keyframes)
// Cropping scale mode (based on max timeline size * cropped size * scaling keyframes)
// respect aspect ratio
// No scaling, use original image size (slower)
// Scale image smaller (or use a previous scaled image)
// If defined and found in CMake, utilize the libresvg for parsing
// SVG files and rasterizing them to QImages.
// Only use resvg for files ending in '.svg' or '.svgz'
// Scale SVG size to keep aspect ratio, and fill the max_size as best as possible
// Create empty QImage
// Render SVG into QImage
// We need to resize the original image to a smaller image (for performance reasons)
// Only do this once, to prevent tons of unneeded scaling operations
// Set max size (to later determine if max_size is changed)
// Create or get frame object
// Add Image data to frame
// return frame object
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Delegating constructor
// Constructor
// Close audio device (only do this once, when all audio playback is finished)
// Return any error string during initialization
// Get error from audio thread (if any)
/// Get Audio Devices from JUCE
// Set the reader
// Set mode to playing, and speed to normal
// Start thread only once
/// Get the current mode
// Check for seek
// Notify cache thread that seek has occurred
// Update current position
// Clear last position (to force refresh)
// Notify audio thread that seek has occurred
// Change mode to stopped
// Notify threads of stopping
// Kill all threads
// Set the reader object
// Set new reader. Note: Be sure to close and dispose of the old reader after calling this
// Get the current reader, such as a FFmpegReader
// Set the QWidget pointer to display the video on (as a LONG pointer id)
// Update override QWidget address on the video renderer
// Get the Renderer pointer address (for Python to cast back into a QObject)
// Get the Playback speed
// Set the Playback speed multiplier (1.0 = normal speed, <1.0 = slower, >1.0 faster)
// Get the Volume
// Set the Volume multiplier (1.0 = normal volume, <1.0 = quieter, >1.0 louder)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Default constructor (blank text)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...) plus the text background color
// Open reader
// Open reader if not already open
// create image
// set background
// set font color
// set font
// Set gravity (map between OpenShot and Qt)
// Draw image
// Update image properties
// 1 hour duration
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close reader
// Close all objects, if reader is 'open'
// Mark as "closed"
// Delete the image
// Get an openshot::Frame object for a specific frame number of this reader.
// Create or get frame object
// Add Image data to frame
// return frame object
// return empty frame
// return frame object
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Constructor for the base reader, where many things are initialized.
// Initialize info struct
// Init parent clip
// Display file information
// Iterate through metadata
// Generate Json::JsonValue for this object
// Create root json object
// Append metadata map
// return JsonValue
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
/// Parent clip object of this reader (which can be unparented and NULL)
/// Set parent clip object of this reader
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Global reference to logger
// Create or Get an instance of the logger singleton
// Create the actual instance of logger only once
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Require ImageMagick support
/// Default constructor (blank text)
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open and Close the reader, to populate its attributes (such as height, width, etc...)
// Open and Close the reader, to populate it's attributes (such as height, width, etc...) plus the text background color
// Open reader
// Open reader if not already open
// create image
// Give image a transparent background color
// Set gravity (map between OpenShot and ImageMagick)
// Set stroke properties
// Draw image
// Update image properties
// 1 hour duration
// Calculate the DAR (display aspect ratio)
// Reduce size fraction
// Set the ratio based on the reduced fraction
// Mark as "open"
// Close reader
// Close all objects, if reader is 'open'
// Mark as "closed"
// Get an openshot::Frame object for a specific frame number of this reader.
// Create or get frame object
// Add Image data to frame
// actually copy the image data to this object
//TODO: Reimplement this with QImage
// return frame object
// return empty frame
// return frame object
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Re-Open path, and re-init everything (if needed)
//USE_IMAGEMAGICK
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default Constructor for the timeline (which sets the canvas width and height)
// Create CrashHandler and Attach (incase of errors)
// Init viewport size (curve based, because it can be animated)
// Init background color
// Init FileInfo struct (clear all values)
// 30 minute default duration
// Init max image size
// Init cache
// Auto Close if not already
// Free all allocated frame mappers
// Dereference and clean up FrameMapper object
// Remove reference and proceed to next element
// Destroy previous cache (if managed by timeline)
// Add an openshot::Clip to the timeline
// All clips should be converted to the frame rate of this timeline
// Apply framemapper (or update existing framemapper)
// Add clip to list
// Sort clips
// Add an effect to the timeline
// Add effect to list
// Sort effects
// Remove an effect from the timeline
// Remove an openshot::Clip to the timeline
// Apply a FrameMapper to a clip which matches the settings of this timeline
// Get lock (prevent getting frames while this happens)
// Determine type of reader
// Get the existing reader
// Create a new FrameMapper to wrap the current reader
// Update the mapping
// Update clip reader
// Apply the timeline's framerate and samplerate to all clips
// Clear all cached frames
// Loop through all clips
// Apply framemapper (or update existing framemapper)
// Calculate time of a frame number, based on a framerate
// Get float version of fps fraction
// Return the time (in seconds) of this frame
// Apply effects to the source frame (if any)
// Debug output
// Find Effects at this position and layer
// Does clip intersect the current requested time
// Debug output
// Clip is visible
// Determine the frame needed for this clip (based on the position on the timeline)
// Debug output
// Apply the effect to this frame
// end effect loop
// Return modified frame
// Get or generate a blank frame
// Init some basic properties about this frame
// Debug output
// Attempt to get a frame (but this could fail if a reader has just been closed)
// Return real frame
// ...
// ...
// ...
// Debug output
// Create blank frame
// Process a new layer of video or audio
// Get the clip's frame & image
// No frame found... so bail
// Debug output
/* REPLACE IMAGE WITH WAVEFORM IMAGE (IF NEEDED) */
// Debug output
// Get the color of the waveform
// Generate Waveform Dynamically (the size of the timeline)
/* Apply effects to the source frame (if any). If multiple clips are overlapping, only process the
// Declare an image to hold the source frame's image
/* COPY AUDIO - with correct volume */
// Debug output
// Get volume from previous frame and this frame
// optional channel to filter (if not -1)
// optional channel to map this channel to (if not -1)
// Apply volume mixing strategy
// Don't allow this clip to exceed 100% (divide volume equally between all overlapping clips with volume
// Reduce clip volume by a bit, hoping it will prevent exceeding 100% (but it is very possible it will)
// If channel filter enabled, check for correct channel (and skip non-matching channels)
// skip to next channel
// If no volume on this frame or previous frame, do nothing
// skip to next channel
// If channel mapping disabled, just use the current channel
// Apply ramp to source frame (if needed)
// TODO: Improve FrameMapper (or Timeline) to always get the correct number of samples per frame.
// Currently, the ResampleContext sometimes leaves behind a few samples for the next call, and the
// number of samples returned is variable... and does not match the number expected.
// This is a crude solution at best. =)
// Force timeline frame to match the source frame
// Copy audio samples (and set initial volume).  Mix samples with existing audio samples.  The gains are added together, to
// be sure to set the gain's correctly, so the sum does not exceed 1.0 (of audio distortion will happen).
// Debug output
// Skip out if video was disabled or only an audio frame (no visualisation in use)
// Skip the rest of the image processing for performance reasons
// Debug output
// Get actual frame image data
/* ALPHA & OPACITY */
// Get source image's pixels
// Loop through pixels
// Get the alpha values from the pixel
// Apply alpha to pixel
// Debug output
/* RESIZE SOURCE IMAGE - based on scale type */
// keep aspect ratio
// Debug output
// ignore aspect ratio
// Debug output
// respect aspect ratio
// Debug output
// Calculate ratio of source size to project size
// Even with no scaling, previews need to be adjusted correctly
// (otherwise NONE scaling draws the frame image outside of the preview)
// Debug output
// This is only here to prevent unused-enum warnings
/* GRAVITY LOCATION - Initialize X & Y to the correct values (before applying location curves) */
// left
// top
// Adjust size for scale x and scale y
// percentage X scale
// percentage Y scale
// This is only here to prevent unused-enum warnings
// center
// right
// center
// center
// center
// right
// center
// bottom
// center
// bottom
// right
// bottom
// Debug output
/* LOCATION, ROTATION, AND SCALE */
// rotate in degrees
// move in percentage of final width
// move in percentage of final height
// Transform source image (if needed)
// ROTATE CLIP
// TRANSLATE/MOVE CLIP
// SCALE CLIP (if needed)
// SHEAR HEIGHT/WIDTH
// Debug output
/* COMPOSITE SOURCE IMAGE (LAYER) ONTO FINAL IMAGE */
// Load timeline's new frame image into a QPainter
// Apply transform (translate, rotate, scale)... if any
// Composite a new layer onto the image
// Draw frame #'s on top of image (if needed)
// This is only here to prevent unused-enum warnings
// Draw frame number on top of image
// Debug output
// Update the list of 'opened' clips
// is clip already in list?
// Remove clip from 'opened' list, because it's closed now
// Close clip
// Add clip to 'opened' list, because it's missing
// Open the clip
// ...
// Debug output
// Sort clips by position on the timeline
// Debug output
// sort clips
// Sort effects by position on the timeline
// sort clips
// Close the reader (and any resources it was consuming)
// Close all open clips
// Open or Close this clip, based on if it's intersecting or not
// Mark timeline as closed
// Clear cache
// Open the reader (and start consuming resources)
// Compare 2 floating point numbers for equality
// Get an openshot::Frame object for a specific frame number of this reader.
// Adjust out of bounds frame number
// Check cache
// Debug output
// Return cached frame
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Check for open reader (or throw exception)
// Check cache again (due to locking)
// Debug output
// Return cached frame
// Minimum number of frames to process (for performance reasons)
// Get a list of clips that intersect with the requested section of timeline
// This also opens the readers for intersecting clips, and marks non-intersecting clips as 'needs closing'
// Allow nested OpenMP sections
// Debug output
// GENERATE CACHE FOR CLIPS (IN FRAME # SEQUENCE)
// Determine all clip frames, and request them in order (to keep resampled audio in sequence)
// Loop through clips
// Get clip frame #
// Cache clip object
// Loop through all requested frames
// Debug output
// Init some basic properties about this frame
// Create blank frame (which will become the requested frame)
// Debug output
// Add Background Color to 1st layer (if animated or not black)
// Debug output
// Find Clips near this time
// Debug output
// Clip is visible
// Determine if clip is "top" clip on this layer (only happens when multiple clips are overlapping)
// Determine if top clip
// Determine max volume of overlapping clips
// Determine the frame needed for this clip (based on the position on the timeline)
// Debug output
// Add clip's frame as layer
// Debug output
// end clip loop
// Debug output
// Set frame # on mapped frame
// Add final frame to cache
// end frame loop
// end parallel
// Debug output
// Return frame (or blank frame)
// Find intersecting clips (or non intersecting clips)
// Find matching clips
// Calculate time of frame
// Re-Sort Clips (since they likely changed)
// Find Clips at this time
// Does clip intersect the current requested time
// Debug output
// Open (or schedule for closing) this clip, based on if it's intersecting or not
// Clip is visible
// Add the intersecting clip
// Add the non-intersecting clip
// end clip loop
// return list
// Set the cache object used by this reader
// Destroy previous cache (if managed by timeline)
// Set new cache
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// Add array of clips
// Find Clips at this time
// Add array of effects
// loop through effects
// return JsonValue
// Load JSON string into this object
// Get lock (prevent getting frames while this happens)
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Close timeline before we do anything (this also removes all open and closing clips)
// Set parent data
// Clear existing clips
// loop through clips
// Create Clip
// Load Json into Clip
// Add Clip to Timeline
// Clear existing effects
// loop through effects
// Create Effect
// Create instance of effect
// Load Json into Effect
// Add Effect to Timeline
// Update duration of timeline
// Re-open if needed
// Apply a special formatted JSON object, which represents a change to the timeline (insert, update, delete)
// Get lock (prevent getting frames while this happens)
// Parse JSON string into JSON objects
// Raise exception
// Process the JSON change array, loop through each item
// Process each type of change
// Apply to CLIPS
// Apply to EFFECTS
// Apply to TIMELINE
// Error parsing JSON (or missing keys)
// Apply JSON diff to clips
// Get key and type of change
// Find id of clip (if any)
// Get each change
// Check for id
// Set the id
// Find matching clip in timeline (if any)
// clip found, exit loop
// id found, exit loop
// Check for a more specific key (targetting this clip's effects)
// For example: ["clips", {"id:123}, "effects", {"id":432}]
// This change is actually targetting a specific effect under a clip (and not the clip)
// Check for id
// Set the id
// Find matching effect in timeline (if any)
// Apply the change to the effect directly
// Calculate start and end frames that this impacts, and remove those frames from the cache
// effect found, don't update clip
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Determine type of change operation
// Create new clip
// Set properties of new clip from JSON
// Add clip to timeline
// Apply framemapper (or update existing framemapper)
// Update existing clip
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Remove cache on clip's Reader (if found)
// Update clip properties from JSON
// Apply framemapper (or update existing framemapper)
// Remove existing clip
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Remove clip from timeline
// Apply JSON diff to effects
// Get key and type of change
// Find id of an effect (if any)
// Check for id
// Set the id
// Find matching effect in timeline (if any)
// effect found, exit loop
// id found, exit loop
// Now that we found the effect, apply the change to it
// Apply change to effect
// Apply JSON diff to effects (if you already know which effect needs to be updated)
// Get key and type of change
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Determine type of change operation
// Determine type of effect
// Create Effect
// Init the matching effect object
// Load Json into Effect
// Add Effect to Timeline
// Update existing effect
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Update effect properties from JSON
// Remove existing effect
// Calculate start and end frames that this impacts, and remove those frames from the cache
// Remove effect from timeline
// Apply JSON diff to timeline properties
// Get key and type of change
// Clear entire cache
// Determine type of change operation
// INSERT / UPDATE
// Check for valid property
// Set color
// Set viewport scale
// Set viewport x offset
// Set viewport y offset
// Update duration of timeline
// Set width
// Set height
// Set fps fraction
// Set fps.num
// Set fps.den
// Set display_ratio fraction
// Set display_ratio.num
// Set display_ratio.den
// Set pixel_ratio fraction
// Set pixel_ratio.num
// Set pixel_ratio.den
// Set sample rate
// Set channels
// Set channel layout
// Error parsing JSON (or missing keys)
// DELETE / RESET
// Reset the following properties (since we can't delete them)
// Error parsing JSON (or missing keys)
// Clear all caches
// Get lock (prevent getting frames while this happens)
// Clear primary cache
// Loop through all clips
// Clear cache on clip
// Clear nested Reader (if any)
// Set Max Image Size (used for performance optimization). Convenience function for setting
// Settings::Instance()->MAX_WIDTH and Settings::Instance()->MAX_HEIGHT.
// Maintain aspect ratio regardless of what size is passed in
// Scale QSize up to proposed size
// Set max size
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor
// Initialized writer info
// This method copy's the info struct of a reader, and sets the writer with the same info
// Display file information
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set data from Json (if key is found)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Global reference to logger
// Create or Get an instance of the logger singleton
// Create the actual instance of logger only once
// init ZMQ variables
// Default connection
//*:5556");
/*:5556");
// Init enabled to False (force user to call Enable())
// Init resvg logging (if needed)
// This can only happen 1 time or it will crash
// Set the connection for this logger
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Does anything need to happen?
// Set new connection
// Create ZMQ Context
// Close an existing bound publisher socket
// Create new publisher instance
// Bind to the socket
//*:*";
/*:*";
// Sleeping to allow connection to wake up (0.25 seconds)
// Don't do anything
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Send message over socket (ZeroMQ)
// Write to log file (if opened, and force it to write to disk in case of a crash)
// Log message to a file (if path set)
// Write to log file (if opened, and force it to write to disk in case of a crash)
// Update path
// Close file (if already open)
// Open file (write + append)
// Get current time and log first message
// Disable logger as it no longer needed
// Close file (if already open)
// Close socket (if any)
// Close an existing bound publisher socket
// Append debug information
// Don't do anything
// Create a scoped lock, allowing only a single thread to run the following code at one time
// Add attributes to method JSON
// Output to standard output
// Send message through ZMQ
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get bar color (and create small color image)
// Get current keyframe values
// Get pixel array pointer
// Get pixels sizes of all bars
// Loop through rows
// Top & Bottom Bar
// Left Bar
// Right Bar
// Cleanup colors and arrays
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get the current blur radius
// Declare arrays for each color channel
// Create empty target RGBA arrays (for the results of our blur)
// Loop through pixels and split RGBA channels into separate arrays
// Get the RGBA values from each pixel
// Split channels into their own arrays
// Init target RGBA arrays
// Loop through each iteration
// HORIZONTAL BLUR (if any)
// Init boxes for computing blur
// Apply horizontal blur to target RGBA channels
// Remove boxes
// Copy blur_<chan> back to <chan> for vertical blur or next iteration
// VERTICAL BLUR (if any)
// Init boxes for computing blur
// Apply vertical blur to target RGBA channels
// Remove boxes
// Copy blur_<chan> back to <chan> for vertical blur or next iteration
// Copy RGBA channels back to original image
// Get the RGB values from the pixel
// Split channels into their own arrays
// Delete channel arrays
// return the modified frame
// Credit: http://blog.ivank.net/fastest-gaussian-blur.html (MIT License)
// standard deviation, number of boxes
// Ideal averaging filter width
// Credit: http://blog.ivank.net/fastest-gaussian-blur.html (MIT License)
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get keyframe values for this frame
// Loop through pixels
// Get the RGB values from the pixel
// Adjust the contrast
// Adjust the brightness
// Constrain the value from 0 to 255
// Set all pixels to new value
// leave the alpha value alone
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init default color
// Init effect properties
// Default constructor, which takes an openshot::Color object and a 'fuzz' factor, which
// is used to determine how similar colored pixels are matched. The higher the fuzz, the
// more colors are matched.
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Determine the current HSL (Hue, Saturation, Lightness) for the Chrome
// Get source image's pixels
// Loop through pixels
// Get the RGB values from the pixel
// Get distance between mask color and pixel color
// Alpha out the pixel (if color similar)
// MATCHED - Make pixel transparent
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get image size
// Get the current shift amount, and clamp to range (-1 to 1 range)
// Red Keyframes
// Green Keyframes
// Blue Keyframes
// Alpha Keyframes
// Make temp copy of pixels
// Init position of current row and pixel
// Init RGBA values
// Loop through rows of pixels
// Get position of current row and pixel
// Get the RGBA value from each pixel (depending on offset)
// Shift X
// Shift Y
// Copy new values to this pixel
// Delete arrays
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get transparent color (and create small transparent image)
// Get current keyframe values
// Get pixel array pointers
// Get pixels sizes of all crop sides
// Loop through rows
// Top & Bottom Crop
// Left Crop
// Right Crop
// Cleanup colors and arrays
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get original size of frame's image
// Get the frame's image
// Create a smaller, new image
// Loop through the scanlines of the image (even or odd)
// Resize deinterlaced image back to original size, and update frame's image
// Update image on frame
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Add Is Odd Frame choices (dropdown style)
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get the current hue percentage shift amount, and convert to degrees
// Calculate a rotation matrix for the RGB colorspace (based on the current hue shift keyframe value)
// Loop through pixels
// Get the RGB values from the pixel
// Multiply each color by the hue rotation matrix
// Set all pixels to new value
// leave the alpha value alone
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the mask image (from the mask reader)
// Check if mask reader is open
// No reader (bail on applying the mask)
// Get mask image (if missing or different size than frame image)
// Only get mask if needed
// Resize mask image to match frame size
// Refresh no longer needed
// Get pixel arrays
// Loop through mask pixels, and apply average gray value to frame alpha channel
// Get the RGB values from the pixel
// Get the average luminosity
// Adjust the contrast
// Adjust the brightness
// Constrain the value from 0 to 255
// Set the alpha channel to the gray value
// Replace frame pixels with gray value
// Set alpha channel
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// does Json contain a reader?
// This reader has changed, so refresh cached assets
// does the reader Json contain a 'type'?
// Close previous reader (if any)
// Close and delete existing reader (if any)
// Create new reader (and load properties)
// Create new reader
// Create new reader
// Create new reader
// Create new reader
// Get all properties for a specific frame
// Generate JSON properties list
// Add replace_image choices (dropdown style)
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Default constructor
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Make a negative of the images pixels
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Get all properties for a specific frame
// Generate JSON properties list
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get current keyframe values
// Resize frame image smaller (based on pixelization value)
// Resize image back to original size (with no smoothing to create pixelated image)
// Get pixel array pointer
// Get pixels sizes of all margins
// Loop through rows
// Copy pixelated pixels into original frame image (where needed)
// Cleanup temp images
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get keyframe values for this frame
// Constants used for color saturation formula
// Loop through pixels
// Get the RGB values from the pixel
// Calculate the saturation multiplier
// Adjust the saturation
// Constrain the value from 0 to 255
// Set all pixels to new value
// leave the alpha value alone
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get the current shift amount, and clamp to range (-1 to 1 range)
// Declare temp arrays to hold pixels while we move things around
// X-SHIFT
// Loop through rows
// Copy current row's pixels
// Replace current row with left part of the pixels
// Move left side to the right
// Move right side to the left
// Move right side to the left
// Move left side to the right
// Make temp copy of pixels for Y-SHIFT
// Y-SHIFT
// Replace current row with left part of the pixels
// Move top side to bottom
// Move bottom side to top
// Move bottom side to top
// Move left side to the right
// Delete arrays
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Blank constructor, useful when using Json to load the effect properties
// Init effect properties
// Default constructor
// Init effect properties
// Init effect settings
/// Initialize the values of the EffectInfo struct.
/// Set the effect info
// This method is required for all derived classes of EffectBase, and returns a
// modified openshot::Frame object
// Get the frame's image
// Get pixels for frame image
// Make temp copy of pixels before we start changing them
// Get current keyframe values
//abs(((frame_number + 255) % 510) - 255);
// Loop through pixels
// Calculate X and Y pixel coordinates
// Calculate wave pixel offsets
// Time and time multiplier (to make the wave move)
// Apply amplitude / height of the wave
// Waveform algorithm on y-axis
// Shifts pixels on the x-axis
// Calculate source array location, and target array location, and copy the 4 color values
// Delete arrays
// return the modified frame
// Generate JSON string of this object
// Return formatted string
// Generate Json::JsonValue for this object
// Create root json object
// get parent properties
// return JsonValue
// Load JSON string into this object
// Parse JSON string into JSON objects
// Raise exception
// Set all values that match
// Error parsing JSON (or missing keys)
// Load Json::JsonValue into this object
// Set parent data
// Set data from Json (if key is found)
// Get all properties for a specific frame
// Generate JSON properties list
// Keyframes
// Return formatted string
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// 1 VA-API, 2 NVDEC, 6 VDPAU
/* WRITER ---------------- */
// Set options
// Open writer
//int frame_number = (rand() % 750) + 1;
// Close writer & reader
// Close timeline
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Init datetime
/* TIMELINE ---------------- */
// Create background video
// Background counter
// mask
// CLIP 1 (background image)
// CLIP 2 (decklink live stream)
// CLIP 3 (foreground image 1)
//c3.gravity = GRAVITY_BOTTOM;
// CLIP 4 (foreground image 2)
//t.AddClip(&c4);
// Decklink writer
// Loop through reader
// Send current frame to BlackMagic
// Increment background frame #
// Change background
//usleep(500 * 1);
// Go to next frame on timeline
// Got behind... skip ahead some
// Go to the next frame
// Sleep
// Image Reader
//	ImageReader r1("/home/jonathan/Pictures/Screenshot from 2013-02-10 15:06:38.png");
//	r1.Open();
//	std::shared_ptr<Frame> f1 = r1.GetFrame(1);
//	r1.Close();
//	f1->TransparentColors("#8fa09a", 20.0);
//	f1->Display();
//	return 0;
//	ImageReader r2("/home/jonathan/Pictures/trees.jpg");
//	r2.Open();
//	std::shared_ptr<Frame> f2 = r2.GetFrame(1);
//	r2.Close();
//	DecklinkReader dr(1, 11, 0, 2, 16);
//	dr.Open();
//
//	DecklinkWriter w(0, 11, 3, 2, 16);
//	w.Open();
//
//	// Loop through reader
//	int x = 0;
//	while (true)
//	{
//		if (x % 30 == 0)
//			cout << "30 frames..." << endl;
//
//		std::shared_ptr<Frame> f = dr.GetFrame(0);
//		if (f)
//		{
//			//f->Display();
//			w.WriteFrame(f);
//			usleep(1000 * 1);
//
//			x++;
//		}
//	}
//
//	// Sleep
//	sleep(4);
//
//	// Close writer
//	w.Close();
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
//#include "../../include/CrashHandler.h"
// Create a reader to generate an openshot::Frame containing text
// width
// height
// x_offset
// y_offset
// gravity
// html
// css
// background_color
// Open the reader
/* WRITER ---------------- */
// Set options
//w.SetAudioOptions(true, "libmp3lame", r.info.sample_rate, r.info.channels, r.info.channel_layout, 128000);
// Open writer
// Same frame every time
// Close writer & reader
// Set a timer with 0 timeout to terminate immediately after
// processing events
// Run QGuiApplication to completion
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Global reference to device manager
// Create or Get an instance of the device manager singleton
// Create the actual instance of device manager only once
// Get preferred audio device name (if any)
// Initialize audio device only 1 time
/* number of input channels */
/* number of output channels */
/* no XML settings.. */
/* select default device on failure */
/* preferredDefaultDeviceName */);
// Persist any errors detected
// Get all audio device names
// Close audio device
// Close Audio Device
// Constructor
// Destructor
// Set the reader object
// Create new audio source reader
// prevent this source from terminating when it reaches the end
// Set local vars
// TODO: Update transport or audio source's sample rate, incase the sample rate
// is different than the original Reader
// Mark as 'playing'
// Get the current frame object (which is filling the buffer)
// Get the currently playing frame number
// Seek the audio thread
// Play the audio
// Start playing
// Stop the audio
// Stop playing
// Start audio thread
// Start new audio device (or get existing one)
// Add callback
// Create TimeSliceThread for audio buffering
// Connect source to transport
// tells it to buffer this many samples ahead
// Connect transport to mixer and player
// Start the transport
// Stop audio and shutdown transport
// Kill previous audio
// Remove source
// Stop time slice thread
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Accept keyboard event
// Close window, stop player, and quit
// paused, so start playing again
// already playing, but speed is zero... so just speed up to normal
// already playing... so pause
// Get filename of media files
// Create FFmpegReader and open file
// Set aspect ratio of widget
// Play video
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor
// Destructor
// Start thread
// bail if no reader set
// Start the threads
// Calculate the milliseconds a single frame should stay on the screen
// Get the start time (to track how long a frame takes to render)
// Get the current video frame (if it's different)
// Experimental Pausing Code (if frame has not changed)
// Set the video frame on the video thread and render frame
// Keep track of the last displayed frame
// How many frames ahead or behind is the video thread?
// Set audio frame again (since we are not in normal speed, and not paused)
// Only calculate this if a reader contains both an audio and video thread
// Get the end time (to track how long a frame takes to render)
// Determine how many milliseconds it took to render the frame
// Calculate the amount of time to sleep (by subtracting the render time)
// Debug
// Adjust drift (if more than a few frames off between audio and video)
// Since the audio and video threads are running independently, they will quickly get out of sync.
// To fix this, we calculate how far ahead or behind the video frame is, and adjust the amount of time
// the frame is displayed on the screen (i.e. the sleep time). If a frame is ahead of the audio,
// we sleep for longer. If a frame is behind the audio, we sleep less (or not at all), in order for
// the video to catch up.
// Skip frame(s) to catch up to the audio (if more than 10 frames behind)
// Seek forward 1/2 the difference
// Don't sleep now... immediately go to next position
// Sleep (leaving the video frame on the screen for the correct amount of time)
// Get the next displayed frame (based on speed and direction)
// Get the next frame (based on speed)
// return cached frame
// Update cache on which frame was retrieved
// return frame from reader
// ...
// ...
// ...
// Start video/audio playback
// Stop video/audio playback
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor
// Destructor
// Get the currently playing frame number (if any)
// Set the currently playing frame number (if any)
// Seek the reader to a particular frame number
// Play the video
// Start playing
// Stop the audio
// Stop playing
// Start the thread
// Calculate sleep time for frame rate
// Cache frames before the other threads need them
// Cache frames up to the max frames
// Only cache up till the max_frames amount... then sleep
// Force the frame to be generated
// Ignore out of bounds frame exceptions
// Is cache position behind current display frame?
// Jump ahead
// Increment frame number
// Sleep for 1 frame length
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Constructor
// Destructor
// Get the currently playing frame number (if any)
// Start the thread
// Make other threads wait on the render event
// Debug
// Render the frame to the screen
// Signal to other threads that the rendered event has completed
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/// Override QWidget which needs to be painted
// re-cast QWidget pointer (long) as an actual QWidget
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// init aspect ratio settings (default values)
// calculate aspect ratio
// maintain aspect ratio
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create cache object
// Loop 50 times
// Add blank frame to the cache
// Cache should have all frames, with no limit
// Max frames should default to 0
// Create cache object (with a max of 5 previous items)
// Loop 20 times
// Add blank frame to the cache
// Cache should have all 20
// Add 10 frames again
// Add blank frame to the cache
// Count should be 20, since we're more frames than can be cached.
// Check which items the cache kept
// Create cache object
// Loop 10 times
// Add blank frame to the cache
// Cache should only have 10 items
// Clear Cache
// Cache should now have 0 items
// Create cache object
// Loop 10 times
// Add blank frame to the cache (each frame is #1)
// Cache should only have 1 items (since all frames were frame #1)
// Create cache object
// Loop 5 times
// Add blank frame to the cache
// Check if certain frames exists (only 1-5 exist)
// Create cache object
// Create 3 frames
// Add frames to cache
// Get frames
// Check if certain frames exists (only 1-5 exist)
// Create cache object (with a max of 10 items)
// Create 3 frames
// Add frames to cache
// Check if frame 1 is the front
// Check if frame 1 is STILL the front
// Erase frame 1
// Check if frame 2 is the front
// Create cache object (with a max of 10 items)
// Create 3 frames
// Add frames to cache
// Check if count is 3
// Check if frame 2 exists
// Remove frame 2
// Check if frame 2 exists
// Check if count is 2
// Remove frame 1
// Check if frame 1 exists
// Check if count is 1
// Create cache object
// Loop 20 times
// Add blank frame to the cache
// Cache defaults max frames to -1, unlimited frames
// Set max frames
// Set max frames
// Create cache object (using platform /temp/ directory)
// Add frames to disk cache
// Add blank frame to the cache
// Add some picture data
// Should have 20 frames
// Remove all 20 frames
// Should have 20 frames
// Create cache object (using platform /temp/ directory)
// Add frames to disk cache
// Add blank frame to the cache
// Add some picture data
// Cache defaults max frames to -1, unlimited frames
// Set max frames
// Set max frames
// Read frames from disk cache
// Check count of cache
// Clear cache
// Check count of cache
// Delete cache directory
// Create cache object (using platform /temp/ directory)
// Add frames to disk cache
// Add blank frame to the cache
// Add some picture data
// Should have 20 frames
// Remove all 20 frames
// Should have 20 frames
// Delete cache directory
// Create cache object (using platform /temp/ directory)
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
// Delete cache directory
// Create memory cache object
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
// Add some frames (out of order)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a empty clip
// Check basic settings
// Create a empty clip
// Check basic settings
// Create a empty clip
// Check basic settings
// Change some properties
// Create a empty clip
// Change some properties
// Get properties JSON string at frame 1
// Parse JSON string into JSON objects
// Raise exception
// Check for specific things
// Error parsing JSON (or missing keys)
// Get properties JSON string at frame 250
// Parse JSON string into JSON objects
// Raise exception
// Check for specific things
// Error parsing JSON (or missing keys)
// Get properties JSON string at frame 250 (again)
// again
// Parse JSON string into JSON objects
// Raise exception
// Check for specific things
// Error parsing JSON (or missing keys)
// Get properties JSON string at frame 500
// Parse JSON string into JSON objects
// Raise exception
// Check for specific things
// Error parsing JSON (or missing keys)
// Free up the reader we allocated
// Load clip with video
// Get frame 1
// Get the image data
// pixel 112 (4 bytes per pixel)
// Check image properties on scanline 10, pixel 112
// Check the # of Effects
// Add a 2nd negate effect
// Get frame 1
// Get the image data
// pixel 112 (4 bytes per pixel)
// Check image properties on scanline 10, pixel 112
// Check the # of Effects
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create an empty color
// Create an empty color
// Set starting color (on frame 0)
// Set ending color (on frame 1000)
// Check the color at frame 500
// Color
// Color
// Color
// Color
// Color with alpha
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create an empty coordinate
// Create an empty coordinate
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Check invalid path
// Create a reader
// Check invalid path
// Create a reader
// Get frame 1
// Get the number of channels and samples
// Check audio properties
// Check actual sample values (to be sure the waveform is correct)
// Close reader
// Create a reader
// Get frame 1
// Get the image data
// pixel 112 (4 bytes per pixel)
// Check image properties on scanline 10, pixel 112
// Check pixel function
// Get frame 1
// Get the next frame
// pixel 112 (4 bytes per pixel)
// Check image properties on scanline 10, pixel 112
// Check pixel function
// Close reader
// Create a reader
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Get frame
// Close reader
// Create a reader
// Get frame that requires a seek
// Close and Re-open the reader
// Get frame
// Close and Re-open the reader
// Get frame
// Close reader
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Reader
/* WRITER ---------------- */
// Set options
// Open writer
// Write some frames
// Close writer & reader
// Verify various settings on new MP4
// Get a specific frame
// Get the image data for row 500
// pixel 112 (4 bytes per pixel)
// Check image properties on scanline 10, pixel 112
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a default fraction (should be 1/1)
// Check default fraction
// reduce fraction
// Check the reduced fraction
// Create fraction
// Check fraction
// reduce fraction
// Check the reduced fraction
// Create fraction
// Check fraction
// reduce fraction
// Check the reduced fraction
// Create fraction
// Check fraction
// Get the reciprocal of the fraction (i.e. flip the fraction)
// Check the reduced fraction
// Re-Check the original fraction (to be sure it hasn't changed)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a reader
// Create mapping between 24 fps and 29.97 fps using classic pulldown
// Should find this frame
// success
// Unexpected failure to find frame
// Create a reader
// Create mapping 24 fps and 29.97 fps
// Check invalid frame number
// Create a reader
// Create mapping 24 fps and 30 fps
// Check for 3 fields of frame 2
// Create a reader
// Create mapping 24 fps and 30 fps
// Check for advanced pulldown (only 1 fake frame)
// Create a reader
// Create mapping 24 fps and 30 fps
// Check for advanced pulldown (only 1 fake frame)
// Create a reader
// Create mapping between 30 fps and 24 fps
// Check for advanced pulldown (only 1 fake frame)
// Create a reader
// Create mapping between 30 fps and 24 fps
// Check for advanced pulldown (only 1 fake frame)
// Create a reader
// Create mapping between 30 fps and 24 fps
// Check for advanced pulldown (only 1 fake frame)
// Create a reader: 24 fps, 2 channels, 48000 sample rate
// Map to 30 fps, 3 channels surround, 44100 sample rate
// Check details
// Change mapping data
// Check details
// Close mapper
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a "blank" default Frame
// Test aborts here if we didn't get a Frame
// Check basic default parameters
// Should be false until we load or create contents
// Calling GetImage() paints a blank frame, by default
// Create a video clip
// Get first frame
// Create a "blank" default Frame
// Load an image
// Test aborts here if we didn't get a Frame
// Check loaded image parameters
// Create a dummy Frame
// Load an image
// Add image to f1, then copy f1 to f2
// SUITE(Frame_Tests)
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Reader
/* WRITER ---------------- */
// Set the image output settings (format, fps, width, height, quality, loops, combine)
// Open writer
// Write some frames (start on frame 500 and go to frame 510)
// Close writer & reader
// Open up the 5th frame from the newly created GIF
// Verify various settings
// Get a specific frame
// Get the image data for row 500
// pixel 230 (4 bytes per pixel)
// Check image properties
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create an empty keyframe
// Create an empty keyframe
// Create an empty keyframe
// Create an empty keyframe
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Check the expected number of values
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Check the expected number of values
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Check the expected number of values
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Check the expected number of values
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Check the expected number of values
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Create a keyframe curve with 2 points
// Spot check values from the curve (to the right)
// Spot check values from the curve (to the left)
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Create a keyframe curve
// Spot check values from the curve
// Spot check values from the curve
// Spot check values from the curve
// Spot check values from the curve
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Resize / Scale the keyframe
// 100% larger
// Spot check values from the curve
// Resize / Scale the keyframe
// 50% smaller, which should match the original size
// Spot check values from the curve
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Flip the points
// Spot check values from the curve
// Flip the points again (back to the original)
// Spot check values from the curve
// Create a keyframe curve with 2 points
// Spot check values from the curve
// Large value
// Create a keyframe curve with 2 points
// 90 minutes long
// Spot check values from the curve
// This is the index of point with X == 2
// Which cases need to be tested to keep same behaviour as
// previously?
//
// - "invalid point" => true
// - point where all next values are equal => false
// - point where first non-eq next value is smaller => false
// - point where first non-eq next value is larger => true
// testing with linear
// testing with bezier
// first non-eq is smaller
// first non-eq is larger
// all next values are equal
// "invalid points"
// all next equal
// first non-eq is larger
// first non-eq is smaller
// bezier and linear
// 10 milliseconds would still be relatively slow, but need to think about slower build machines!
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a point with X and Y values
// Create a point with a coordinate
// Create a point with a coordinate and interpolation
// Create a point with a coordinate and interpolation
// Create a point with a coordinate and interpolation
// Create a point with a coordinate and interpolation
// Create a point with a coordinate and interpolation
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Since it is not possible to instantiate an abstract class, this test creates
// a new derived class, in order to test the base class file info struct.
// Create a new derived class from type ReaderBase
// Create an instance of the derived class
// Check some of the default values of the FileInfo struct on the base class
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create an empty color
// Create an empty color
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Run all unit tests
/**
/* LICENSE
//www.openshotstudios.com/>. This file is part of
//www.openshot.org/>.
//www.gnu.org/licenses/>.
// Prevent name clashes with juce::UnitTest
// Create a default fraction (should be 1/1)
// Check values
// Create a default fraction (should be 1/1)
// Check values
// Create a default fraction (should be 1/1)
// Check values
// Set width
// Check values
// Set height
// Check values
// Create a default fraction (should be 1/1)
// Check values
// Create a reader
// Delay the overlay by 0.05 seconds
// Make the duration of the overlay 1/2 second
// Create a timeline
// Add clips
// Open Timeline
// Get frame
// Get the image data
// pixel 230 (4 bytes per pixel)
// Check image properties
// Get frame
// Check image properties
// Get frame
// Check image properties
// Get frame
// Check image properties
// Get frame
// Check image properties
// Get frame
// Check image properties
// Get frame
// Check image properties
// Close reader
// Create a timeline
// Add some clips out of order
// Open Timeline
// Loop through Clips and check order (they should have been sorted into the correct order)
// Bottom layer to top layer, then by position.
// Get clip object from the iterator
// increment counter
// Add another clip
// Loop through clips again, and re-check order
// Get clip object from the iterator
// increment counter
// Close reader
// Create a timeline
// Add some effects out of order
// Open Timeline
// Loop through effects and check order (they should have been sorted into the correct order)
// Bottom layer to top layer, then by position, and then by order.
// Get clip object from the iterator
// increment counter
// Add some more effects out of order
// Loop through effects again, and re-check order
// Get clip object from the iterator
// increment counter
// Close reader
// Create a timeline
// Add some effects out of order
// Open Timeline
// Get frame
// Close reader
/// Json-cpp amalgamated source (http://jsoncpp.sourceforge.net/).
/// It is intended to be used with #include "json/json.h"
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: LICENSE
// //////////////////////////////////////////////////////////////////////
/*
//en.wikipedia.org/wiki/MIT_License
// //////////////////////////////////////////////////////////////////////
// End of content of file: LICENSE
// //////////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: src/lib_json/json_tool.h
// //////////////////////////////////////////////////////////////////////
// Copyright 2007-2010 Baptiste Lepilleur and The JsonCpp Authors
// Distributed under MIT license, or public domain if desired and
// recognized in your jurisdiction.
// See file LICENSE for detail or copy at http://jsoncpp.sourceforge.net/LICENSE
// Also support old flag NO_LOCALE_SUPPORT
/* This header provides common string manipulation support, such as UTF-8,
/// Converts a unicode code-point to UTF-8.
// based on description from http://en.wikipedia.org/wiki/UTF-8
/// Constant that specify the size of the buffer that must be passed to
/// uintToString.
// Defines a char buffer for use with uintToString().
/** Converts an unsigned integer to string.
/** Change ',' to '.' everywhere in buffer.
//github.com/open-source-parsers/jsoncpp/pull/9
/**
// Don't delete the last zero before the decimal point.
// namespace Json
// LIB_JSONCPP_JSON_TOOL_H_INCLUDED
// //////////////////////////////////////////////////////////////////////
// End of content of file: src/lib_json/json_tool.h
// //////////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: src/lib_json/json_reader.cpp
// //////////////////////////////////////////////////////////////////////
// Copyright 2007-2011 Baptiste Lepilleur and The JsonCpp Authors
// Copyright (C) 2016 InfoTeCS JSC. All rights reserved.
// Distributed under MIT license, or public domain if desired and
// recognized in your jurisdiction.
// See file LICENSE for detail or copy at http://jsoncpp.sourceforge.net/LICENSE
// if !defined(JSON_IS_AMALGAMATION)
//__cplusplus
//_CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES
//_MSC_VER
// Disable warning about strdup being deprecated.
// Define JSONCPP_DEPRECATED_STACK_LIMIT as an appropriate integer at compile
// time to change the stack limit
// see readValue()
// Implementation of class Features
// ////////////////////////////////
// Implementation of class Reader
// ////////////////////////////////
// Class Reader
// //////////////////////////////////////////////////////////////////
// std::istream_iterator<char> begin(is);
// std::istream_iterator<char> end;
// Those would allow streamed input from a file, if parse() were a
// template function.
// Since String is reference-counted, this at least does not
// create an extra copy.
// Set error location to start of doc, ideally should be first token found
// in doc
// readValue() may call itself only if it calls readObject() or ReadArray().
// These methods execute nodes_.push() just before and nodes_.pop)() just
// after calling readValue(). parse() executes one nodes_.push(), so > instead
// of >=.
// "Un-read" the current token and mark the current value as a null
// token.
// Else, fall through...
// convert dos EOL
// convert Mac EOL
// Consume DOS EOL. It will be normalized in addComment.
// Break on Moc OS 9 EOL.
// stopgap for already consumed character
// integral part
// fractional part
// exponential part
// empty object
// error already set
// empty array
// error already set
// Accept Comment after last item in the array.
// Attempts to parse the number as an integer. If the number is
// larger than the maximum supported value of an integer then
// we decode the number as a double.
// TODO: Help the compiler do the div and mod at compile time or get rid of
// them.
// We've hit or exceeded the max value divided by 10 (rounded down). If
// a) we've only just touched the limit, b) this is the last digit, and
// c) it's small enough to fit in that rounding delta, we're okay.
// Otherwise treat this number as a double to avoid overflow.
// skip '"'
// do not include '"'
// surrogate pairs
// discard errors caused by recovery
// column & line start at 1
// Deprecated. Preserved for backward compatibility
// exact copy of Features
// OurFeatures
// exact copy of Implementation of class Features
// ////////////////////////////////
// Implementation of class Reader
// ////////////////////////////////
// exact copy of Reader, renamed to OurReader
// no impl
// no impl
// OurReader
// complete copy of Read impl, for OurReader
// Set error location to start of doc, ideally should be first token found
// in doc
//  To preserve the old behaviour we cast size_t to int.
// "Un-read" the current token and mark the current value as a null
// token.
// else, fall through ...
// else fall through
// convert dos EOL
// convert Mac EOL
// Consume DOS EOL. It will be normalized in addComment.
// Break on Moc OS 9 EOL.
// stopgap for already consumed character
// integral part
// fractional part
// exponential part
// empty object
// error already set
// empty array
// error already set
// Accept Comment after last item in the array.
// Attempts to parse the number as an integer. If the number is
// larger than the maximum supported value of an integer then
// we decode the number as a double.
// TODO: Help the compiler do the div and mod at compile time or get rid of
// them.
// We've hit or exceeded the max value divided by 10 (rounded down). If
// a) we've only just touched the limit, b) this is the last digit, and
// c) it's small enough to fit in that rounding delta, we're okay.
// Otherwise treat this number as a double to avoid overflow.
// Sanity check to avoid buffer overflow exploits.
// Avoid using a string constant for the format control string given to
// sscanf, as this can cause hard to debug crashes on OS X. See here for more
// info:
//
//     http://developer.apple.com/library/mac/#DOCUMENTATION/DeveloperTools/gcc-4.0.1/gcc/Incompatibilities.html
// skip '"'
// do not include '"'
// surrogate pairs
// discard errors caused by recovery
// column & line start at 1
// so we do not need to test for NULL
// static
//! [CharReaderBuilderStrictMode]
//! [CharReaderBuilderStrictMode]
// static
//! [CharReaderBuilderDefaults]
//! [CharReaderBuilderDefaults]
//////////////////////////////////
// global functions
// Note that we do not actually need a null-terminator.
// namespace Json
// //////////////////////////////////////////////////////////////////////
// End of content of file: src/lib_json/json_reader.cpp
// //////////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: src/lib_json/json_valueiterator.inl
// //////////////////////////////////////////////////////////////////////
// Copyright 2007-2010 Baptiste Lepilleur and The JsonCpp Authors
// Distributed under MIT license, or public domain if desired and
// recognized in your jurisdiction.
// See file LICENSE for detail or copy at http://jsoncpp.sourceforge.net/LICENSE
// included by json_value.cpp
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// class ValueIteratorBase
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// Iterator for null value are initialized using the default
// constructor, which initialize current_ to the default
// std::map::iterator. As begin() and end() are two instance
// of the default std::map::iterator, they can not be compared.
// To allow this, we handle this comparison specifically.
// Usage of std::distance is not portable (does not compile with Sun Studio 12
// RogueWave STL,
// which is the one used by default).
// Using a portable hand-made version for non random iterator instead:
//   return difference_type( std::distance( current_, other.current_ ) );
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// class ValueConstIterator
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// class ValueIterator
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// namespace Json
// //////////////////////////////////////////////////////////////////////
// End of content of file: src/lib_json/json_valueiterator.inl
// //////////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: src/lib_json/json_value.cpp
// //////////////////////////////////////////////////////////////////////
// Copyright 2011 Baptiste Lepilleur and The JsonCpp Authors
// Distributed under MIT license, or public domain if desired and
// recognized in your jurisdiction.
// See file LICENSE for detail or copy at http://jsoncpp.sourceforge.net/LICENSE
// if !defined(JSON_IS_AMALGAMATION)
// min()
// size_t
// Provide implementation equivalent of std::snprintf for older _MSC compilers
// Disable warning C4702 : unreachable code
// This is a walkaround to avoid the static initialization of Value::null.
// kNull must be word-aligned to avoid crashing on ARM.  We use an alignment of
// 8 (instead of 4) as a bit of future-proofing.
// static const unsigned char ALIGNAS(8) kNull[sizeof(Value)] = { 0 };
// const unsigned char& kNullRef = kNull[0];
// const Value& Value::null = reinterpret_cast<const Value&>(kNullRef);
// const Value& Value::nullRef = null;
// static
// for backwards compatibility, we'll leave these global references around, but
// DO NOT use them in JSONCPP library code any more!
// The constant is hard-coded because some compiler have trouble
// converting Value::maxUInt64 to a double correctly (AIX/xlC).
// Assumes that UInt64 is a 64 bits integer.
// defined(JSON_HAS_INT64)
// The casts can lose precision, but we are looking only for
// an approximate range. Might fail on edge cases though. ~cdunn
// return d >= static_cast<double>(min) && d <= static_cast<double>(max);
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
/** Duplicates the specified string value.
// Avoid an integer overflow in the call to malloc below by limiting length
// to a sane value.
/* Record the length as a prefix.
// Avoid an integer overflow in the call to malloc below by limiting length
// to a sane value.
// to avoid buffer over-run accidents by users later
/** Free the string duplicated by
// length==0 => we allocated the strings memory
// !JSONCPP_USING_SECURE_MEMORY
// JSONCPP_USING_SECURE_MEMORY
// namespace Json
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// ValueInternals...
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// if !defined(JSON_IS_AMALGAMATION)
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// class Value::CZString
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// Notes: policy_ indicates if the string was allocated when
// a string is stored.
// allocate != duplicate
// +1 for null terminating
// character for sake of
// completeness but not actually
// necessary
// return strcmp(cstr_, other.cstr_) < 0;
// Assume both are strings.
// return strcmp(cstr_, other.cstr_) == 0;
// Assume both are strings.
// const char* Value::CZString::c_str() const { return cstr_; }
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// class Value::Value
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////
/*! \internal Default constructor initialization must be equivalent to:
// allocated_ == false, so this is safe.
// defined(JSON_HAS_INT64)
// unreachable
// unreachable
// if defined(JSON_HAS_INT64)
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
// This can fail (silently?) if the value is bigger than MAX_FLOAT.
// if !defined(JSON_USE_INT64_DOUBLE_CONVERSION)
// This is kind of strange. Not recommended.
/// Number of values in array or object
// size of the array is highest index + 1
// unreachable;
// Access an object value by name, create a null member if it does not exist.
// @pre Type of '*this' is object or null.
// @param key is null-terminated.
// NOTE!
// @param key is not null-terminated.
// shift left all items left, into the place of the "removed"
// erase the last one ("leftover")
//
//# ifdef JSON_USE_CPPTL
// EnumMemberNames
// Value::enumMemberNames() const
//{
//   if ( type() == objectValue )
//   {
//      return CppTL::Enum::any(  CppTL::Enum::transform(
//         CppTL::Enum::keys( *(value_.map_), CppTL::Type<const CZString &>() ),
//         MemberNamesTransform() ) );
//   }
//   return EnumMemberNames();
//}
//
//
// EnumValues
// Value::enumValues() const
//{
//   if ( type() == objectValue  ||  type() == arrayValue )
//      return CppTL::Enum::anyValues( *(value_.map_),
//                                     CppTL::Type<const Value &>() );
//   return EnumValues();
//}
//
//# endif
// Note that maxInt64 (= 2^63 - 1) is not exactly representable as a
// double, so double(maxInt64) will be rounded up to 2^63. Therefore we
// require the value to be strictly less than the limit.
// JSON_HAS_INT64
// Note that maxUInt64 (= 2^64 - 1) is not exactly representable as a
// double, so double(maxUInt64) will be rounded up to 2^64. Therefore we
// require the value to be strictly less than the limit.
// JSON_HAS_INT64
// Note that maxUInt64 (= 2^64 - 1) is not exactly representable as a
// double, so double(maxUInt64) will be rounded up to 2^64. Therefore we
// require the value to be strictly less than the limit.
// JSON_HAS_INT64
// Always discard trailing newline, to aid indentation.
// class PathArgument
// //////////////////////////////////////////////////////////////////
// class Path
// //////////////////////////////////////////////////////////////////
/*path*/,
// Error: missing argument %d
// Error: bad argument type
/*path*/, int /*location*/) {
// Error: invalid path.
// Error: unable to resolve path (array value expected at position...
// Error: unable to resolve path (object value expected at position...)
// Error: unable to resolve path (object has no member named '' at
// position...)
// Error: node is not an array at position ...
// Error: node is not an object at position...
// namespace Json
// //////////////////////////////////////////////////////////////////////
// End of content of file: src/lib_json/json_value.cpp
// //////////////////////////////////////////////////////////////////////
// //////////////////////////////////////////////////////////////////////
// Beginning of content of file: src/lib_json/json_writer.cpp
// //////////////////////////////////////////////////////////////////////
// Copyright 2011 Baptiste Lepilleur and The JsonCpp Authors
// Distributed under MIT license, or public domain if desired and
// recognized in your jurisdiction.
// See file LICENSE for detail or copy at http://jsoncpp.sourceforge.net/LICENSE
// if !defined(JSON_IS_AMALGAMATION)
//_CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES
//_MSC_VER
// Solaris
// IEEE standard states that NaN values will not compare to themselves
// Disable warning about strdup being deprecated.
// # if defined(JSON_HAS_INT64)
// Print into the buffer. We need not request the alternative representation
// that always has a decimal point because JSON doesn't distinguish the
// concepts of reals and integers.
// strip the zero padding from the right
// try to ensure we preserve the fact that this was given to us as a double on
// input
// namespace
// oversized encoded characters are invalid
// surrogates aren't valid codepoints itself
// shouldn't be UTF-8 encoded
// oversized encoded characters are invalid
// oversized encoded characters are invalid
// We have to walk value and escape any special characters.
// Appending to String is not efficient, but this should be rare.
// (Note: forward slashes are *not* rare, but I am not escaping them.)
// allescaped+quotes+NULL
// to avoid lots of mallocs
// case '/':
// Even though \/ is considered a legal escape in JSON, a bare
// slash is also legal, so I see no reason to escape it.
// (I hope I am not misunderstanding something.)
// blep notes: actually escaping \/ may be useful in javascript to avoid </
// sequence.
// Should add a flag to allow this compatibility mode and prevent this
// sequence from occurring.
// don't escape non-control characters
// (short escape sequence are applied above)
// codepoint is in Basic Multilingual Plane
// codepoint is not in Basic Multilingual Plane
// convert to surrogate pair first
// Class Writer
// //////////////////////////////////////////////////////////////////
// Class FastWriter
// //////////////////////////////////////////////////////////////////
// Is NULL possible for value.string_? No.
// Class StyledWriter
// //////////////////////////////////////////////////////////////////
// Is NULL possible for value.string_? No.
// output on a single line
// check if line length > max line length
// '[ ' + ', '*n + ' ]'
// already indented
// Comments may add new-line
// Comments are stripped of trailing newlines, so add one here
// Class StyledStreamWriter
// //////////////////////////////////////////////////////////////////
// Forget the stream, for safety.
// Is NULL possible for value.string_? No.
// output on a single line
// check if line length > max line length
// '[ ' + ', '*n + ' ]'
// blep intended this to look at the so-far-written string
// to determine whether we are already indented, but
// with a stream we cannot do that. So we rely on some saved state.
// The caller checks indented_.
// writeIndent();  // would include newline
//////////////////////////
// BuiltStyledStreamWriter
/// Scoped enums are not available until C++11.
/// Decide whether to write comments.
///< Drop all comments.
///< Recover odd behavior of previous versions (not implemented yet).
///< Keep all comments.
// Is NULL is possible for value.string_? No.
// output on a single line
// check if line length > max line length
// '[ ' + ', '*n + ' ]'
// blep intended this to look at the so-far-written string
// to determine whether we are already indented, but
// with a stream we cannot do that. So we rely on some saved state.
// The caller checks indented_.
// In this case, drop newlines too.
// writeIndent();  // would write extra newline
// static
///////////////
// StreamWriter
// so we do not need to test for NULL
// static
//! [StreamWriterBuilderDefaults]
//! [StreamWriterBuilderDefaults]
// namespace Json
// //////////////////////////////////////////////////////////////////////
// End of content of file: src/lib_json/json_writer.cpp
// //////////////////////////////////////////////////////////////////////
# Automatically import all openshot objects when this module is imported
#!/usr/bin/env python3
# LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
# This can be run against an uninstalled build of libopenshot, just set the
# environment variable PYTHONPATH to the location of the Python bindings.
#
# For example:
# $ PYTHONPATH=../../build/src/bindings/python python3 Example.py
#
# Create an FFmpegReader
# Open the reader
# Display metadata
# Set up Writer
# Open the Writer
# Grab 30 frames from Reader and encode to Writer
# Close out Reader & Writer
#!/usr/bin/env python3
# LICENSE
#
# Copyright (c) 2008-2019 OpenShot Studios, LLC
# <http://www.openshotstudios.com/>. This file is part of
# OpenShot Library (libopenshot), an open-source project dedicated to
# delivering high quality video editing and animation solutions to the
# world. For more information visit <http://www.openshot.org/>.
#
# OpenShot Library (libopenshot) is free software: you can redistribute it
# and/or modify it under the terms of the GNU Lesser General Public License
# as published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# OpenShot Library (libopenshot) is distributed in the hope that it will be
# useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with OpenShot Library. If not, see <http://www.gnu.org/licenses/>.
#ffffff;}
#red {color: #ff0000;}
# Create a QtHtmlReader
# width
# height
# x offset
# y offset
#000000"  # background color
# Open the reader
# Display metadata
# Set up Writer
# Open the Writer
# Grab 30 frames from Reader and encode to Writer
# Close out Reader & Writer
# Set a timer to terminate the app as soon as the event queue empties
# Run QGuiApplication to completion
# Create an empty timeline
# lower layer
# higher layer
#c2.alpha = openshot.Keyframe(0.5)
# Wipe / Transition
#t.AddEffect(e1)
